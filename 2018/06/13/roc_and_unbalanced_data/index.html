<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="ROC," />










<meta name="description" content="介绍机器学习中分类模型常用的评价指标，acc，auc，F1 和如何去处理不平衡数据。">
<meta name="keywords" content="ROC">
<meta property="og:type" content="article">
<meta property="og:title" content="ROC和 unbalanced data">
<meta property="og:url" content="http://yoursite.com/2018/06/13/roc_and_unbalanced_data/index.html">
<meta property="og:site_name" content="Jijeng&#39;s blog">
<meta property="og:description" content="介绍机器学习中分类模型常用的评价指标，acc，auc，F1 和如何去处理不平衡数据。">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://ws1.sinaimg.cn/large/e9a223b5ly1g3qc7npncdj20ug0dawfa.jpg">
<meta property="og:image" content="http://ws1.sinaimg.cn/large/e9a223b5ly1g3q453345pj205c046glh.jpg">
<meta property="og:image" content="http://ws1.sinaimg.cn/large/e9a223b5ly1g3q4b2shb6j20at06vdfz.jpg">
<meta property="og:image" content="https://i.loli.net/2019/08/01/5d421f9678f9649303.jpg">
<meta property="og:image" content="https://i.loli.net/2019/08/01/5d422029970c282991.png">
<meta property="og:image" content="https://cdn-images-1.medium.com/max/1600/1*MrcJwiWD8z47AXe_GPgZkA.png">
<meta property="og:image" content="https://cdn-images-1.medium.com/max/1600/1*H4pRIFSGcExAlV5pE6ObNA.png">
<meta property="og:image" content="https://i.loli.net/2019/10/21/oHQ7UEOwGScle4v.png">
<meta property="og:updated_time" content="2019-10-21T01:35:45.828Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ROC和 unbalanced data">
<meta name="twitter:description" content="介绍机器学习中分类模型常用的评价指标，acc，auc，F1 和如何去处理不平衡数据。">
<meta name="twitter:image" content="http://ws1.sinaimg.cn/large/e9a223b5ly1g3qc7npncdj20ug0dawfa.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/06/13/roc_and_unbalanced_data/"/>







<script>
	(function(){
		if(''){
			if (prompt('请输入文章密码','') !== ''){
				alert('密码错误！');
				history.back();
			}
		}
	})();
</script>

  <title>ROC和 unbalanced data | Jijeng's blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jijeng's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/13/roc_and_unbalanced_data/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jijeng Jia">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jijeng's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">ROC和 unbalanced data</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-13T10:35:17+08:00">
                2018-06-13
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-10-21T09:35:45+08:00">
                2019-10-21
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/06/13/roc_and_unbalanced_data/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/06/13/roc_and_unbalanced_data/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>介绍机器学习中分类模型常用的评价指标，acc，auc，F1 和如何去处理不平衡数据。</p>
<a id="more"></a>
<h2 id="ROC曲线和AUC值"><a href="#ROC曲线和AUC值" class="headerlink" title="ROC曲线和AUC值"></a>ROC曲线和AUC值</h2><p>ROC全称是“受试者工作特征”（Receiver Operating Characteristic）。ROC曲线的面积就是AUC（Area Under the Curve）。AUC用于衡量“二分类问题”机器学习算法性能（泛化能力）。说到这里不得不提及就是经常使用的符号，TP(True Positive), FP(False, Positive), TN(True Negative),FN(False Negative)。他们是根据原来真实数据和预测类别进行的排列组合（当然这是针对二分问题）。</p>
<p><strong>ROC 曲线</strong>: ROC 曲线（接收者操作特征曲线）是一种显示分类模型在所有分类阈值下的效果的图表。该曲线绘制了以下两个参数：真正例率 和 假正例率。</p>
<p>真正例率 (TPR) 是召回率的同义词，因此定义如下：<br>$$<br>T P R = \frac { T P } { T P + F N }<br>$$<br>假正例率 (FPR) 的定义如下：<br>$$<br>F P R = \frac { F P } { F P + T N }<br>$$</p>
<p>ROC 中 TPR =(True positive / ( True positive +False negative)), 那个false negative 也是真实的类别，只不过是错误的当做了 negative（false negative）</p>
<p><img src="http://ws1.sinaimg.cn/large/e9a223b5ly1g3qc7npncdj20ug0dawfa.jpg" alt=""></p>
<p>第一类错误和第二类措施是假设检验中的概念。第一类错误是原来假设是错误的，但是却被认为是正确的；第二类错误是原来的假设是正确的，但是被认为是错误的。</p>
<p>针对一个二分类问题，将实例分成正类(postive)或者负类(negative)。但是实际中分类时，会出现四种情况.</p>
<ul>
<li>若一个实例是正类并且被预测为正类，即为真正类(True Postive TP)</li>
<li>若一个实例是正类，但是被预测成为负类，即为假负类(False Negative FN)</li>
<li>若一个实例是负类，但是被预测成为正类，即为假正类(False Postive FP)</li>
<li>若一个实例是负类，但是被预测成为负类，即为真负类(True Negative TN)</li>
</ul>
<p><strong>ROC 曲线是如何绘制的</strong>: 采用不同分类阈值时的 TPR 与 FPR。降低分类阈值会导致将更多样本归为正类别，从而增加假正例（FP）和真正例（TP）的个数，可以理解为降低了被认为正确的标准，数量自然就增多了。下图显示了一个典型的 ROC 曲线。注意观察图中TPR 和 FPR是呈正相关的，验证了上述的结论。<br><img src="http://ws1.sinaimg.cn/large/e9a223b5ly1g3q453345pj205c046glh.jpg" alt=""><br>为了计算 ROC 曲线上的点，我们可以使用不同的分类阈值多次评估逻辑回归模型，但这样做效率非常低。幸运的是，有一种基于排序的高效算法可以为我们提供此类信息，这种算法称为曲线下面积。</p>
<p>ROC曲线，一般适用于你的分类器输出一个“概率值”，即这个样本属于某个类的概率是多少。 如此的话，你就需要设定一个阈值， 大于这个阈值属于正类，小于这个阈值属于负类。   从而，对于这个阈值P0， 就会得到对应的TPR, FPR, 也就是ROC曲线上的一个点，你设置不同的阈值，就会得到不同的TPR, FPR， 从而构成ROC曲线。   通常来说 阈值降低，即进入正类的门槛变低， TPR会变大，但是FPR也会变大， 看他们谁变的快。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">gbc = GradientBoostingClassifier()</span><br><span class="line">gbc.fit(x_train, y_train)</span><br><span class="line">resu = gbc.predict(x_test)  <span class="comment">#进行预测</span></span><br><span class="line">y_pred_gbc = gbc.predict_proba(x_test)[:,<span class="number">1</span>]  <span class="comment">###这玩意就是预测概率的</span></span><br><span class="line">fpr, tpr, threshold = roc_curve(y_test, y_pred_gbc)   <span class="comment">###画图的时候要用预测的概率，而不是你的预测的值</span></span><br><span class="line">plt.plot(fpr, tpr, <span class="string">'b'</span>, label=<span class="string">'AUC = %0.2f'</span> % rocauc)<span class="comment">#生成ROC曲线</span></span><br><span class="line">plt.legend(loc=<span class="string">'lower right'</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], <span class="string">'r--'</span>)</span><br><span class="line">plt.xlim([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.ylim([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">plt.ylabel(<span class="string">'真正率'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'假正率'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="http://ws1.sinaimg.cn/large/e9a223b5ly1g3q4b2shb6j20at06vdfz.jpg" alt=""></p>
<p>最理想的目标：tpr =1， fpr =0，即图中的 (0, 1) 点， 故 ROC 曲线越靠近(0, 1 ) 点，分类效果越好。</p>
<p>接着我们计算TRP(True Positive Radio)，FRP(False Positive Ratio)用于描述ROC曲线，分别表示该曲线的Y轴，X轴。<br>TPR=TP/(TP+FN)<br>FPR=FP/(FP+TN)<br>最后就形成了类似这样的图像(来源于上述的训练模型)</p>
<p>我们希望的结果是TRU越大（接近1），FRU越小（接近0）。AUC的值是ROC所覆盖的面积，当AUC越大时候，分类器的效果越好。从图中可以看出模型(ensemble)的面积是最大的，分类效果也是最好的。<br>关于该图像还有一点，如果你的曲线拟合对角线（图中虚线），那么相当于随机猜测。</p>
<p>ROC(<em>receiver operating characteristic curve</em>): ROC曲线的横坐标为<em>false positive rate</em>（FPR,假正率），纵坐标为<em>true positive rate</em>（TPR，真正率，召回率）<br>PRC(<em>precision recall curve</em>): PRC曲线的横坐标为召回率<em>Recall</em>，纵坐标为准确率<em>Precision</em>。</p>
<p>用ROC curve来表示分类器的performance很直观好用。可是，人们总是希望能有一个数值来标志分类器的好坏。<br>通常，AUC的值介于0.5到1.0之间，较大的AUC代表了较好的Performance。<br>一般来说，如果ROC是光滑的，那么基本可以判断没有太大的overfitting（比如图中0.2到0.4可能就有问题，但是样本太少了），这个时候调模型可以只看AUC，面积越大一般认为模型越好。</p>
<p><img src="https://i.loli.net/2019/08/01/5d421f9678f9649303.jpg" alt="1.jpg"></p>
<h3 id="precision-recall-的方式"><a href="#precision-recall-的方式" class="headerlink" title="precision-recall 的方式"></a>precision-recall 的方式</h3><p>一般情况，用不同的阀值，统计出一组不同阀值下的精确率和召回率，这就是PRC曲线。如下图：</p>
<p><img src="https://i.loli.net/2019/08/01/5d422029970c282991.png" alt="1.png"></p>
<p>如果是做搜索，那就是保证召回的情况下提升准确率；如果做疾病监测、反垃圾，则是保准确率的条件下，提升召回。（从图中上可以看出，一般来说，召回率的提升不会导致准确率的上升，也就是说 准确率可能不变，可能下降）</p>
<p>两者的区别：<br>在正负样本分布得极不均匀(highly skewed datasets)的情况下，PRC比ROC能更有效地反应分类器的好坏。</p>
<p>Recall：查全率，正样本中被预测出来是正的比例(越大越好)<br>Precision：查准率，预测的正样本中被正确预测的比例(越大越好)<br>True Positive Rate：跟 Recall 定义一样 （越大越好)<br>FPR : 负样本中被预测为正的比例(越小越好)</p>
<p>对于一个二分类问题，往往要设定一个 threshold，当预测值大于这个 threshold 时预测为正样本，小于这个 threshold 时预测为负样本。如果以 Recall 为横轴，Precision 为纵轴，那么设定一个 threshold 时，便可在坐标轴上画出一个点，设定多个 threshold 则可以画出一条曲线，这条曲线便是 PR 曲线。</p>
<p>PR 曲线是以 Recall 为横轴，Precision 为纵轴；而 ROC曲线则是以 FPR 为横轴，TPR 为纵轴。</p>
<p>定理1：对于一个给定的的数据集，ROC空间和PR空间存在一一对应的关系，因为二者包含完全一致的混淆矩阵。我们可以将ROC曲线转化为PR曲线，反之亦然。</p>
<p>定理 2 中 “曲线A优于曲线B” 是指曲线 B 的所有部分与曲线 A 重合或在曲线 A 之下。而在ROC空间，ROC曲线越凸向左上方向效果越好。与ROC曲线左上凸不同的是，PR曲线是右上凸效果越好。</p>
<p>F1对于PRC就好象AUC对于ROC一样。一个数字比一条线更方便调模型。</p>
<p>阈值设定的两种方法：</p>
<ol>
<li>等距离阈值，range(0, 1, 100) 生成了100 个阈值，那么对应着p-r 中的100 个点</li>
<li>二分类结果是模型的概率值，对概率值进行排序，依次使用这些概率值作为阈值，也是可以得到不同的点的坐标。</li>
</ol>
<p>如精准营销领域的商品推荐模型，模型目的是尽量将商品推荐给感兴趣的用户，若用户对推荐的商品不感兴趣，也不会有很大损失，因此此时TPR相对FPR更重要。再比如反欺诈领域的欺诈预测模型，由于模型结果会对识别的坏人进行一定的处置措施，FPR过高会对好人有一定干扰，造成误杀，影响客户体验，因此模型需保证在低于一定FPR的基础上尽量增加TPR。</p>
<p>如果在我们所说的fraud detection 或者癌症检测这一类应用中，我们的倾向肯定是“宁可错杀一千，不可放过一个”呀。所以我们可以设定在合理的precision下，最高的recall作为最优点，找到这个对应的threshold点。</p>
<p>召回率应用场景<br>召回率的应用场景：比如拿网贷违约率为例，相对好用户，我们更关心坏用户，不能错放过任何一个坏用户。因为如果我们过多的将坏用户当成好用户，这样后续可能发生的违约金额会远超过好用户偿还的借贷利息金额，造成严重偿失。召回率越高，代表实际坏用户被预测出来的概率越高，它的含义类似：宁可错杀一千，绝不放过一个。</p>
<p>对于ROC 曲线，我们希望， TPR 越高，同时FPR 越低（ROC 曲线向着左上角扩展，越陡越好）</p>
<p>先看二分类问题。指标的好坏主要取决于分类器的目标。比方说，电子邮件的垃圾过滤，你是希望它更全面（查出所有的垃圾，但是会有大量有用信息也被判为垃圾）呢，还是希望它尽量精准（不要老是将有用的邮件判为垃圾）呢？在这个例子里，显然，我们认为False Positive的伤害要大于False Negative：重要邮件要是被判成垃圾所造成的损失，远大于收件箱里还有一部分的垃圾邮件——前者可能会让你错过重要的工作，后者仅仅是让你在阅读的时候皱皱眉头。在这种情况下，我们会认为Precision的指标会比较重要，或者反应在ROC图上，FPR尽量的小——自然，在保证FPR的基础上，Recall依然还是重要的——毕竟用户购买的是垃圾过滤，如果只是过滤了1条垃圾但是Precision＝100%，这样的东西看起来也没什么用——那么综合起来，我们也可以通过ROC的AUC来进行比较，面积较大的代表同样的FPR下面，recall比较高。</p>
<p>其次是搜索问题。搜索问题其实是一个排序问题，但我们往往会定义Precision@Top K这样的指标，即正确的答案有没有被排在Top K中，如果是的话，就相当于判断为“真”，反之则为“否”。这样搜索问题就转化为了一个二分类问题，唯一的问题是，这是一个典型的数据不均衡的case。很显然，所有的候选集的数量是非常巨大的，但是K的数量不会很大（比如Top 10, Top 20）。所以，在这个问题中，我们会主要看Precision-Recall curve。更重要的是，一般而言，人们看搜索结果都不会太有耐心，所以希望Top K中的有用信息尽量多，换言之，Precision@Top K的指标，是最核心的。</p>
<p>然而如果我们的问题是多分类的问题，实际上这些指标就不适合了，我们需要看的是Confusion Matri:</p>
<p>简单来讲,</p>
<p>尽可能地找到正样例(最关心的类别)时,选recall(immediate from recall定义)<br>尽可能地避免把非正样例预测为正样例时，选precision(immediate from precision定义)</p>
<p>拿楼上的『地震预测』举例子。我的理解是，对模型的要求是不能漏报（recall一定要高），但是不能老是误报（FPR不能太高）。混合的准确率其实没有太大的意义。所以，我会选择ROC。『犯罪检测』也是一样的。要求一样，数据分布也类似（正样本&lt;&lt;负样本）</p>
<p>ROC-AUC 和 precision-recall 在实现上的差别</p>
<p>在实现上 pyplot 是 (x, y)， 如何记忆 x 和y 轴对应的是哪个指标呢？ （一般对于图标的描述是先y 后x）比如说P-R曲线，说明precision 是y 轴，recall 是x 轴。ROC 曲线是TP-FN，那么true positive rate 是y 轴，false negative rate 是x 轴。所以这两个曲线中的  recall（true positive rate ）是相反的位置。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">0</span>, <span class="number">5</span>, <span class="number">0.1</span>)</span><br><span class="line">y = np.sin(x)</span><br><span class="line">plt.plot(x, y)</span><br></pre></td></tr></table></figure>
<p>ROC 曲线<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fpr, tpr, thresholds = roc_curve(testy, probs)</span><br><span class="line">pyplot.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], linestyle=<span class="string">'--'</span>)</span><br><span class="line">pyplot.plot(fpr, tpr, marker=<span class="string">'.'</span>)</span><br><span class="line">pyplot.show()</span><br><span class="line">auc_score = roc_auc_score(testy, probs)</span><br><span class="line">print(<span class="string">'AUC: %.3f'</span> % auc_score)</span><br></pre></td></tr></table></figure></p>
<p>P-R曲线<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pyplot.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>], linestyle=<span class="string">'--'</span>)</span><br><span class="line">pyplot.plot(recall, precision, marker=<span class="string">'.'</span>)</span><br><span class="line">pyplot.show()</span><br><span class="line">print(<span class="string">'AUC: %.3f'</span> % auc_score)</span><br></pre></td></tr></table></figure></p>
<p>看完上面的，这个链接是补充信息<br><a href="http://www.davidsbatista.net/blog/2018/08/19/NLP_Metrics/" target="_blank" rel="noopener">Evaluation Metrics, ROC-Curves and imbalanced datasets</a></p>
<h3 id="PR曲线和-ROC曲线的区别"><a href="#PR曲线和-ROC曲线的区别" class="headerlink" title="PR曲线和 ROC曲线的区别"></a>PR曲线和 ROC曲线的区别</h3><p>要平衡精确率和召回率，可以调节区分正负类别的概率临界值。 为提高精确率，可以提高概率临界值，使得正类别的判断更加保守；为了提高召回率，可以降低概率临界值，以增加正类别的数量</p>
<p>做搜索：保证召回的情况下提升准确率；做疾病监测、反垃圾：保证准确率的条件下，提升召回率</p>
<p>当正负样本的分布发生变化时，ROC曲线的形状能够基本保持不变，而P-R曲线的形状一般会发生较剧烈的变化。ROC能够尽量降低不同测试集带来的干扰，更加客观的衡量模型本身的性能。如果研究者希望更多地看到模型在特定数据集上的表现，P-R曲线能够更直观地反映其性能。</p>
<p><strong>TakeOff</strong></p>
<p>If you have an imbalanced dataset accuracy can give you false assumptions regarding the classifier’s performance, it’s better to rely on precision and recall, in the same way a Precision-Recall curve is better to calibrate the probability threshold in an imbalanced class scenario as a ROC curve.</p>
<ul>
<li><p>ROC Curves: summarise the trade-off between the true positive rate and false positive rate for a predictive model using different probability thresholds.</p>
</li>
<li><p>Precision-Recall curves: summarise the trade-off between the true positive rate and the positive predictive value for a predictive model using different probability thresholds.</p>
</li>
</ul>
<p>ROC curves are appropriate when the observations are balanced between each class, whereas precision-recall curves are appropriate for imbalanced datasets. In both cases the area under the curve (AUC) can be used as a summary of the model performance.</p>
<p>Why a ROC curve cannot measure well?</p>
<p>The Receiver Operating Characteristic (ROC) curves plot FPR vs. TPR as shown below. Because TPR only depends on positives, ROC curves do not measure the effects of negatives. <strong>The area under the ROC curve (AUC) assesses overall classification performance </strong>. AUC does not place more emphasis on one class over the other, so it does not reflect the minority class well.</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*MrcJwiWD8z47AXe_GPgZkA.png" alt=""><br>Davis and Goadrich in this paper propose that Precision-Recall (PR) curves will be more informative than ROC when dealing with highly skewed datasets. The PR curves plot precision vs. recall (FPR). Because Precision is directly influenced by class imbalance so the Precision-recall curves are better to highlight differences between models for highly imbalanced data sets. When you compare different models with imbalanced settings, the area under the Precision-Recall curve will be more sensitive than the area under the ROC curve.<br><img src="https://cdn-images-1.medium.com/max/1600/1*H4pRIFSGcExAlV5pE6ObNA.png" alt=""></p>
<p><a href="http://www.davidsbatista.net/blog/2018/08/19/NLP_Metrics/" target="_blank" rel="noopener">最强讲解</a></p>
<h2 id="AUC-precision-recall-和ROC-的比较"><a href="#AUC-precision-recall-和ROC-的比较" class="headerlink" title="AUC, precision-recall 和ROC 的比较"></a>AUC, precision-recall 和ROC 的比较</h2><p>acc （准确率）的局限性主要发生在正负样本不均衡的条件下。</p>
<p>在排序问题中，通常没有一个确定的阈值把得到的结果直接判定为正样本或负样本，而是采用Top N返回结果的Precision值和Recall值来衡量排序模型的性能，即认为模型返回的Top N的结果就是模型判定的正样本，然后计算前N个位置上的准确率Precision@N和前N个位置上的召回率Recall@N。<br>Precision值和Recall值是既矛盾又统一的两个指标，为了提高Precision值，分类器需要尽量在“更有把握”时才把样本预测为正样本,但此时往往会因为过于保守而漏掉很多“没有把握”的正样本，导致Recall值降低。</p>
<p>模型返回的Precision@5的结果非常好，也就是说排序模型Top 5的返回值的质量是很高的。但在实际应用过程中，用户为了找一些冷门的视频,往往会寻找排在较靠后位置的结果，甚至翻页去查找目标视频。但根据题目描述，用户经常找不到想要的视频，这说明模型没有把相关的视频都找出来呈现给用户。显然，问题出在召回率上。如果相关结果有100个，即使Precision@5达到了100%，Recall@5也仅仅是5%。在模型评估时，我们是否应该同时关注Precision值和Recall值。进一步而言， 应该选取不同的Top N的结果进行观察，应该选取更高阶的评估指标来更全面地反映模型在Precision值和Recall值两方面的表现。最好绘制出模型的PR曲线。</p>
<p>F1 其中只是一种特例，还有更加一般的形式。<br>更一般的，我们定$F_β$分数为<br>$$<br>F_{\beta}=\left(1+\beta^{2}\right) \cdot \frac{\text {precision} \cdot \text {recall}}{\left(\beta^{2} \cdot \text {precision}\right)+\text {recall}}<br>$$</p>
<p>$F_β$的物理意义就是将准确率和召回率这两个分值合并为一个分值，在合并的过程中，召回率的权重是准确率的 $β $倍。F1分数认为召回率和准确率同等重要，F2分数认为召回率的重要程度是准确率的2倍，而 $F_{0.5}$分数认为召回率的重要程度是准确率的一半。</p>
<p>PR曲线和 ROC 曲线的区别?</p>
<p>将测试集中的负样本数量增加10倍后，可以看出PR曲线发生了明显的变化，而ROC曲线形状基本不变。这个特点让ROC曲线能够尽量降低不同测试集带来的干扰，更加客观地衡量模型本身的性能。实际问题中，正负样本的数量往往很不均衡。比如计算广告领域经常涉及转化率模型，正样本的数量往往是负样本数量的1比1000甚至1比10000。若选择不同的测试集，P-R曲线的变化就会非常大，而ROC曲线则能够更加稳定地反映模型本身的好坏。所以，ROC曲线的适用场景更多，被广泛用于排序、推荐、广告等领域。但需要注意的是，选择P-R曲线还是ROC曲线是因实际问题而异的，如果研究者希望更多地看到模型在特定数据集上的表现，P-R曲线则能够更直观地反映其性能。</p>
<p><a href="https://zdkswd.github.io/2019/03/20/%E7%99%BE%E9%9D%A2%20%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/" target="_blank" rel="noopener">参考文献</a></p>
<h2 id="how-to-handle-unbalanced-data"><a href="#how-to-handle-unbalanced-data" class="headerlink" title="how to handle unbalanced data"></a>how to handle unbalanced data</h2><p>对于这类问题是可以从数据和模型来进行考虑的。</p>
<p>Imbalanced data typically refers to a problem with classification problems where the classes are not represented equally. The accuracy paradox is the name for the exact situation in the introduction to this post.</p>
<p><strong> Data approach</strong><br>Oversample minority class  and Undersample majority class</p>
<ul>
<li>Over-sampling increases the number of minority class members in the training set. The advantage of over-sampling is that no information from the original training set is lost, as all observations from the minority and majority classes are kept. On the other hand, it is prone to overfitting. (You can add copies of instances from the under-represented class called over-sampling or more formally sampling with replacement)</li>
<li>Under-sampling, on contrary to over-sampling, aims to reduce the number of majority samples to balance the class distribution. Since it is removing observations from the original data set, it might discard useful information. (You can delete instances from the over-represented class, called under-sampling.)</li>
</ul>
<p>Some Rules of Thumb</p>
<ul>
<li>Consider testing under-sampling when you have an a lot data (tens- or hundreds of thousands of instances or more)</li>
<li>Consider testing over-sampling when you don’t have a lot of data (tens of thousands of records or less)</li>
<li>Consider testing random and non-random (e.g. stratified) sampling schemes.</li>
<li>Consider testing different resampled ratios (e.g. you don’t have to target a 1:1 ratio in a binary classification problem, try other ratios)</li>
</ul>
<p><strong> Try Different Algorithms</strong><br>基于树的这种结构的模型还是表现比较给力的。<br>That being said, decision trees often perform well on imbalanced datasets. The splitting rules that look at the class variable used in the creation of the trees, can force both classes to be addressed.</p>
<p><strong>Try Penalized Models</strong><br>Penalized classification imposes an additional cost on the model for making classification mistakes on the minority class during training. These penalties can bias the model to pay more attention to the minority class.</p>
<p><strong> Try Changing Your Performance Metric</strong></p>
<p>使用 precision and recall  curves or F1 去评价你的网络效果</p>
<ul>
<li>Precision: A measure of a classifiers exactness.</li>
<li>Recall: A measure of a classifiers completeness</li>
<li>F1 Score (or F-score): A weighted average of precision and recall.</li>
</ul>
<p>而 ROC curves 通常不是一个最好的选择。</p>
<p><a href="https://medium.com/anomaly-detection-with-python-and-r/sampling-techniques-for-extremely-imbalanced-data-281cc01da0a8" target="_blank" rel="noopener">https://medium.com/anomaly-detection-with-python-and-r/sampling-techniques-for-extremely-imbalanced-data-281cc01da0a8</a></p>
<ul>
<li>GBC参数<br>这些参数中，类似于Adaboost，我们把重要参数分为两类，第一类是Boosting框架的重要参数，第二类是弱学习器即CART回归树的重要参数。<br>n_estimators: 也就是弱学习器的最大迭代次数，或者说最大的弱学习器的个数。<br>learning_rate: 即每个弱学习器的权重缩减系数ν，也称作步长<br>对于分类模型，有对数似然损失函数”deviance”和指数损失函数”exponential”两者输入选择。默认是对数似然损失函数”deviance”。一般来说，推荐使用默认的”deviance”。它对二元分离和多元分类各自都有比较好的优化。而指数损失函数等于把我们带到了Adaboost算法。<br>对于回归模型，有均方差”ls”, 绝对损失”lad”, Huber损失”huber”和分位数损失“quantile”。默认是均方差”ls”。一般来说，如果数据的噪音点不多，用默认的均方差”ls”比较好。如果是噪音点较多，则推荐用抗噪音的损失函数”huber”。而如果我们需要对训练集进行分段预测的时候，则采用“quantile”。<br>max_features:可以使用很多种类型的值，默认是”None”,意味着划分时考虑所有的特征数.<br>subsample: 选择小于1的比例可以减少方差，即防止过拟合，但是会增加样本拟合的偏差，因此取值不能太低。推荐在[0.5, 0.8]之间，默认是1.0，即不使用子采样。</li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://www.cnblogs.com/pinard/p/6143927.html" target="_blank" rel="noopener">GBC参数设置</a><br><a href="https://www.cnblogs.com/gatherstars/p/6084696.html" target="_blank" rel="noopener">ROC曲线和AUC值</a><br><a href="https://www.dataquest.io/blog/introduction-to-ensembles/" target="_blank" rel="noopener">Introduction to Python Ensembles</a></p>
<h2 id="new-added"><a href="#new-added" class="headerlink" title="new added"></a>new added</h2><p>对于分类模型，AUC、KS、ROC曲线是综合评价模型区分能力和排序能力的指标，而精确率、召回率和F1值是在确定最佳阈值之后计算得到的指标。</p>
<p>如果增大这个阈值，预测错误（针对正样本而言，即指预测是正样本但是预测错误，下同）的概率就会降低但是随之而来的就是预测正确的概率也降低；如果减小这个阈值，那么预测正确的概率会升高但是同时预测错误的概率也会升高。实际上，这种阈值的选取也一定程度上反映了分类器的分类能力。我们当然希望无论选取多大的阈值，分类都能尽可能地正确，也就是希望该分类器的分类能力越强越好，一定程度上可以理解成一种鲁棒能力吧。为了形象地衡量这种分类能力，ROC曲线横空出世</p>
<p><strong>AUC能拿来干什么</strong></p>
<p>从作者有限的经历来说，AUC最大的应用应该就是点击率预估（CTR）的离线评估。CTR的离线评估在公司的技术流程中占有很重要的地位，一般来说，ABTest和转全观察的资源成本比较大，所以，一个合适的离线评价可以节省很多时间、人力、资源成本。那么，为什么AUC可以用来评价CTR呢？我们首先要清楚两个事情：</p>
<ul>
<li>CTR是把分类器输出的概率当做是点击率的预估值，如业界常用的LR模型，利用sigmoid函数将特征输入与概率输出联系起来，这个输出的概率就是点击率的预估值。内容的召回往往是根据CTR的排序而决定的。</li>
<li>AUC量化了ROC曲线表达的分类能力。这种分类能力是与概率、阈值紧密相关的，分类能力越好（AUC越大），那么输出概率越合理，排序的结果越合理。</li>
</ul>
<p>我们不仅希望分类器给出是否点击的分类信息，更需要分类器给出准确的概率值，作为排序的依据。所以，这里的AUC就直观地反映了CTR的准确性（也就是CTR的排序能力）</p>
<p>AUC 是一个模型评价指标，只能用于二分类模型的评价，对于二分类模型，还有很多其他评价指标，比如 logloss，accuracy，precision。如果你经常关注数据挖掘比赛，比如 kaggle，那你会发现 AUC 和 logloss 基本是最常见的模型评价指标。</p>
<p>从Mann–Whitney U statistic的角度来解释，AUC就是从所有1样本中随机选取一个样本， 从所有0样本中随机选取一个样本，然后根据你的分类器对两个随机样本进行预测，把1样本预测为1的概率为p1，把0样本预测为1的概率为p0，p1&gt;p0的概率就等于AUC。</p>
<p>但是在某些场景下，我们会更关注正样本，这时候就要用到 PR 曲线了。比如说信用卡欺诈检测，我们会更关注 precision 和 recall，比如说如果要求预测出为欺诈的人尽可能准确，那么就是要提高 precision；而如果要尽可能多地预测出潜在的欺诈人群，那么就是要提高 recall。一般来说，提高二分类的 threshold 就能提高 precision，降低 threshold 就能提高 recall，这时便可观察 PR 曲线，得到最优的 threshold。</p>
<p>两种 AUC 的理解：一般有两大类解释，一种是基于 ROC 线下面积，需要理解混淆矩阵，包括精确率、召回率、F1 值、ROC 等指标的含义。另外一种是基于概率的解释，模型的排序能力。</p>
<p>AUC是一个模型评价指标，只能用于二分类模型的评价，对于二分类模型，还有很多其他评价指标，比如logloss，accuracy，precision。如果你经常关注数据挖掘比赛，比如kaggle，那你会发现AUC和logloss基本是最常见的模型评价指标。即AUC是指随机给定一个正样本和一个负样本，分类器输出该正样本为正的那个概率值比分类器输出该负样本为正的那个概率值要大的可能性。所以AUC反应的是分类器对样本的排序能力。</p>
<p>AUC的意义</p>
<p>为什么AUC和logloss比accuracy更常用呢？因为很多机器学习的模型对分类问题的预测结果都是概率，如果要计算accuracy，需要先把概率转化成类别，这就需要手动设置一个阈值，如果对一个样本的预测概率高于这个预测，就把这个样本放进一个类别里面，低于这个阈值，放进另一个类别里面。所以这个阈值很大程度上影响了accuracy的计算。使用AUC或者logloss可以避免把预测概率转换成类别。</p>
<p>AUC指标的不足之处：</p>
<ol>
<li>只反映了模型的整体性能，看不出在不同点击率区间上的误差情况；</li>
<li>只反映了排序能力，关注的是概率值的相对大小，与阈值和概率值的绝对大小没有关系，没有反映预测精度；（简单说，如果对一个模型的点击率统一乘以2，AUC不会变化，但显然模型预测的值和真实值之间的offset扩大了。）</li>
<li>AUC只关注正负样本之间的排序，并不关心正样本内部，或者负样本内部的排序。这也体现了AUC的本质：任意个正样本的概率都大于负样本的概率的能力。</li>
</ol>
<p>logloss衡量的是预测概率分布和真实概率分布的差异性，取值越小越好。与AUC不同，logloss对预测概率敏感。（这个log loss 在书写的时候，最好是加上负号，这样是比较规范的）</p>
<p>AUC是现在分类模型，特别是二分类模型使用的主要离线评测指标之一。相比于准确率、召回率、F1等指标，AUC有一个独特的优势，就是不关注具体得分，只关注排序结果，这使得它特别适用于排序问题的效果评估，例如推荐排序的评估。</p>
<p>AUC这个指标有两种解释方法，一种是传统的“曲线下面积”解释，另一种是关于排序能力的解释。例如0.7的AUC，其含义可以大概理解为：给定一个正样本和一个负样本，在70%的情况下，模型对正样本的打分高于对负样本的打分。可以看出在这个解释下，我们关心的只有正负样本之间的分数高低，而具体的分值则无关紧要。</p>
<p>对于 ROC 和AUC的总结</p>
<ul>
<li>ROC曲线反映了分类器的分类能力，结合考虑了分类器输出概率的准确性</li>
<li>AUC量化了ROC曲线的分类能力，越大分类效果越好，输出概率越合理</li>
<li>AUC常用作CTR的离线评价，AUC越大，CTR的排序能力越强</li>
</ul>
<p><a href="https://www.jianshu.com/p/848838ecbc2d" target="_blank" rel="noopener">分类器性能度量指标之ROC曲线、AUC值</a></p>
<p>KS值是在模型中用于区分预测正负样本分隔程度的评价指标，一般应用于金融风控领域。与ROC曲线相似，ROC是以FPR作为横坐标，TPR作为纵坐标，通过改变不同阈值，从而得到ROC曲线。而在KS曲线中，则是以阈值作为横坐标，以FPR和TPR作为纵坐标，ks曲线则为TPR-FPR，ks曲线的最大值通常为ks值。</p>
<p>为什么这样求KS值呢？我们知道，当阈值减小时，TPR和FPR会同时减小，当阈值增大时，TPR和FPR会同时增大。而在实际工程中，我们希望TPR更大一些，FPR更小一些，即TPR-FPR越大越好，即ks值越大越好。</p>
<p>KS值的取值范围是[0，1]。通常来说，值越大，模型区分正负样本的能力越强（一般0.3以上，说明模型的效果比较好）。</p>
<p>评估指标和代价函数是一家人吗？</p>
<p>代价函数：f(θ,y)，又称Cost function，loss function objective function。一般用在训练过程中，用来定义预测值和真实值之间的距离（也就是衡量模型在训练集上的性能），作为模型调整参数的反馈。代价函数越小，模型性能越好。</p>
<p>评判指标：f(ŷ ,y)，一般用于训练和测试过程中，用于评估模型好坏。评判指标越大（或越小），模型越好。</p>
<p>本质上代价函数和评判指标都是一家人，只他们的应用场景不同，分工不同。代价函数是用来优化模型参数的，评价指标是用来评判模型好坏的。</p>
<p>作为评判指标所具备的条件：</p>
<p>直观，可以理解<br>……</p>
<p>作为代价函数所具备的条件：</p>
<p>函数光滑且可导：可用梯度下降求解极值<br>函数为凸函数：可用梯度下降求解最优解<br>……</p>
<p>例如我们经常使用的分类器评判指标 AUC 就不能直接被优化，因此我们常采用交叉熵来代替 AUC 进行优化。 一般情况下，交叉熵越小，AUC 就会越大。</p>
<p>推荐策略中的召回</p>
<p>推荐系统如何根据已有的用户画像和内容画像去推荐，涉及到两个关键问题：召回和排序。“召回（match）”指从全量信息集合中触发尽可能多的正确结果，并将结果返回给“排序”。召回的方式有多种：协同过滤、主题模型、内容召回和热点召回等，而“排序（rank）“则是对所有召回的内容进行打分排序，选出得分最高的几个结果推荐给用户。</p>
<p><img src="https://i.loli.net/2019/10/21/oHQ7UEOwGScle4v.png" alt="2.png"></p>
<p>搜索和推荐的区别： 搜索中用户是有明确的搜索词，但是在推荐中用户是没有明确的搜搜索词输入，是要根据用户画像，内容画像等各种信息为用户推荐他感兴趣的。</p>
<p>召回策略的评估主要根据两个评价指标：召回率和准确率。</p>
<p>召回策略主要包含两大类，即基于内容匹配的召回和基于系统过滤的召回。</p>
<ol>
<li>基于内容匹配的召回</li>
</ol>
<p>内容匹配即将用户画像与内容画像进行匹配，又分为基于内容标签的匹配和基于知识的匹配。</p>
<p>例如，A用户的用户画像中有一条标签是“杨幂的粉丝”，那么在他看了《绣春刀2》这部杨幂主演的电影后，可以为他推荐杨幂主演的其他电影或电视剧，这就是“基于内容标签的匹配”。</p>
<p>“基于知识的匹配”则更进一步，需要系统存储一条“知识”——《绣春刀2》是《绣春刀1》的续集，这样就可以为看过《绣春刀2》的用户推荐《绣春刀1》。基于内容匹配的召回较为简单、刻板，召回率较高，但准确率较低（因为标签匹配并不一定代表真的感兴趣），比较适用于冷启动的语义环境。</p>
<ol start="2">
<li>基于协同过滤的召回</li>
</ol>
<p>如果仅使用上述较简单的召回策略，推荐内容会较为单一，目前业界最常用的基于协同过滤的召回，它又分为基于用户、基于项目和基于模型的协同过滤。</p>
<p>基于用户（User-based）的协同推荐是最基础的，它的基础假设是“相似的人会有相同的喜好”，推荐方法是，发现与用户相似的其他用户，用用户的浏览记录做相互推荐。例如，通过浏览记录发现用户一与用户二的偏好类似，就将用户一点击的内容推送给用户</p>
<p>基于项目（Item-based）的协同过滤中的“项目”可以视场景定为信息流产品中的“内容”或者电商平台中的“商品”，其基础假设是“喜欢一个物品的用户会喜欢相似的物品”计算项目之间的相似性，再根据用户的历史偏好信息将类似的物品推荐给该用户。</p>
<p>基于模型的协同过滤推荐（Model-based）就是基于样本的用户喜好信息，训练一个推荐模型，然后根据实时的用户喜好的信息进行预测推荐。</p>
<p>总体来说，基于协同过滤的召回即建立用户和内容间的行为矩阵，依据“相似性”进行分发。这种方式准确率较高，但存在一定程度的冷启动问题。</p>
<p>在实际运用中，采用单一召回策略的推荐结果实际会非常粗糙，通用的解决方法是将规则打散，将上述几种召回方式中提炼到的各种细小特征赋予权重，分别打分，并计算总分值，预测CTR。</p>
<p>例如，根据内容匹配召回策略，用户A和内容甲的标签匹配度为0.6，同时，根据协同过滤召回策略，应该将内容甲推荐给用户A的可能性为0.7，那么就为0.6和0.7这两个数值分别赋予权重（这个权重可能会根据算法的具体情况来确定），得出总分，用它来预测用户可能点击的概率，从而决定是否返回该结果。</p>
<p><a href="https://t.qidianla.com/1171357.html" target="_blank" rel="noopener">技能GET | 推荐策略中的“召回”</a></p>
<p>从商业角度看，很多推荐系统连接着平台方、内容生产者、用户三个结点，因此一个好的推荐系统必然是尽可能让这三方的利益都能够考虑到，评测指标也就更加多元化，这是与学术界非常大的一个区别。</p>
<p><a href="https://lumingdong.cn/criteria-for-evaluating-recommendation-systems-in-industry.html" target="_blank" rel="noopener">工业界推荐系统的评测标准</a></p>
<p>线下评测是推荐系统最常使用的，通常有两种评测方式，一种是离线模拟评测，一种是使用用户历史真实访问数据进行评测。</p>
<p>利用历史真实日志构造用户访问参数，得到带评测接口的结果日志后，结合对应的真实反馈，可以定性评测效果对比。比如，可以评测推荐结果的 TopK 的准确率，或者排序效果 AUC。这些模型效果类指标，虽然不能代表最终关注的商业指标，但是两者之间一般存在一定的相关性。通常来说 TopK 准确率高，或者 AUC 高于 0.5 越多，对应的商业指标就会越好，这是一个基本假设。通过离线模拟评测每一天的模型效果指标，同时计算当天真实的商业指标，可以绘制出两者之间的散点图，从而回归出一个简单的模型，用离线模型效果预估上线后真实商业指标。</p>
<p>查准率，即在推荐（预测）的物品中，有多少是用户真正（准确）感兴趣的。<br>查全率，即用户喜欢的物品中，有多少是被推荐了的。</p>
<p>优点：</p>
<p>准确率和召回率对比评分准确度指标更能反应推荐系统在真实场景中的表现。</p>
<p>局限性：</p>
<p>准确率和召回率必须要一起使用才能全面评价算法的好坏 。准确率和召回率是两个很相似的指标，这两个指标存在负相关的关系，他们分别从不同的角度来评价推荐系统，单独的指标不足以说明算法的好坏，必须一起使用才是更加全面的评价。</p>
<p>准确率和召回率存在负相关关联，取决于推荐列表的长度，互相牵制<br>1）当准确率很高的时候，表明希望推荐的物品绝大多数是用户感兴趣的，因此推荐较为保守，只推少量最有­把握的物品，这样的话，有些用户可能感兴趣但排名没有那么靠前的物品则会被忽略。因此召回率就比较低。<br>2）如果召回率很高，表明目标是尽可能把用户感兴趣的物品全部召回，则门槛就会降低，为了捕获更多用户感兴趣的物品，召回的总量就多了，而准确率就低了。</p>
<p>关于排序能力的评测指标，我们自然会想到搜索引擎中的排序指标，它们在某种程度是可以应用于推荐系统发的评测，但是会有些问题。由于推荐系统输出结果是非常个人化的，除了用户本人，其他人都很难替他回答哪个好哪个不好，而搜索引擎评价搜索结果和查询相关性，具有很强的客观属性，可以他人代替评价。所以通常评价推荐系统排序效果很少采用搜索引擎排序指标，比如 MAP、MRR、NDCG。推荐系统评价排序通常采用 AUC。</p>
<p>核心关键词一般竞争力很大，相反长尾关键词一般更能带来转换率，因为目的性相对来说更强。长尾关键词 。由长尾关键词带来的流量就是长尾流量<br>虽然长尾关键词的搜索量比较少，同时也不稳定。 但是长尾关键词库能够带来的客户，转化成交为网站产品客户的比例比一般的核心关键词要高出很多，这是因为长尾关键词的目的性会更明显。</p>
<p>学会分析 AUC</p>
<p>AUC 是推荐系统中非常重要的一个指标，在工业界模型的不同阶段会有三个不同的 AUC 指标。</p>
<p>正交性：从几何中来的术语，如果两条直线互不依赖，那么他们就是正交的。</p>
<p>AUC 理论上差距应该比较小，但实际中依然可能出现较大的差异，学会对比分析这三个 AUC 值，其实可以看出很多问题。</p>
<p>train AUC &gt;&gt; test AUC ？</p>
<p>train AUC 远大于 test AUC，通常情况是模型出现了过拟合。</p>
<p>test AUC &gt;&gt; Online AUC ？</p>
<p>test AUC 远大于 online AUC， 通常是因为特征不一致产生的，那特征不一致是如何产生的呢？</p>
<p><a href="https://lumingdong.cn/criteria-for-evaluating-recommendation-systems-in-industry.html" target="_blank" rel="noopener">这里有关于不一致的原因的分析</a></p>
<p>AUC 量化了 ROC 曲线表达的分类能力。这种分类能力是与概率、阈值紧密相关的，AUC 值越大，则说明分类能力越好，那么预测输出的概率越合理，因此排序的结果越合理。如此 AUC 这个值在数学上等价于：模型把关心的那一类样本排在其他样本前面的概率。最大是 1，完美结果，而 0.5 就是随机排列，0 就是完美地全部排错。</p>
<p>pv page view 页面浏览量<br>uv unique visitor 独立访客数</p>
<h2 id="复习笔记"><a href="#复习笔记" class="headerlink" title="复习笔记"></a>复习笔记</h2><ol>
<li>ROC曲线，precision-recall 曲线是二分类模型中经常使用的评价模型最后效果的指标。AUC值一般是指ROC 曲线的面积，对应的precision-recall 也有一个数值指标F1。对于ROC 曲线纵坐标是TP_rate， 横坐标是FP_rate。</li>
<li>处理 unbalanced data 思路从data 和model 两方面进行考虑。（其实任何NN 中问题都是可以从这两方面进行考虑的）。<strong>数据处理</strong>，(1) 增强类别数量少的样本 (2)减少类别数量多的样本。在predict 的时候确实是可以设定不同的正负样本比，然后看一下模型的对于样本是否具有偏差。<strong>模型处理</strong>：(1) 基于树的模型在处理imbalanced data 还是比较给力的 (2 ) 当minority class 预测出错的时候，添加 additional cost，这样使得模型能够更加关注minority class。 <strong>使用不同的评价指标</strong>： 当样本不均衡的时候，使用 precision_ recall 或者 F1 去评价模型（这个时候ROC 通常不是很好的选择，因为对于正负样本比例不是很敏感）</li>
</ol>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/ROC/" rel="tag"># ROC</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/06/05/对抗性生成网络/" rel="next" title="对抗生成网络实验对比">
                <i class="fa fa-chevron-left"></i> 对抗生成网络实验对比
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/06/22/那些年的算法题目（一）/" rel="prev" title="那些年的算法题目（一）">
                那些年的算法题目（一） <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpeg"
                alt="Jijeng Jia" />
            
              <p class="site-author-name" itemprop="name">Jijeng Jia</p>
              <p class="site-description motion-element" itemprop="description">Stay Hungry, Stay Foolish</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">96</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">57</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/jijeng" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:jia1509309698@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          <script type="text/javascript" src="//rf.revolvermaps.com/0/0/5.js?i=5kk0u0mm50w&amp;m=0&amp;c=54ff00&amp;cr1=ff0000" async="async"></script>


  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
  <script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <script src="//cdn.bootcss.com/blueimp-md5/1.1.0/js/md5.min.js"></script>
  <script>
      var gitalk = new Gitalk({
        clientID: '8c6403951ee3eab4e420',
        clientSecret: 'd842e48ca0c28ec41200f973ba52f96ba975b441',
        repo: 'jijeng.github.io',
        owner: 'jia1509309698@163.com',
        admin: 'jia1509309698@163.com',
        id: md5(location.pathname),
        distractionFreeMode: 'true'
      });
      var div = document.createElement('div');
      div.setAttribute("id", "gitalk_comments");
      div.setAttribute("class", "post-nav");
      var bro = document.getElementById('posts').getElementsByTagName('article');
      bro = bro[0].getElementsByClassName('post-block');
      bro = bro[0].getElementsByTagName('footer');
      bro = bro[0];
      bro.appendChild(div);
      gitalk.render('gitalk_comments');
  </script>

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#ROC曲线和AUC值"><span class="nav-number">1.</span> <span class="nav-text">ROC曲线和AUC值</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#precision-recall-的方式"><span class="nav-number">1.1.</span> <span class="nav-text">precision-recall 的方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PR曲线和-ROC曲线的区别"><span class="nav-number">1.2.</span> <span class="nav-text">PR曲线和 ROC曲线的区别</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#AUC-precision-recall-和ROC-的比较"><span class="nav-number">2.</span> <span class="nav-text">AUC, precision-recall 和ROC 的比较</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#how-to-handle-unbalanced-data"><span class="nav-number">3.</span> <span class="nav-text">how to handle unbalanced data</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考文献"><span class="nav-number">4.</span> <span class="nav-text">参考文献</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#new-added"><span class="nav-number">5.</span> <span class="nav-text">new added</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#复习笔记"><span class="nav-number">6.</span> <span class="nav-text">复习笔记</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jijeng Jia</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>

<div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
Total  <span id="busuanzi_value_site_pv"></span> views
You got  <span id="busuanzi_value_site_uv"></span> visitors
</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://https-jijeng-github-io.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2018/06/13/roc_and_unbalanced_data/';
          this.page.identifier = '2018/06/13/roc_and_unbalanced_data/';
          this.page.title = 'ROC和 unbalanced data';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://https-jijeng-github-io.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
   <script type="text/javascript">
        var gitalk = new Gitalk({
          clientID: '',
          clientSecret: '',
          repo: 'jijeng.github.io',
          owner: '',
          admin: [''],
          id: location.pathname,
          distractionFreeMode: ''
        })
        gitalk.render('gitalk-container')           
       </script>


  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
