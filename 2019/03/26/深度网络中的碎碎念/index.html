<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="介绍深度网络中小的基本概念，比如权重初始化、激活函数和优化器 和常见的技术比如 dropout。">
<meta property="og:type" content="article">
<meta property="og:title" content="深度网络中的碎碎念">
<meta property="og:url" content="http://yoursite.com/2019/03/26/%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%A2%8E%E7%A2%8E%E5%BF%B5/index.html">
<meta property="og:site_name" content="Jijeng&#39;s blog">
<meta property="og:description" content="介绍深度网络中小的基本概念，比如权重初始化、激活函数和优化器 和常见的技术比如 dropout。">
<meta property="og:image" content="https://i.bmp.ovh/imgs/2019/06/ed14b5c14cb9fc02.gif">
<meta property="og:image" content="https://upload.cc/i1/2019/06/20/cMRW62.jpg">
<meta property="og:image" content="https://b2.bmp.ovh/imgs/2019/07/d95ac0845ef9211a.png">
<meta property="og:image" content="https://i.bmp.ovh/imgs/2019/07/619bdec3f9b8bffb.png">
<meta property="og:image" content="https://i.bmp.ovh/imgs/2019/07/2ce4806231a16edb.png">
<meta property="og:image" content="https://upload.cc/i1/2019/07/11/1yQFLb.png">
<meta property="og:image" content="https://upload.cc/i1/2019/07/31/srRb1v.png">
<meta property="og:image" content="https://ftp.bmp.ovh/imgs/2019/12/a730dba1a8f29659.png">
<meta property="og:image" content="https://upload.cc/i1/2019/12/12/PHKs1c.png">
<meta property="article:published_time" content="2019-03-26T02:28:14.000Z">
<meta property="article:modified_time" content="2019-12-12T04:00:18.555Z">
<meta property="article:author" content="Jijeng Jia">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.bmp.ovh/imgs/2019/06/ed14b5c14cb9fc02.gif">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/03/26/深度网络中的碎碎念/"/>







<script>
	(function(){
		if(''){
			if (prompt('请输入文章密码','') !== ''){
				alert('密码错误！');
				history.back();
			}
		}
	})();
</script>

  <title>深度网络中的碎碎念 | Jijeng's blog</title>
  








<meta name="generator" content="Hexo 4.2.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jijeng's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/26/%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%A2%8E%E7%A2%8E%E5%BF%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jijeng Jia">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jijeng's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">深度网络中的碎碎念</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-26T10:28:14+08:00">
                2019-03-26
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-12-12T12:00:18+08:00">
                2019-12-12
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/26/%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%A2%8E%E7%A2%8E%E5%BF%B5/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/03/26/深度网络中的碎碎念/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>介绍深度网络中小的基本概念，比如权重初始化、激活函数和优化器 和常见的技术比如 dropout。</p>
<a id="more"></a>

<h2 id="Weights-Initialization"><a href="#Weights-Initialization" class="headerlink" title="Weights Initialization"></a>Weights Initialization</h2><p>weights 的初始化在网络的训练起到重要的作用，初始化的好坏能够直接影响到网络是否可以正常收敛。这里的初始化都是指的是weights初始化。bias 表示偏差，噪声，作用在于企图去描述真实的分布（高斯分布），通过引入随机性来表示这个是具有推广性的。主要介绍常见的三种初始化方法和选择方法。</p>
<blockquote>
<p>Here’s another trick — before squishing our scalar value (called an activation) into the sigmoid function, we can add a little number called the bias, b. There will be two biases, one for each user and one for each movie.</p>
</blockquote>
<h3 id="Random-Initialization"><a href="#Random-Initialization" class="headerlink" title="Random Initialization"></a>Random Initialization</h3><p>总结来说就是容易出现梯度消失和梯度爆炸，尤其是在layer_size（特征数量） 比较大的时候。从均值方差的角度进行分析。</p>
<blockquote>
<p>a) If weights are initialized with very high values the term np.dot(W,X)+becomes significantly higher and if an activation function like sigmoid() is applied, the function maps its value near to 1 where slope of gradient changes slowly and learning takes a lot of time.<br>b) If weights are initialized with low values it gets mapped to 0, where the case is same as above.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w =np.random.randn(layer_size[l],layer_size[l<span class="number">-1</span>])</span><br></pre></td></tr></table></figure>

<p>另外的表述方式：</p>
<blockquote>
<p>If the weights start too small, then the signal shrinks as it passes through each layer until it’s too small to be useful.<br>If the weights start too large, then the signal grows as it passes through each layer until it’s too massive to be useful (big value in sigmoid function).</p>
</blockquote>
<h3 id="Xavier-initialization-ˈzeɪvjər-s"><a href="#Xavier-initialization-ˈzeɪvjər-s" class="headerlink" title="Xavier initialization /ˈzeɪvjər/s"></a>Xavier initialization /ˈzeɪvjər/s</h3><p>For deep networks, we can use a heuristic to initialize the weights depending on the non-linear activation function. This applies to Xavier and He initialization. Xavier/Glorot Initialization initializes the weights in your network by drawing them from a distribution with zero mean and a specific variance.<br>$$ { var } ( w _ { i } ) = \frac { 1 } { layer_{l-1}}$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w=np.random.randn(layer_size[l],layer_size[l<span class="number">-1</span>])*np.sqrt(<span class="number">1</span>/layer_size[l<span class="number">-1</span>])</span><br></pre></td></tr></table></figure>

<p>In practice, it works better for layers with sigmoid or tanh function. </p>
<p>总的思想原则：<br>They set the weights neither too much bigger that 1, nor too much less than 1.<br>就是本来就是在 (0,1) 标准正太分布出来，然后进行了进一步的约束条件。思想当特征数量越大的时候，weights 的波动情况是成反比的，最后的weights 数值越接近于均值附近。</p>
<h3 id="He-Initialization"><a href="#He-Initialization" class="headerlink" title="He Initialization"></a>He Initialization</h3><p>Using RELU or Leaky RELU is relatively robust to the vanishing/ exploding gradient issues compared with sigmoid function especially for networks that are not too deep. And it the case of Leaky RELU, it never has zero gradients. For RELU, we multiply the randomly generated values of $w$ by:</p>
<p>$$\sqrt { \frac { 2 } { layer _ { [ l - 1 ] } } }$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w=np.random.randn(layer_size[l],layer_size[l<span class="number">-1</span>])*np.sqrt(<span class="number">2</span>/layer_size[l<span class="number">-1</span>])</span><br></pre></td></tr></table></figure>
<p>Sometimes, we combine the idea of Xavier initialization and He initializaiton so the variance becomes the following:</p>
<p>$$\sqrt { \frac { 2 } { layer _ { [ l - 1 ] } + \operatorname { layer } _ { [ l ] } } }$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w=np.random.randn(layer_size[l],layer_size[l<span class="number">-1</span>])*np.sqrt(<span class="number">2</span>/(layer_size[l<span class="number">-1</span>]+layer_size[l]))</span><br><span class="line"><span class="comment"># 代码中 random() 中的两个参数是 shape，最后的np.sqrt 标准差</span></span><br></pre></td></tr></table></figure>

<p>The idea behind this is that we set the weights neither too much bigger than 1 nor too much less than 1 so the gradients do not vanish or explode too quickly.</p>
<p>所以上述的初始化从数学的角度去理解： 从(0,1) 标准正太分布 转换成了 (0, np.sqrt(2/ size_l -1)) 这样的分布，就是你网络结构是越宽，那么这个方差就是越小的，最后的结果是越集中的，就越集中的 均值 u 左右。从图像的角度看，方差越大，图像越矮胖；方差越小，图像越瘦高。</p>
<p>** Takeoff**</p>
<p>In summary, the main difference in machine learning is the following:</p>
<ul>
<li>He initialization works better for layers with ReLu(s) activation.</li>
<li>Xavier initialization works better for layers with sigmoid activation.</li>
</ul>
<h2 id="Activation-function"><a href="#Activation-function" class="headerlink" title="Activation function"></a>Activation function</h2><p>总的说可以分为线性和非线性的激活函数， activation function 的作用 就是对于网络的输出 说yes or no. It maps the resulting values in between 0 to 1 or -1 to 1 etc.</p>
<h3 id="Sigmoid-function-Logistic-Activation"><a href="#Sigmoid-function-Logistic-Activation" class="headerlink" title="Sigmoid function (Logistic Activation)"></a>Sigmoid function (Logistic Activation)</h3><p>the only reason why we use sigmoid is because it exists between 0 to 1. 这个非常有利于 predict probability. 因为自然映射到 0 是不存在 然后1 是存在。而当多分类的时候，使用softmax。</p>
<h3 id="Tanh-function"><a href="#Tanh-function" class="headerlink" title="Tanh function"></a>Tanh function</h3><blockquote>
<p>The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.</p>
</blockquote>
<h3 id="Relu-Rectified-Linear-Unit-Activation"><a href="#Relu-Rectified-Linear-Unit-Activation" class="headerlink" title="Relu (Rectified Linear Unit) Activation"></a>Relu (Rectified Linear Unit) Activation</h3><p>本质上是分段函数。 range: [0, infinity]. The function and its derivative both are monotonic.</p>
<h3 id="Leaky-Relu"><a href="#Leaky-Relu" class="headerlink" title="Leaky Relu"></a>Leaky Relu</h3><p>每当一个伟大的东西产出，总会伴随着比较明显的错误，然后紧跟着就是有一个  rectified(improved) 这种版本。这个相比之前就是修正了 当输入是负数的时候，怎么办的问题。</p>
<h3 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h3><p>这个需要从数学的角度去理解，数学公式就是下面。有一个真实的例子： 如果一张”4” 的图片，输出一个网络，最后是softmax 激活函数，那么最后得到的 “4” 的概率是最大的，但是也是有其他的可能性存在的，这个就是softmax 的效果。 最主要的功能是 convert number into probabilities. 这种效果，不像sigmoid 那样有很明确的数学公式。</p>
<p>$$\sigma ( z ) _ { j } = \frac { e ^ { z _ { j } } } { \sum _ { k = 1 } ^ { K } e ^ { z _ { k } } }$$</p>
<blockquote>
<p>Softmax function, a wonderfulactivation function that turns numbers aka logits into probabilities that sum to one.<br>Remember the takeaway is: the essential goal of softmax is to turn numbers into probabilities.</p>
</blockquote>
<h2 id="卷积网络"><a href="#卷积网络" class="headerlink" title="卷积网络"></a>卷积网络</h2><p>一个卷积神经网络由若干卷积层、Pooling层、全连接层组成。</p>
<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>$Input \rightarrow [Conv] \times N \rightarrow [Pool] \times M \rightarrow [FK] \times K$</p>
<p>下面的动画显示了包含两个filter的卷积层的计算。我们可以看到 $7 \times 7 \times 3$ 输入，经过两个$3 \times 3 \times 3 $filter的卷积(步幅为2)，得到了$ 3 \times 3 \times 2 $的输出。另外我们也会看到下图的Zero padding是1，也就是在输入元素的周围补了一圈0。Zero padding对于图像边缘部分的特征提取是很有帮助的。</p>
<p><img src="https://i.bmp.ovh/imgs/2019/06/ed14b5c14cb9fc02.gif" alt=""></p>
<blockquote>
<p>100×100×3，3×3 卷积核，输出是 50×50×10，算进行了多少次乘-加操作？<br>输出的每个像素点都要经过 3×3×3 = 27 次乘-加操作，因此总共需要进行 50×50×10×27 次乘-加操作。</p>
</blockquote>
<p>对于包含两个 $3<em>3</em>3 $的fitler的卷积层来说，其参数数量仅有 $(3 \times 3 \times3+1) \times 2 =56 $个，且参数数量与上一层神经元个数无关。与全连接神经网络相比，其参数数量大大减少了。</p>
<p>卷积层输出大小计算：<br>输入大小： $W 1 \times H 1 \times D 1$<br>超参数（filter信息 +是否填充）： filter 个数( K), filter 大小( F), 步长 (S )，边界填充( P)<br>输出：<br>$$<br>\begin{split}<br>W _ { 2 } &amp; = \left( W _ { 1 } - F + 2 P \right) / S + 1 \\<br>H _ { 2 } &amp;= \left( H _ { 1 } - F + 2 P \right) / S + 1 \\<br>D _ { 2 } &amp;= K<br>\end{split}<br>$$</p>
<p>注意计算的是宽和高的两个维度。</p>
<p>$$<br>\begin{split}<br>\text {output} _ { w } &amp;= \left\lfloor \frac { i m a g e _ { w } + 2 p a d d i n g - k e r n e l _ { s i z e } } { s t r i d e } \right\rfloor + 1 \\<br>\text {output} _ { h } &amp;= \left\lfloor \frac { i m a g e _ { h } + 2 p a d d i n g - k e r n e l _ { s i z e } } { s t r i d e } \right\rfloor + 1 \\<br>\end{split}<br>$$<br>卷积层参数量计算：</p>
<p>权值共享： 给定一张图，用一个 filter 去扫描这张图， filter 里面的数字叫做权重，这张图么个位置是被同样的filter 扫描的，所以权重是一样的，也就是共享。（从减少参数量的角度去理解）这个概念是和全连接层中的权值进行比较的，简单来说就是降低了权重的使用。权重共享即 filter 值的共享。<br>对于 三维图片来说，每个filter需要F<em>F</em>D1个权重值，总共K个filter，需要F<em>F</em>D1*K权重值。和一维一样，整个滑动过程中filter W0和W1值保持不变，可称作权值共享。而且，补充一句，对于三维的input，权值只是在input的每个depth slice上共享的。对于一层的 filter 只是有一个bias。</p>
<p>for example:<br>Filter个数：32<br>原始图像shape：$224 \times 224 \times 3$<br>卷积核大小为：$2 \times 2$<br>一个卷积核的参数：<br>$ 2 \times 2 \times 3=12 $<br>16个卷积核的参数总额：<br>$ 16 \times 12 + 16 =192 + 16 = 208 $<br>$ weight \times x + bias $根据这个公式，即可算的最终的参数总额为：208</p>
<h3 id="Pooling-层"><a href="#Pooling-层" class="headerlink" title="Pooling 层"></a>Pooling 层</h3><p>Pooling层主要的作用是下采样，主要有两点作用，一个是提取重要特征，一个是简化网络的计算。Pooling的方法很多，最常用的是Max Pooling。Max Pooling实际上就是在n*n的样本中取最大值，作为采样后的样本值。下图是 max pooling：</p>
<p><img src="https://upload.cc/i1/2019/06/20/cMRW62.jpg" alt=""><br>除了Max Pooing之外，常用的还有Mean Pooling——取各样本的平均值。</p>
<p>池化层往往在卷积层后面，通过池化来降低卷积层输出的特征向量，同时改善结果（不易出现过拟合）。</p>
<p>池化层参数个数计算，并且池化层明显是没有参数的。</p>
<p>卷积特征往往对应某个局部的特征。要得到global的特征需要将全局的特征执行一个aggregation（聚合）。池化就是这样一个操作，对于每个卷积通道，将更大尺寸（甚至是global）上的卷积特征进行pooling就可以得到更有全局性的特征。这里的pooling当然就对应了cross region。</p>
<h3 id="卷积层-vs-pooling-层"><a href="#卷积层-vs-pooling-层" class="headerlink" title="卷积层 vs pooling 层"></a>卷积层 vs pooling 层</h3><p>主要比较两者在降维、特征提取方面的差别。</p>
<p>pooling 层常见的 max pooling 和 average (mean ) pooling两种。该层是没有参数的。 pooling 的作用主要体现在减少模型去拟合的难度，防止过拟合，节省计算力方面。<br>max pooling 相比于 mean pooling 更加有 提取特征的感觉。抓住比计较显著的特征，AVE pooling 可以带来一定意义上的平滑，可以减小图像尺寸变化的干扰。从效果上讲，前者一半是要好于后者的。</p>
<p><img src="https://b2.bmp.ovh/imgs/2019/07/d95ac0845ef9211a.png" alt=""><br>从上面左图可以看到，使用了pool操作其实就是降低图片的空间尺寸。右图使用一个 2 × 2的 池化核（filter），以2为步长（stride），对图片进行max pooling，那么会图片就会尺寸就会减小一半。需要注意，这里是因为 stride = 2，所以图片尺寸才会减少一半的。</p>
<p>不同点：<br>pooling 是没有 weights 或者 parameter 更新，仅仅是下采样<br>convolution layer 则不一样，提取了特征并且进行了下采样。</p>
<h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>连接所有的特征，将输出值送给分类器（如softmax分类器）</p>
<p>比如说上一层（池化层）的输出为：$(111 \times 111 \times 16) $，从第一层到第二层，只是图片大小发生了变化，深度没有发生变化，而Dense对应的神经元个数为133个，那么还是根据公式：$weight \times x + bias$，计算得：$133 \times16+133=2261$</p>
<h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><p>** 概念**</p>
<p>dropout 是指在深度学习网络的训练过程中，按照一定的概率将一部分神经网络单元暂时从网络中丢弃，相当于从原始的网络中找到一个更瘦的网络。</p>
<p>** why**</p>
<p>我们在训练神经网络的时候，会遇到两大缺点：</p>
<ul>
<li>容易过拟合</li>
<li>费时</li>
</ul>
<p>dropout 主要是为了在一定程度上减少过拟合。</p>
<p>** 工作原理**</p>
<ul>
<li>首先随机（临时）删掉网络中一半的隐藏神经元，输入输出神经元保持不变（图中虚线为部分临时被删除的神经元）</li>
<li>然后把输入x通过修改后的网络前向传播，然后把得到的损失结果通过修改的网络反向传播。一小批训练样本执行完这个过程后，在没有被删除的神经元上按照随机梯度下降法更新对应的参数（w，b）</li>
<li>继续重复这一过程：恢复被删掉的神经元（此时被删除的神经元保持原样，而没有被删除的神经元已经有所更新）。从隐藏层神经元中随机选择一个一半大小的子集临时删除掉（备份被删除神经元的参数）。</li>
<li>不断的重复着一过程</li>
</ul>
<p>*<em>怎么理解测试时权重参数w要乘以概率p？ *</em></p>
<p> 假设总共有100个神经元，训练的时候我们加上dropout，p=0.5，那么我们就有50个神经元参与训练，那么我们每次50个神经元训练出来的模型参数w是要比直接100个神经元要小的，因为它更新的次数会更少。我们测试的时候100个神经元是都会参与计算的，这就跟训练的时候我们使用50个神经元产生差异了，如果要保证测试的时候每个神经元的关联计算不能少，只能从通过改变w来达到跟训练时一样输出，所以才会有权重参数w乘以p。</p>
<p>** 为什么 dropout 可以有效的减少过拟合？**<br>（类似取平均的活动）<br>因为不同的网络可能产生不同的过拟合，取平均则有可能让一些“相反的”拟合互相抵消。dropout掉不同的隐藏神经元就类似在训练不同的网络，随机删掉一半隐藏神经元导致网络结构已经不同，整个dropout过程就相当于对很多个不同的神经网络取平均。</p>
<h3 id="梯度消失-梯度爆炸"><a href="#梯度消失-梯度爆炸" class="headerlink" title="梯度消失/ 梯度爆炸"></a>梯度消失/ 梯度爆炸</h3><p> 首先一个观点，梯度消失和梯度爆炸本质上一回事。</p>
<p> 理由：sigmoid 导数的最大值为0.25，通常 abs(w) &lt; 1,则上述分析中的激活函数的导数与权重的积小于0.25，前面的层比后面的层梯度变化更小，故变化更慢，从而引起了梯度消失问题。当权值过大，前面层比后面层梯度变化更快，则引起梯度爆炸问题。所以后面的梯度消失和梯度爆炸只是前面初始化值的一种蝴蝶效应，只是数值问题。</p>
<p> ** 解决方法**</p>
<ol>
<li>重新设计网络结构</li>
</ol>
<ul>
<li>使用比较浅的网络结构</li>
<li>使用残差结构, 这种方式在图像处理中更加常见</li>
</ul>
<ol start="2">
<li><p>激活函数<br>使用 relu or leaky relu 而不是 sigmoid or tanh</p>
</li>
<li><p>关于weights 方面</p>
</li>
</ol>
<ul>
<li>使用梯度截断（Gradient Clipping），检查误差梯度的值是否超过阈值，如果超过，则截断梯度，将梯度设置为阈值。</li>
<li>使用权重正则化（Weight Regularization），常用的是 ，通常使用的是 L1 惩罚项（权重绝对值）或 L2 惩罚项（权重平方）这个是在损失函数上的操作</li>
<li>batch normalization  （关于BN 的位置是可以再查一下的，现在有两个位置，一个是在激活函数之前一个是 激活函数之后，个人倾向于激活函数之前，因为这样才有可以减少梯度消失和梯度爆炸的发生呀）  dropout一定在激活函数之后</li>
</ul>
<p>ps:</p>
<p>CONV / FC - &gt; BatchNorm - &gt; ReLu（或其他激活） - &gt; Dropout - &gt; CONV / FC<br>对于 cnn 还有一种常见的结构：<br>先卷积，再batchnorm, 然后激活函数，最后pooling<br>在fully connection中的应用，用在全连接层之后激活函数之前</p>
<p> ** 理解 正则化如何减少模型过拟合程度**</p>
<p> High Bias（高偏差）就是欠拟合，High Variance（高方差）就是过拟合。<br> <img src="https://i.bmp.ovh/imgs/2019/07/619bdec3f9b8bffb.png" alt=""></p>
<p> 简单来说，正则化就是在原来的 cost function 中添加 正则项。</p>
<p> 正则化项能减少模型的非线性程度，从而降低模型的过拟合。从图中来看，正则化项能将过拟合的模型（蓝色）变为Just Right的模型（粉红色）。</p>
<p> 为什么正则化是有效的？</p>
<p> 对于线性模型，其添加了正则化项的Cost Function如下图。<br> <img src="https://i.bmp.ovh/imgs/2019/07/2ce4806231a16edb.png" alt=""></p>
<p>现在目标函数有两个目标，第一个是我们想要训练的，使假设更好地去拟合训练数据，第二个目标是我们想要保持参数较小。 $ \lambda$ 用来调节两者之间的平衡，这样理解如果 该值设置的很大，那么前面的参数 $\theta 1 \theta 2 \theta 3 \theta 4$ 就会被非常大的惩罚，这些值就会接近0。如果假设第一个目标是多项式组成的，那么当 $\theta $ 数值变小的时候，这个式子就没有了，就减少了模型的复杂度。</p>
<p> 对于神经网络，其激活函数（以tanh为例）如下图<br> <img src="https://upload.cc/i1/2019/07/11/1yQFLb.png" alt=""></p>
<p>直观的理解，如果我们的正则化系数（lambda）无穷大，则权重w就会趋近于0。权重变小，激活函数输出z变小。z变小，就到了激活函数的线性区域，从而降低了模型的非线性化程度。</p>
<h3 id="感受野的计算"><a href="#感受野的计算" class="headerlink" title="感受野的计算"></a>感受野的计算</h3><p>在卷积神经网络中，感受野（Receptive Field）的定义是卷积神经网络每一层输出的特征图（feature map）上的像素点在输入图片上映射的区域大小。</p>
<p>这个是一个反向的过程。这个和 CNN 的 不同在于，如果是2  两层，那么这个是连续（持续）的对同一个图像进行采样。接着上一个的结果进行操作。</p>
<p>使用例子说明：两层$3 \times 3$ 卷积操作的有效区域(感受野)是 $5  \times 5 $ (所有filter的stride=1,pad=0)。</p>
<p><img src="https://upload.cc/i1/2019/07/31/srRb1v.png" alt=""></p>
<h3 id="卷积和池化操作的计算（例题）"><a href="#卷积和池化操作的计算（例题）" class="headerlink" title="卷积和池化操作的计算（例题）"></a>卷积和池化操作的计算（例题）</h3><p>卷积和池化的计算方式是一样的，具体可以参考上面小结关于卷积操作的公式。</p>
<blockquote>
<p>输入图片大小为200×200，依次经过一层卷积（kernel size 5×5，padding 1，stride 2），pooling（kernel size 3×3，padding 0，stride 1），又一层卷积（kernel size 3×3，padding 1，stride 1）之后，输出特征图大小为：<br>A. 95<br>B. 96<br>C. 97<br>D. 98<br>E. 99<br>F. 100</p>
</blockquote>
<p>解答：</p>
<p>第一次卷积后大小：<br>$$<br>\frac { 200 + 2 - 5 } { 2 } + 1 = 99<br>$$</p>
<p>第一次池化后大小：</p>
<p>$$<br>\frac { 99 + 0 - 3 } { 1 } + 1 = 97<br>$$</p>
<p>第二次卷积后大小：</p>
<p>$$<br>\frac { 97 + 2 - 3 } { 1 } + 1 = 97<br>$$</p>
<p>所以最后的结果是 97</p>
<h3 id="为什么使用奇数小尺寸的卷积核"><a href="#为什么使用奇数小尺寸的卷积核" class="headerlink" title="为什么使用奇数小尺寸的卷积核"></a>为什么使用奇数小尺寸的卷积核</h3><blockquote>
<p>For an odd-sized filter, all the previous layer pixels would be symmetrically around the output pixel. Without this symmetry, we will have to account for distortions across the layers which happens when using an even sized kernel. Therefore, even sized kernel filters are mostly skipped to promote implementation simplicity.<br>选择奇数个数的filter 是因为前后的filter 是有对称性的。下图所示。</p>
</blockquote>
<img src="https://ftp.bmp.ovh/imgs/2019/12/a730dba1a8f29659.png" width="80%" height="60%">


<p>$3x3$ 是最小的能够捕获像素八邻域信息的尺寸。</p>
<p>1). 参数量<br>多个 $3x3 $的卷积层比一个大尺寸的 filter 有更少的参数，假设卷基层的输入和输出的特征图大小相同为$ C$，那么三个 $3x3$ 的卷积层参数个数 $3x（3x3xCxC）=27C^2$；一个$7x7 $的卷积层参数为 $49C^2$；所以可以把三个 $3x3 $的filter看成是一个$7x7 $filter的分解。<br>2). 增加非线性<br>多个 $3x3 $的卷基层比一个大尺寸 filter卷基层有更多的非线性（更多层的非线性函数），使得判决函数更加具有判决性。</p>
<h3 id="1-1-的卷积核特点"><a href="#1-1-的卷积核特点" class="headerlink" title="$1 * 1$的卷积核特点"></a>$1 * 1$的卷积核特点</h3><p>1). 降维/升维</p>
<p>2). 增加非线性</p>
<p>$1 *1 $卷积核，可以在保持feature map尺度不变的（即不损失分辨率）的前提下大幅增加非线性特性（利用后接的非线性激活函数），把网络做的很deep。</p>
<p>3). 从全连接层的角度理解 $1 * 1$卷积操作</p>
<img src="https://upload.cc/i1/2019/12/12/PHKs1c.png" width="60%" height="40%">


<p>左边6个神经元，分别是a1—a6，通过全连接之后变成5个，分别是b1—b5</p>
<p>左边6个神经元相当于输入特征里面的channels：6</p>
<p>右边5个神经元相当于$1 *1$卷积之后的新的特征channels：5</p>
<p>左边 $W *H *6$ 经过 $1 *1 *5 $的卷积核就能实现全连接</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/03/26/siamese-network/" rel="next" title="siamese network">
                <i class="fa fa-chevron-left"></i> siamese network
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/04/05/data_structure/" rel="prev" title="Data Structure">
                Data Structure <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpeg"
                alt="Jijeng Jia" />
            
              <p class="site-author-name" itemprop="name">Jijeng Jia</p>
              <p class="site-description motion-element" itemprop="description">Solving Problems by Coding</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%20%7C%7C%20archive">
              
                  <span class="site-state-item-count">168</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">83</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/jijeng" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:jia1509309698@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          <script type="text/javascript" src="//rf.revolvermaps.com/0/0/5.js?i=5kk0u0mm50w&amp;m=0&amp;c=54ff00&amp;cr1=ff0000" async="async"></script>


        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Weights-Initialization"><span class="nav-number">1.</span> <span class="nav-text">Weights Initialization</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Random-Initialization"><span class="nav-number">1.1.</span> <span class="nav-text">Random Initialization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Xavier-initialization-ˈzeɪvjər-s"><span class="nav-number">1.2.</span> <span class="nav-text">Xavier initialization &#x2F;ˈzeɪvjər&#x2F;s</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#He-Initialization"><span class="nav-number">1.3.</span> <span class="nav-text">He Initialization</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Activation-function"><span class="nav-number">2.</span> <span class="nav-text">Activation function</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Sigmoid-function-Logistic-Activation"><span class="nav-number">2.1.</span> <span class="nav-text">Sigmoid function (Logistic Activation)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tanh-function"><span class="nav-number">2.2.</span> <span class="nav-text">Tanh function</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Relu-Rectified-Linear-Unit-Activation"><span class="nav-number">2.3.</span> <span class="nav-text">Relu (Rectified Linear Unit) Activation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Leaky-Relu"><span class="nav-number">2.4.</span> <span class="nav-text">Leaky Relu</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Softmax"><span class="nav-number">2.5.</span> <span class="nav-text">Softmax</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#卷积网络"><span class="nav-number">3.</span> <span class="nav-text">卷积网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#卷积层"><span class="nav-number">3.1.</span> <span class="nav-text">卷积层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pooling-层"><span class="nav-number">3.2.</span> <span class="nav-text">Pooling 层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#卷积层-vs-pooling-层"><span class="nav-number">3.3.</span> <span class="nav-text">卷积层 vs pooling 层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#全连接层"><span class="nav-number">3.4.</span> <span class="nav-text">全连接层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dropout"><span class="nav-number">3.5.</span> <span class="nav-text">Dropout</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度消失-梯度爆炸"><span class="nav-number">3.6.</span> <span class="nav-text">梯度消失&#x2F; 梯度爆炸</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#感受野的计算"><span class="nav-number">3.7.</span> <span class="nav-text">感受野的计算</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#卷积和池化操作的计算（例题）"><span class="nav-number">3.8.</span> <span class="nav-text">卷积和池化操作的计算（例题）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么使用奇数小尺寸的卷积核"><span class="nav-number">3.9.</span> <span class="nav-text">为什么使用奇数小尺寸的卷积核</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-的卷积核特点"><span class="nav-number">3.10.</span> <span class="nav-text">$1 * 1$的卷积核特点</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jijeng Jia</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>

<div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
Total  <span id="busuanzi_value_site_pv"></span> views
You got  <span id="busuanzi_value_site_uv"></span> visitors
</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://https-jijeng-github-io.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2019/03/26/%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%A2%8E%E7%A2%8E%E5%BF%B5/';
          this.page.identifier = '2019/03/26/深度网络中的碎碎念/';
          this.page.title = '深度网络中的碎碎念';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://https-jijeng-github-io.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  















  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('10');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
