<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="nlp è®ºæ–‡é˜…è¯»ç¬”è®°, éšæ—¶ updateâ€¦ attention is all you needSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a repre">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP Papers Reading- BERT">
<meta property="og:url" content="http://yoursite.com/2019/05/27/paper-reading-nlp/index.html">
<meta property="og:site_name" content="Jijeng&#39;s blog">
<meta property="og:description" content="nlp è®ºæ–‡é˜…è¯»ç¬”è®°, éšæ—¶ updateâ€¦ attention is all you needSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a repre">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3env74i1dj20rs0f8dge.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3enz4w1tmj21bu0r0q6v.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eo6o8obxj20l00d6wee.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eo7eiu73j20rs0i342d.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3enq6lqouj20uq0eoq4u.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3ep38emyqj20bl03o3zj.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3ftfz3uxij206e088aa2.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eobewbqoj20c50bhq4y.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eof674adj20ii0dfgoe.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3dvg2o3wwj20qo0grdgp.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3dw277xiyj20pi0c10ww.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eqwkv9tlj20kd097gm4.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eqyoxmknj20ey0d640u.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3esxw2nilj20dh08ujth.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3fub67ulaj20u20h3wfx.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3fubpu9ibj20li0m1q5b.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3fuc693mrj211z0hbjur.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3fuci4xodj213j0kitcq.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3flokoc0mj20ab07474a.jpg">
<meta property="og:updated_time" content="2019-06-01T08:32:40.833Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="NLP Papers Reading- BERT">
<meta name="twitter:description" content="nlp è®ºæ–‡é˜…è¯»ç¬”è®°, éšæ—¶ updateâ€¦ attention is all you needSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a repre">
<meta name="twitter:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3env74i1dj20rs0f8dge.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/05/27/paper-reading-nlp/"/>





  <title>NLP Papers Reading- BERT | Jijeng's blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jijeng's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/05/27/paper-reading-nlp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jijeng Jia">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jijeng's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">NLP Papers Reading- BERT</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-27T14:13:14+08:00">
                2019-05-27
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-06-01T16:32:40+08:00">
                2019-06-01
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/05/27/paper-reading-nlp/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/05/27/paper-reading-nlp/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>nlp è®ºæ–‡é˜…è¯»ç¬”è®°, éšæ—¶ updateâ€¦</p>
<h2 id="attention-is-all-you-need"><a href="#attention-is-all-you-need" class="headerlink" title="attention is all you need"></a>attention is all you need</h2><p>Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.</p>
<p>An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The ouput is computed as a weighted sum of the values, where the weight assigned to each value is computed cy a compatibility function of the query with the corresponding key.</p>
<p>ä¸­æ–‡çš„ç†è§£ï¼š<br>æ·±åº¦å­¦ä¹ é‡Œçš„Attentionmodelå…¶å®æ¨¡æ‹Ÿçš„æ˜¯äººè„‘çš„æ³¨æ„åŠ›æ¨¡å‹ï¼Œä¸¾ä¸ªä¾‹å­æ¥è¯´ï¼Œå½“æˆ‘ä»¬è§‚èµä¸€å¹…ç”»æ—¶ï¼Œè™½ç„¶æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ•´å¹…ç”»çš„å…¨è²Œï¼Œä½†æ˜¯åœ¨æˆ‘ä»¬æ·±å…¥ä»”ç»†åœ°è§‚å¯Ÿæ—¶ï¼Œå…¶å®çœ¼ç›èšç„¦çš„å°±åªæœ‰å¾ˆå°çš„ä¸€å—ï¼Œè¿™ä¸ªæ—¶å€™äººçš„å¤§è„‘ä¸»è¦å…³æ³¨åœ¨è¿™ä¸€å°å—å›¾æ¡ˆä¸Šï¼Œä¹Ÿå°±æ˜¯è¯´è¿™ä¸ªæ—¶å€™äººè„‘å¯¹æ•´å¹…å›¾çš„å…³æ³¨å¹¶ä¸æ˜¯å‡è¡¡çš„ï¼Œæ˜¯æœ‰ä¸€å®šçš„æƒé‡åŒºåˆ†çš„ã€‚è¿™å°±æ˜¯æ·±åº¦å­¦ä¹ é‡Œçš„AttentionModelçš„æ ¸å¿ƒæ€æƒ³ã€‚æ‰€è°“æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°±æ˜¯è¯´åœ¨ç”Ÿæˆæ¯ä¸ªè¯çš„æ—¶å€™ï¼Œå¯¹ä¸åŒçš„è¾“å…¥è¯ç»™äºˆä¸åŒçš„å…³æ³¨æƒé‡ã€‚é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶ï¼Œæˆ‘ä»¬å°†è¾“å…¥å¥å­ç¼–ç ä¸ºä¸€ä¸ªå‘é‡åºåˆ—ï¼Œå¹¶è‡ªé€‚åº”åœ°é€‰æ‹©è¿™äº›å‘é‡çš„ä¸€ä¸ªå­é›†ï¼ŒåŒæ—¶å¯¹è¯‘æ–‡è¿›è¡Œè¯‘ç ï¼Œä¾‹å¦‚where are youâ€”â€”&gt;ä½ åœ¨å“ªï¼Ÿç°åœ¨æˆ‘ä»¬åœ¨ç¿»è¯‘â€œä½ â€çš„æ—¶å€™ç»™â€youâ€æ›´å¤šçš„æƒé‡ï¼Œé‚£ä¹ˆå°±å¯ä»¥æœ‰æ•ˆçš„è§£å†³å¯¹é½é—®é¢˜ã€‚</p>
<p>Background:</p>
<p>ä¸»è¦æ˜¯é¢ä¸´çš„ä¸‰ä¸ªé—®é¢˜ã€‚<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3env74i1dj20rs0f8dge.jpg" alt=""></p>
<p>Model:<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3enz4w1tmj21bu0r0q6v.jpg" alt=""></p>
<p>Encoder: encoderç”±6ä¸ªç›¸åŒçš„å±‚å †å è€Œæˆï¼Œæ¯ä¸ªå±‚æœ‰ä¸¤ä¸ªå­å±‚ã€‚ç¬¬ä¸€ä¸ªå­å±‚æ˜¯å¤šå¤´è‡ªæˆ‘æ³¨æ„åŠ›æœºåˆ¶(multi-head self-attention mechanism)ï¼Œç¬¬äºŒå±‚æ˜¯ç®€å•çš„ä½ç½®çš„å…¨è¿æ¥å‰é¦ˆç½‘ç»œ(position-wise fully connected feed-forward network)ã€‚åœ¨ä¸¤ä¸ªå­å±‚ä¸­ä¼šä½¿ç”¨ä¸€ä¸ªæ®‹å·®è¿æ¥ï¼Œæ¥ç€è¿›è¡Œå±‚æ ‡å‡†åŒ–(layer normalization)ã€‚ä¹Ÿå°±æ˜¯è¯´æ¯ä¸€ä¸ªå­å±‚çš„è¾“å‡ºéƒ½æ˜¯LayerNorm(x + sublayer(x))ã€‚ç½‘ç»œè¾“å…¥æ˜¯ä¸‰ä¸ªç›¸åŒçš„å‘é‡q, kå’Œvï¼Œæ˜¯word embeddingå’Œposition embeddingç›¸åŠ å¾—åˆ°çš„ç»“æœã€‚ä¸ºäº†æ–¹ä¾¿è¿›è¡Œæ®‹å·®è¿æ¥ï¼Œæˆ‘ä»¬éœ€è¦å­å±‚çš„è¾“å‡ºå’Œè¾“å…¥éƒ½æ˜¯ç›¸åŒçš„ç»´åº¦ã€‚</p>
<p>Decoder: decoderä¹Ÿæ˜¯ç”±Nï¼ˆN=6ï¼‰ä¸ªå®Œå…¨ç›¸åŒçš„Layerç»„æˆï¼Œdecoderä¸­çš„Layerç”±encoderçš„Layerä¸­æ’å…¥ä¸€ä¸ªMulti-Head Attention + Add&amp;Normç»„æˆã€‚è¾“å‡ºçš„embeddingä¸è¾“å‡ºçš„position embeddingæ±‚å’Œåšä¸ºdecoderçš„è¾“å…¥ï¼Œç»è¿‡ä¸€ä¸ªMulti-HeadAttention + Add&amp;Normï¼ˆï¼ˆMA-1ï¼‰å±‚ï¼ŒMA-1å±‚çš„è¾“å‡ºåšä¸ºä¸‹ä¸€Multi-Head Attention + Add&amp;Normï¼ˆMA-2ï¼‰çš„queryï¼ˆQï¼‰è¾“å…¥ï¼ŒMA-2å±‚çš„Keyå’ŒValueè¾“å…¥ï¼ˆä»å›¾ä¸­çœ‹ï¼Œåº”è¯¥æ˜¯encoderä¸­ç¬¬iï¼ˆi = 1,2,3,4,5,6ï¼‰å±‚çš„è¾“å‡ºå¯¹äºdecoderä¸­ç¬¬iï¼ˆi = 1,2,3,4ï¼Œ5,6ï¼‰å±‚çš„è¾“å…¥ï¼‰ã€‚MA-2å±‚çš„è¾“å‡ºè¾“å…¥åˆ°ä¸€ä¸ªå‰é¦ˆå±‚ï¼ˆFFï¼‰ï¼Œç»è¿‡ANæ“ä½œåï¼Œç»è¿‡ä¸€ä¸ªçº¿æ€§+softmaxå˜æ¢å¾—åˆ°æœ€åç›®æ ‡è¾“å‡ºçš„æ¦‚ç‡ã€‚<br> å¯¹äºdecoderä¸­çš„ç¬¬ä¸€ä¸ªå¤šå¤´æ³¨æ„åŠ›å­å±‚ï¼Œéœ€è¦æ·»åŠ maskingï¼Œç¡®ä¿é¢„æµ‹ä½ç½®içš„æ—¶å€™ä»…ä»…ä¾èµ–äºä½ç½®å°äºiçš„è¾“å‡ºã€‚<br> å±‚ä¸å±‚ä¹‹é—´ä½¿ç”¨çš„Position-wise feed forward networkã€‚</p>
<p> ä»æ•´ä½“ä¸Šæ¥çœ‹ï¼ŒTransformerä¾æ—§æ˜¯ä¸€ä¸ªâ€œSequence to Sequenceâ€æ¡†æ¶ï¼Œæ‹¥æœ‰Encoderå’ŒDecoderä¸¤éƒ¨åˆ†ï¼š</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eo6o8obxj20l00d6wee.jpg" alt=""></p>
<p>Transformerçš„Encoderå…¶å®æœ‰6å±‚ï¼ŒDecoderä¹Ÿæœ‰6å±‚ï¼Œä»Encoderçš„è§’åº¦ï¼Œä½å±‚çš„Encoderæ˜¯è¡¨å±‚çš„è¯æ³•ä¿¡æ¯ï¼Œé€æ­¥å‘ä¸Šè¿›è¡ŒæŠ½è±¡ä¹‹åï¼Œåœ¨ä¸Šå±‚å°†è¡¨ç¤ºæŠ½è±¡è¯­ä¹‰ä¿¡æ¯ã€‚Encoderéƒ¨åˆ†è¿˜åœ¨æœ€ä¸Šå±‚è¿äº†å‡ æ¡çº¿åˆ°æ¯ä¸ªDecoderçš„éƒ¨åˆ†ï¼Œè¿™æ˜¯ä¸ºäº†åœ¨Decoderä¸­è¿›è¡ŒAttentionæ“ä½œï¼ŒDecoderçš„ç½‘ç»œä¸­å’ŒEncoderä¹Ÿæœ‰ä¿¡æ¯ä¼ é€’å’Œäº¤äº’çš„ã€‚æœ€åä¸€ä¸ªç‰¹ç‚¹æ˜¯Decoderå’ŒEncoderç”»çš„å¤§å°æ˜¯ä¸€æ ·çš„ï¼Œå› ä¸ºå®ƒä»¬å±‚çš„ç»´åº¦å¤§å°æ˜¯ä¸€æ ·çš„ã€‚</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eo7eiu73j20rs0i342d.jpg" alt=""></p>
<p>ä¹Ÿå°±æ˜¯è¯´encoderçš„è¾“å‡ºï¼Œä¼šå’Œæ¯ä¸€å±‚çš„decoderè¿›è¡Œç»“åˆã€‚<br>Encoderå’ŒDecoderçš„å†…éƒ¨ç»“æ„ï¼š<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3enq6lqouj20uq0eoq4u.jpg" alt=""></p>
<p>æ¨¡å‹çš„ç‰¹ç‚¹ï¼š<br>Positional embeddingï¼›ï¼ˆä½ç½®åµŒå…¥å‘é‡â€”â€”å…¶å®ç±»ä¼¼word2vecï¼Œå¤„ç†çš„è¯­åºçš„ä¿¡æ¯ï¼‰ã€‚<br>multi-head attention; (å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶â€”â€”ç‚¹ä¹˜æ³¨æ„åŠ›çš„å‡çº§ç‰ˆæœ¬ï¼Œ è¿™ä¸ªå°±ç±»ä¼¼ensembleçš„æ€æƒ³ï¼Œä¸åŒçš„å­ç©ºé—´çš„attention è¿›è¡Œèåˆï¼‰<br>Position-wise Feed-Forward Networksï¼ˆä½ç½®å…¨é“¾æ¥å‰é¦ˆç½‘ç»œâ€”â€”MLPå˜å½¢ï¼‰</p>
<p>æœ‰ä¸¤ç§å¸¸ç”¨çš„æ³¨æ„åŠ›å‡½æ•°ï¼Œä¸€ç§æ˜¯åŠ æ³•æ³¨æ„åŠ›(additive attention)ï¼Œå¦å¤–ä¸€ç§æ˜¯ç‚¹ä¹˜æ³¨æ„åŠ›(dot-productattention)ï¼Œè®ºæ–‡æ‰€é‡‡ç”¨çš„å°±æ˜¯ç‚¹ä¹˜æ³¨æ„åŠ›ï¼Œè¿™ç§æ³¨æ„åŠ›æœºåˆ¶å¯¹äºåŠ æ³•æ³¨æ„åŠ›è€Œè¨€ï¼Œæ›´å¿«ï¼ŒåŒæ—¶æ›´èŠ‚çœç©ºé—´ã€‚</p>
<p>åŠ æ³•æ³¨æ„åŠ›<br>è¿˜æ˜¯ä»¥ä¼ ç»Ÿçš„RNNçš„seq2seqé—®é¢˜ä¸ºä¾‹å­ï¼ŒåŠ æ€§æ³¨æ„åŠ›æ˜¯æœ€ç»å…¸çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ƒä½¿ç”¨äº†æœ‰ä¸€ä¸ªéšè—å±‚çš„å‰é¦ˆç½‘ç»œï¼ˆå…¨è¿æ¥ï¼‰æ¥è®¡ç®—æ³¨æ„åŠ›åˆ†é…ï¼š<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3ep38emyqj20bl03o3zj.jpg" alt=""></p>
<p>å…¬å¼:<br>$$<br>\alpha _ { i j } = \frac { \exp \left( e _ { i j } \right) } { \sum _ { k = 1 } ^ { L } e _ { i k } }<br>$$</p>
<p>Scaled Dot-Product<br>è¿™ç¯‡è®ºæ–‡è®¡ç®—queryå’Œkeyç›¸ä¼¼åº¦ä½¿ç”¨äº†dot-product attentionï¼Œå³queryå’Œkeyè¿›è¡Œç‚¹ä¹˜ï¼ˆå†…ç§¯ï¼‰æ¥è®¡ç®—ç›¸ä¼¼åº¦ã€‚<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3ftfz3uxij206e088aa2.jpg" alt=""></p>
<p>Multi-Head Attention:</p>
<p>åœ¨å®é™…ä¸­ä¸ºäº†å¹¶è¡Œè®¡ç®—ï¼Œå¯ä»¥åœ¨ä¸€ç»„queriesä¸Šè®¡ç®—æ³¨æ„åŠ›å‡½æ•°ï¼Œå°†å¤šä¸ªqueryå †å æˆQï¼ŒåŒç†keyså’Œvaluesä¹Ÿè¢«å †å æˆKå’ŒVï¼Œé€šè¿‡ä¸‹é¢çš„å…¬å¼æ¥è®¡ç®—çŸ©é˜µè¾“å‡º:<br>self-attention æ¨¡å‹å°±æ˜¯è‡ªå·±å¯¹è‡ªå·±æ±‚attentionï¼Œå³ğ‘„=ğ¾=ğ‘‰<br>$$<br>\text { Attention } ( Q , K , V ) = \operatorname { softmax } \left( \frac { Q K ^ { T } } { \sqrt { d _ { k } } } \right) V<br>$$<br>ä¹‹æ‰€ä»¥ç”¨å†…ç§¯é™¤ä»¥ç»´åº¦çš„å¼€æ–¹ï¼Œè®ºæ–‡ç»™å‡ºçš„è§£é‡Šæ˜¯ï¼šå‡è®¾Qå’ŒKéƒ½æ˜¯ç‹¬ç«‹çš„éšæœºå˜é‡ï¼Œæ»¡è¶³å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼Œåˆ™ç‚¹ä¹˜åç»“æœå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸ºdkã€‚ä¹Ÿå³æ–¹å·®ä¼šéšç»´åº¦dkçš„å¢å¤§è€Œå¢å¤§ï¼Œè€Œå¤§çš„æ–¹å·®å¯¼è‡´æå°çš„æ¢¯åº¦(æˆ‘è®¤ä¸ºå¤§æ–¹å·®å¯¼è‡´æœ‰çš„è¾“å‡ºå•å…ƒaï¼ˆaæ˜¯softmaxçš„ä¸€ä¸ªè¾“å‡ºï¼‰å¾ˆå°ï¼Œsoftmaxåå‘ä¼ æ’­æ¢¯åº¦å°±å¾ˆå°ï¼ˆæ¢¯åº¦å’Œaæœ‰å…³ï¼‰ï¼‰ã€‚ä¸ºäº†é¿å…è¿™ç§å¤§æ–¹å·®å¸¦æ¥çš„è®­ç»ƒé—®é¢˜ï¼Œè®ºæ–‡ä¸­ç”¨å†…ç§¯é™¤ä»¥ç»´åº¦çš„å¼€æ–¹ï¼Œä½¿ä¹‹å˜ä¸ºå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ã€‚</p>
<p>é™¤äº†è®¡ç®—ä¸€ä¸ªå•ç‹¬çš„æ³¨æ„åŠ›å‡½æ•°ï¼Œè®ºæ–‡æå‡ºå¯¹queriesï¼Œkeyså’Œvaluesåšhæ¬¡ä¸åŒçš„æŠ•å½±, ç„¶åéƒ½ç»è¿‡Scaled Dot-Product Attentionï¼Œå°†ç»“æœæ‹¼æ¥åœ¨ä¸€èµ·ï¼Œæœ€åé€šè¿‡ä¸€ä¸ªçº¿æ€§æ˜ å°„è¾“å‡ºï¼Œé€šè¿‡å¤šå¤´æ³¨æ„åŠ›ï¼Œæ¨¡å‹èƒ½å¤Ÿè·å¾—ä¸åŒå­ç©ºé—´ä¸‹çš„ä½ç½®ä¿¡æ¯ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå…¬å¼å¦‚ä¸‹:<br>$$<br>\text {MultiHead} ( Q , K , V ) =Concat(head_1, head_2, â€¦, head_h)  W ^ { o }$$</p>
<p>Self-Attention<br>é‚£ä¹ˆé¦–å…ˆè¦æ˜ç™½ä»€ä¹ˆæ˜¯Attentionã€‚ä»è¯­è¨€å­¦çš„è§’åº¦ï¼Œå®ƒæ˜¯è¡¨ç¤ºè¯ä¸è¯ä¹‹é—´çš„å…³è”å…³ç³»ï¼Œåƒä¸‹å›¾æ‰€ç¤ºï¼Œè¿™æ˜¯ä¸€ä¸ªSelf-Attentionçš„ç¤ºæ„ï¼Œå®ƒè¿™ä¸ªitä¼šå’Œå…¶ä»–ä½ç½®çš„è¯å‘ç”Ÿå…³ç³»ï¼Œé¢œè‰²è¶Šæ·±çš„æ˜¯è¯´å…³ç³»è¶Šç´§å¯†ï¼Œä»ä¸­å›¾ä¸­çœ‹åˆ°å®ƒå¾ˆæ­£ç¡®çš„å…³è”åˆ°äº†animalå®ƒå®é™…æŒ‡ä»£çš„ä¸€ä¸ªè¯ã€‚<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eobewbqoj20c50bhq4y.jpg" alt=""><br>ä»æœºå™¨å­¦ä¹ çš„è§’åº¦ï¼Œè¿™ä¸ªAttentionæ˜¯ç¥ç»ç½‘ç»œéšå±‚ä¹‹é—´ä¸€ä¸ªç›¸ä¼¼åº¦çš„è¡¨ç¤ºï¼Œä»€ä¹ˆæ˜¯Self-Attentionï¼Ÿå°±æ˜¯è¡¨ç¤ºå¥å­å†…éƒ¨è¯ä¸è¯ä¹‹é—´çš„å…³è”å…³ç³»ï¼Œå°±åƒè¿™é‡Œçš„itåˆ°animalï¼Œå¯ä»¥ç”¨äºæŒ‡ä»£æ¶ˆè§£ç­‰é—®é¢˜ã€‚</p>
<p>Positional Encoding<br>Position Embeddingï¼Œä¹Ÿå°±æ˜¯â€œä½ç½®å‘é‡â€ï¼Œå°†æ¯ä¸ªä½ç½®ç¼–å·ï¼Œç„¶åæ¯ä¸ªç¼–å·å¯¹åº”ä¸€ä¸ªå‘é‡ï¼Œé€šè¿‡ç»“åˆä½ç½®å‘é‡å’Œè¯å‘é‡ï¼Œå°±ç»™æ¯ä¸ªè¯éƒ½å¼•å…¥äº†ä¸€å®šçš„ä½ç½®ä¿¡æ¯ï¼Œè¿™æ ·Attentionå°±å¯ä»¥åˆ†è¾¨å‡ºä¸åŒä½ç½®çš„è¯äº†ã€‚</p>
<p>Residual connectionå’Œlayer-normalization<br>ï¼ˆè¿™ä¸¤ä¸ªæ“ä½œä¸»è¦æ˜¯åº”å¯¹ æ·±åº¦ç½‘ç»œè€Œæå‡ºçš„ï¼‰<br>å¯¹äºå­¦ä¹ CVçš„äººä¼°è®¡å¯¹è¿™ä¸ªç»“æ„ä¸€ç‚¹ä¹Ÿä¸é™Œç”Ÿï¼ŒResidual connectionæ˜¯å¯¹äºè¾ƒä¸ºæ·±å±‚çš„ç¥ç»ç½‘ç»œæœ‰æ¯”è¾ƒå¥½çš„ä½œç”¨ï¼Œæ¯”å¦‚ç½‘ç»œå±‚å¾ˆæ·±æ—¶ï¼Œæ•°å€¼çš„ä¼ æ’­éšç€weightä¸æ–­çš„å‡å¼±ï¼ŒResidual connectionæ˜¯ä»è¾“å…¥çš„éƒ¨åˆ†ï¼Œå°±æ˜¯å›¾ä¸­è™šçº¿çš„éƒ¨åˆ†ï¼Œå®é™…è¿åˆ°å®ƒè¾“å‡ºå±‚çš„éƒ¨åˆ†ï¼ŒæŠŠè¾“å…¥çš„ä¿¡æ¯åŸå°ä¸åŠ¨copyåˆ°è¾“å‡ºçš„éƒ¨åˆ†ï¼Œå‡å°‘ä¿¡æ¯çš„æŸå¤±ã€‚</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eof674adj20ii0dfgoe.jpg" alt=""><br>layer-normalizationè¿™ç§å½’ä¸€åŒ–å±‚æ˜¯ä¸ºäº†é˜²æ­¢åœ¨æŸäº›å±‚ä¸­ç”±äºæŸäº›ä½ç½®è¿‡å¤§æˆ–è€…è¿‡å°å¯¼è‡´æ•°å€¼è¿‡å¤§æˆ–è¿‡å°ï¼Œå¯¹ç¥ç»ç½‘ç»œæ¢¯åº¦å›ä¼ æ—¶æœ‰è®­ç»ƒçš„é—®é¢˜ï¼Œä¿è¯è®­ç»ƒçš„ç¨³å®šæ€§ï¼Œè¿™æ˜¯ç¥ç»ç½‘ç»œè®¾è®¡æ¯”è¾ƒå¸¸ç”¨çš„caseã€‚</p>
<p>ç»“è®ºï¼š<br>self-attentionå±‚çš„å¥½å¤„æ˜¯èƒ½å¤Ÿä¸€æ­¥åˆ°ä½æ•æ‰åˆ°å…¨å±€çš„è”ç³»ï¼Œè§£å†³äº†é•¿è·ç¦»ä¾èµ–ï¼Œå› ä¸ºå®ƒç›´æ¥æŠŠåºåˆ—ä¸¤ä¸¤æ¯”è¾ƒï¼ˆä»£ä»·æ˜¯è®¡ç®—é‡å˜ä¸º O(n2)ï¼Œå½“ç„¶ç”±äºæ˜¯çº¯çŸ©é˜µè¿ç®—ï¼Œè¿™ä¸ªè®¡ç®—é‡ç›¸å½“ä¹Ÿä¸æ˜¯å¾ˆä¸¥é‡ï¼‰ï¼Œè€Œä¸”æœ€é‡è¦çš„æ˜¯å¯ä»¥è¿›è¡Œå¹¶è¡Œè®¡ç®—ã€‚<br>ç›¸æ¯”ä¹‹ä¸‹ï¼ŒRNN éœ€è¦ä¸€æ­¥æ­¥é€’æ¨æ‰èƒ½æ•æ‰åˆ°ï¼Œå¹¶ä¸”å¯¹äºé•¿è·ç¦»ä¾èµ–å¾ˆéš¾æ•æ‰ã€‚è€Œ CNN åˆ™éœ€è¦é€šè¿‡å±‚å æ¥æ‰©å¤§æ„Ÿå—é‡ï¼Œè¿™æ˜¯ Attention å±‚çš„æ˜æ˜¾ä¼˜åŠ¿ã€‚</p>
<h2 id="A-simple-but-tough-to-beat-baseline-for-sentence-embeddings"><a href="#A-simple-but-tough-to-beat-baseline-for-sentence-embeddings" class="headerlink" title="A simple but tough-to-beat baseline for sentence embeddings"></a>A simple but tough-to-beat baseline for sentence embeddings</h2><p>è¿™ç§motivation è¿˜æ˜¯å¾ˆå€¼å¾—å¥½å¥½çœ‹çš„ï¼ŒéªŒè¯è®ºæ–‡çš„å¥½åæ˜¯å¯ä»¥é€šè¿‡çœ‹æœ€åçš„æ•ˆæœ/ ç»“æœæ˜¯å¦æŒ‰ç…§ motivation é‚£æ ·çš„ã€‚  â€œrelative weightsâ€ æ˜¯é’ˆå¯¹ word2vec ä¸­çš„æ•ˆæœæ”¹è¿›çš„ï¼Œä»motivation çš„è§’åº¦æ²¡æœ‰è€ƒè™‘åˆ° melo or BERT ä¸­çš„ context . å½“ç„¶è®ºæ–‡çš„åˆ›æ–°ç‚¹åœ¨äº æ— ç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œå½“åˆ«äººéƒ½åœ¨è½¬å‘æœ‰ç›‘ç£å’Œå¤šä»»åŠ¡çš„æ—¶å€™ï¼Œåœ¨ç¼©çŸ­è¿è¡Œæ—¶é—´çš„åŒæ—¶ï¼Œæœ€åçš„æ•ˆæœå’Œç¥ç»ç½‘ç»œæ——é¼“ç›¸å½“ã€‚</p>
<p>Taking the average of the word embeddings in a sentence tends to give too much weight to words that are quite irrelevant, semantically speaking. Smooth Inverse Frequency tries to solve this problem in two ways:</p>
<ul>
<li>Weighting: like our tf-idf baseline above, SIF takes the weighted average of the word embeddings in the sentence. Every word embedding is weighted by a/(a + p(w)), where a is a parameter that is typically set to 0.001 and p(w) is the estimated frequency of the word in a reference corpus.</li>
<li>Common component removal: next, SIF computes the principal component of the resulting embeddings for a set of sentences. It then subtracts from these sentence embeddings their projections on their first principal component. This should remove variation related to frequency and syntax that is less relevant semantically.<br>As a result, SIF downgrades unimportant words such as but, just, etc., and keeps the information that contributes most to the semantics of the sentence.</li>
</ul>
<p>æœ¬æ–‡æ˜¯ç”¨æ— ç›‘ç£æ–¹æ³•åšå¥å­çº§åˆ«çš„ embeddingï¼Œç”¨çš„æ˜¯ä¸€ä¸ªååˆ†ç®€å•ä½†å´åˆå¾ˆæœ‰æ•ˆçš„ä¼ ç»Ÿæ–¹æ³•ï¼Œè¿™åœ¨ç¥ç»ç½‘ç»œæ³›æ»¥çš„å¹´ä»£ç®—æ˜¯ä¸€è‚¡æ¸…æµäº†ã€‚<br>è¿™å¼ å›¾ä¸Šçš„ä¿¡æ¯è¿˜æ˜¯å¾ˆå¤šçš„ï¼Œæ‰€ä»¥å¥½å¥½å½’çº³æ•´ç†ä¸€ä¸‹ã€‚<br>å°½ç®¡é•¿æœŸä»¥æ¥å¥å­çš„æ— ç›‘ç£è¡¨ç¤ºå­¦ä¹ æ˜¯ä¸»æµï¼Œæœ€è¿‘å‡ ä¸ªæœˆï¼ˆ2017å¹´æœ«/2018å¹´åˆï¼‰ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†è®¸å¤šéå¸¸æœ‰è¶£çš„å·¥ä½œï¼Œæ˜¾ç¤ºäº†å‘ç›‘ç£å­¦ä¹ å’Œå¤šä»»åŠ¡å­¦ä¹ è½¬å‘çš„è¶‹åŠ¿ã€‚</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3dvg2o3wwj20qo0grdgp.jpg" alt=""></p>
<ul>
<li>å¼ºåŠ›/è¿…é€Ÿçš„åŸºçº¿ï¼šFastTextã€è¯è¢‹ï¼ˆBag-of-Wordsï¼‰</li>
<li>å½“å‰æœ€å…ˆè¿›æ¨¡å‹ï¼šELMoã€Skip-Thoughtsã€Quick-Thoughtsã€ InferSentã€MILA/MSRçš„General Purpose Sentence Representationsã€Googleçš„Universal Sentence Encoder</li>
</ul>
<p>å…³äºnlp ä¸­çš„word embedding æ˜¯å¯ä»¥æœ‰ phrases, sentences, and paragraphs ä¸‰ä¸ªä¸åŒç±»åˆ«çš„ embeddingï¼Œæ‰€ä»¥è¿˜æ˜¯æŒºå¥½çš„ã€‚</p>
<p>è¿‘äº”å¹´æ¥æå‡ºäº†å¤§é‡è¯åµŒå…¥æ–¹æ³•ã€‚å…¶ä¸­æœ€å¸¸ç”¨çš„æ¨¡å‹æ˜¯word2vecå’ŒGloVeï¼Œè¿™ä¸¤ä¸ªæ¨¡å‹éƒ½æ˜¯åŸºäºåˆ†å¸ƒå‡è¯´ï¼ˆdistributional hypothesisï¼‰çš„æ— ç›‘ç£æ–¹æ³•ã€‚ï¼ˆæ ¹æ®åˆ†å¸ƒå‡è¯´ï¼Œå‡ºç°åœ¨ç›¸åŒä¸Šä¸‹æ–‡ä¸­çš„å•è¯å€¾å‘äºå…·æœ‰ç›¸ä¼¼çš„å«ä¹‰ï¼‰ã€‚<br>å°½ç®¡æœ‰ä¸€äº›å·¥ä½œé€šè¿‡å¹¶å…¥è¯­ä¹‰æˆ–è¯­æ³•çŸ¥è¯†ç­‰å¢å¼ºè¿™äº›æ— ç›‘ç£æ–¹æ³•ï¼Œçº¯æ— ç›‘ç£æ–¹æ³•åœ¨2017-2018å¹´æœŸé—´å–å¾—äº†æœ‰è¶£çš„è¿›å±•ï¼Œå…¶ä¸­æœ€é‡å¤§çš„æ˜¯FastTextï¼ˆword2vecçš„æ‰©å±•ï¼‰å’ŒELMoï¼ˆå½“å‰æœ€å…ˆè¿›çš„ä¸Šä¸‹æ–‡è¯å‘é‡ï¼‰ã€‚</p>
<p>åœ¨ELMoä¸­ï¼ŒåµŒå…¥åŸºäºä¸€ä¸ªåŒå±‚çš„åŒå‘è¯­è¨€æ¨¡å‹ï¼ˆbiLMï¼‰çš„å†…éƒ¨çŠ¶æ€è®¡ç®—ï¼ŒELMoä¹Ÿæ˜¯å› æ­¤å¾—åçš„ï¼šEmbeddings from Language Modelsï¼ˆæ¥è‡ªè¯­è¨€æ¨¡å‹çš„åµŒå…¥ï¼‰ã€‚<br>ELMoçš„ç‰¹æ€§ï¼š<br>ELMoçš„è¾“å…¥æ˜¯å­—ç¬¦è€Œä¸æ˜¯å•è¯ã€‚è¿™ä½¿å¾—å®ƒå¯ä»¥åˆ©ç”¨å­å­—ï¼ˆsub-wordï¼‰å•å…ƒä¸ºè¯æ±‡è¡¨ä»¥å¤–çš„å•è¯è®¡ç®—æœ‰æ„ä¹‰çš„è¡¨ç¤ºï¼ˆå’ŒFastTextç±»ä¼¼ï¼‰ã€‚<br>ELMoæ˜¯biLMçš„å¤šå±‚æ¿€æ´»çš„è¿æ¥ï¼ˆconcatenationï¼‰ã€‚è¯­è¨€æ¨¡å‹çš„ä¸åŒå±‚ç¼–ç äº†å•è¯çš„ä¸åŒä¿¡æ¯ã€‚è¿æ¥æ‰€æœ‰å±‚ä½¿å¾—ELMoå¯ä»¥ç»„åˆå¤šç§è¯è¡¨ç¤ºï¼Œä»¥æå‡ä¸‹æ¸¸ä»»åŠ¡çš„è¡¨ç°ã€‚</p>
<p>æ™®é€‚å¥åµŒå…¥<br>è¯è¢‹æ–¹æ³•<br>è¿™ä¸€é¢†åŸŸçš„ä¸€èˆ¬å…±è¯†æ˜¯ï¼Œç›´æ¥å¹³å‡ä¸€ä¸ªå¥å­çš„è¯å‘é‡è¿™ä¸€ç®€å•æ–¹æ³•ï¼ˆæ‰€è°“è¯è¢‹æ–¹æ³•ï¼‰ï¼Œä¸ºè®¸å¤šä¸‹æ¸¸ä»»åŠ¡æä¾›äº†å¼ºåŠ›çš„åŸºçº¿ã€‚<br>Aroraç­‰å»å¹´åœ¨ICLRå‘è¡¨çš„è®ºæ–‡A Simple but Tough-to-Beat Baseline for Sentence Embeddingsæä¾›äº†ä¸€ä¸ªå¾ˆå¥½çš„ç®—æ³•ï¼šé€‰æ‹©ä¸€ç§æµè¡Œçš„è¯åµŒå…¥ï¼Œç¼–ç å¥å­ä¸ºè¯å‘é‡çš„çº¿æ€§åŠ æƒç»„åˆï¼Œç„¶åè¿›è¡Œç›¸åŒæˆåˆ†ç§»é™¤ï¼ˆæ ¹æ®é¦–è¦ä¸»æˆåˆ†ç§»é™¤å‘é‡æŠ•å½±ï¼‰ã€‚è¿™ä¸€é€šç”¨æ–¹æ³•å…·æœ‰æ·±åˆ»è€Œå¼ºå¤§çš„ç†è®ºåŠ¨æœºï¼ŒåŸºäºåœ¨è¯­ç¯‡å‘é‡ä¸Šéšæœºè¡Œèµ°ä»¥ç”Ÿæˆæ–‡æœ¬çš„ç”Ÿæˆå¼æ¨¡å‹ã€‚</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3dw277xiyj20pi0c10ww.jpg" alt=""></p>
<p>ï¼ˆæœ‰äººå®è·µï¼‰è¿™ä¸ªæ–¹æ³•åœ¨çŸ­æ–‡æœ¬ä¸Šæ•ˆæœæ›´å¥½ï¼Œåœ¨è¯­æ–™ä¸è¶³çš„æ—¶å€™æ•ˆæœä¸èƒ½ä¿è¯ã€‚è¿™ç§æ¨¡å‹æ²¡æœ‰è€ƒè™‘è¯é¡ºåºï¼ˆä¹Ÿå¯ä»¥è¯´åªèƒ½ç†è§£è¯æ„æ€ï¼Œä½†æ˜¯ä¸èƒ½ç†è§£è¯­ä¹‰ï¼‰ï¼Œè€Œæ·±åº¦ç½‘ç»œæ¨¡å‹æ˜¯å¯ä»¥è€ƒè™‘è¯­ä¹‰çš„ã€‚å¯èƒ½å†ç›¸ä¼¼åº¦é—®é¢˜ä¸Šå¯ä»¥å–å¾—æ¯”è¾ƒå¥½çš„æ•ˆæœï¼Œä½†æ˜¯åœ¨æ–‡æœ¬åˆ†ç±»ï¼Œæƒ…æ„Ÿåˆ†ç±»ä¸Šæ•ˆæœä¸€èˆ¬ã€‚</p>
<blockquote>
<p>æ€è€ƒï¼šä»ç›´è§‰ä¸Šç†è§£, çŸ­æ–‡æœ¬ä¸Šçš„ word2vecã€SIF è¿™ç§æ²¡æœ‰ handle è¯­åºçš„æ¨¡å‹å¾—åˆ°çš„æ•ˆæœå°±å·²ç»è¶³å¤Ÿçš„å¥½ï¼Œå¯¹äºä¸­é•¿æ–‡æœ¬ï¼ˆå¥å­ã€æ®µè½ç­‰ï¼‰elmo å’ŒBERT è¿™ç§æ¨¡å‹çš„æ•ˆæœæ˜¯æ›´åŠ çš„ã€‚</p>
</blockquote>
<p>ç¨‹åºçš„è¿è¡Œåªéœ€è¦åå‡ åˆ†é’Ÿï¼Œä¸ç¥ç»ç½‘ç»œçš„æ•ˆæœæ——é¼“ç›¸å½“ã€‚</p>
<h2 id="Supervised-Learning-of-Universal-Sentence-Representations-from-Natural-Language-Inference-Data"><a href="#Supervised-Learning-of-Universal-Sentence-Representations-from-Natural-Language-Inference-Data" class="headerlink" title="Supervised Learning of Universal Sentence Representations from Natural Language Inference Data"></a>Supervised Learning of Universal Sentence Representations from Natural Language Inference Data</h2><p>æ–‡ç« æˆåŠŸçš„æ‰¾åˆ°äº†NLPé¢†åŸŸçš„ImageNet â€” SNLI (Stanford Natural Language Inference dataset), å¹¶ä¸”è¯•éªŒäº†ä¸åŒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œæœ€ç»ˆç¡®å®šbi-LSTM max pooled ä¸ºæœ€ä½³æ¨¡å‹ã€‚</p>
<table>
<thead>
<tr>
<th>åŸŸ</th>
<th>æ•°æ®</th>
<th>ä»»åŠ¡</th>
<th>æ¨¡å‹(ç¼–ç å™¨)</th>
</tr>
</thead>
<tbody>
<tr>
<td>CV</td>
<td>ImageNet</td>
<td>image classification</td>
<td>Le-Net, VGG-Net, Google-Net, ResNet, DenseNet</td>
</tr>
<tr>
<td>NLP</td>
<td>SNLI</td>
<td>NLI</td>
<td>?</td>
</tr>
</tbody>
</table>
<p>åŸºäºç›‘ç£å­¦ä¹ æ–¹æ³•å­¦ä¹ sentence embeddingså¯ä»¥å½’çº³ä¸ºä¸¤ä¸ªæ­¥éª¤ï¼š<br>ç¬¬ä¸€æ­¥é€‰æ‹©ç›‘ç£è®­ç»ƒæ•°æ®ï¼Œè®¾è®¡ç›¸åº”çš„åŒ…å«å¥å­ç¼–ç å™¨Encoderçš„æ¨¡å‹æ¡†æ¶ï¼›<br>ç¬¬äºŒæ­¥é€‰æ‹©ï¼ˆè®¾è®¡ï¼‰å…·ä½“çš„å¥å­ç¼–ç å™¨ï¼ŒåŒ…æ‹¬DANã€åŸºäºLSTMã€åŸºäºCNNå’ŒTransformerç­‰ã€‚</p>
<p>æ•°æ®é›†ï¼š</p>
<p>æœ¬æ–‡é‡‡ç”¨çš„æ˜¯Stanford Natural Language Inference Datasetsï¼Œç®€ç§°SNLI ï¼ˆNLPé¢†åŸŸçš„ImageNet ï¼‰ã€‚SNLIåŒ…å«570Kä¸ªäººç±»äº§ç”Ÿçš„å¥å­å¯¹ï¼Œæ¯ä¸ªå¥å­å¯¹éƒ½å·²ç»åšå¥½äº†æ ‡ç­¾ï¼Œæ ‡ç­¾æ€»å…±åˆ†ä¸ºä¸‰ç±»ï¼šè•´å«ã€çŸ›ç›¾å’Œä¸­ç«‹ï¼ˆEntailmentã€contradiction and neutralï¼‰ã€‚ä¸‹é¢æ˜¯è¿™äº›æ•°æ®é›†çš„ä¸€ä¸ªä¾‹å­ï¼š</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eqwkv9tlj20kd097gm4.jpg" alt=""><br>ä»ä¸Šå›¾å¯ä»¥çœ‹å‡ºï¼Œæ¯ä¸ªå¥å­å¯¹ä¸ºï¼ˆtext, hypothesisï¼‰,ä¸­é—´çš„judgmentsä¸ºå®ƒä»¬çš„æ ‡ç­¾ã€‚å¯ä»¥çœ‹åˆ°æ ‡ç­¾æ˜¯ç»¼åˆäº†5ä¸ªä¸“å®¶çš„æ„è§ï¼Œæ ¹æ®å°‘æ•°æœä»å¤šæ•°çš„åŸåˆ™å¾—åˆ°çš„ã€‚</p>
<p>7ç§ä¸åŒçš„architecturesï¼š </p>
<ol>
<li>standard recurrent encoders with LSTM ï¼Œå–æœ€åä¸€ä¸ªéšçŠ¶æ€</li>
<li>standard recurrent encoders with GRU ï¼Œå–æœ€åä¸€ä¸ªéšçŠ¶æ€<br>ä¸Šè¿°ä¸¤ç§æ˜¯åŸºç¡€çš„recurrent encoderï¼Œåœ¨å¥å­å»ºæ¨¡ä¸­é€šå¸¸å°†ç½‘ç»œä¸­çš„æœ€åä¸€ä¸ªéšè—çŠ¶æ€ä½œä¸ºsentence representationï¼› </li>
<li>conncatenation of last hidden states of forward and backward GRU<br>è¿™ç§æ–¹æ³•æ˜¯å°†å•å‘çš„ç½‘ç»œå˜æˆäº†åŒå‘çš„ç½‘ç»œï¼Œç„¶åç”¨å°†å‰å‘å’Œåå‘çš„æœ€åä¸€ä¸ªçŠ¶æ€è¿›è¡Œè¿æ¥ï¼Œå¾—åˆ°å¥å­å‘é‡ï¼› </li>
<li>Bi-directional LSTMs (BiLSTM) with mean pooling </li>
<li>Bi-directional LSTMs (BiLSTM) with max pooling<br>è¿™ä¸¤ç§æ–¹æ³•ä½¿ç”¨äº†åŒå‘LSTMç»“åˆä¸€ä¸ªpoolingå±‚çš„æ–¹æ³•æ¥è·å–å¥å­è¡¨ç¤ºï¼Œå…·ä½“å…¬å¼å¦‚ä¸‹ï¼š </li>
<li>self-attentive network<br>è¿™ä¸ªç½‘ç»œåœ¨åŒå‘LSTMçš„åŸºç¡€ä¸ŠåŠ å…¥äº†attentionæœºåˆ¶ï¼Œå…·ä½“ç½‘ç»œç»“æ„å¦‚ä¸‹ï¼š </li>
<li>hierarchical convolutional networks </li>
</ol>
<p>Now that we have discussed the various sentence encoding architectures used in the paper, letâ€™s go through the part of the network which takes these sentence embeddings and predicts the output label.</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eqyoxmknj20ey0d640u.jpg" alt=""><br>After the sentence vectors are fed as input to this model, 3 matching methods are applied to extract relations between the text, u and hypothesis, v â€“</p>
<ul>
<li>concatenation of the two representations (u, v)</li>
<li>element-wise product u * v</li>
<li>and, absolute element-wise difference |u â€“ v |</li>
</ul>
<p>The resulting vector captures information from both the text, u and the hypothesis, v, and is fed into a 3-class classifier consisting of multiple fully connected layers followed by a softmax layer.</p>
<h2 id="Universal-Sentence-Encoder"><a href="#Universal-Sentence-Encoder" class="headerlink" title="Universal Sentence Encoder"></a>Universal Sentence Encoder</h2><p>è¿™ç¯‡æ–‡ç« åŸºäºInferSentï¼Œ ä¹Ÿæ˜¯æƒ³æ‰¾åˆ°ä¸€ä¸ªuniversal encoderã€‚ä¸åŒä¹‹å¤„åœ¨äºæ–‡ç« æŠŠInferSentçš„bi-lstmæ¢æˆäº†DANï¼ˆæˆ–è€…Transformer)ï¼Œè€Œä½¿ç”¨DANè¿™æ ·â€œç®€å•â€çš„encoderçš„æ•ˆæœç«Ÿç„¶ç›¸å½“å¥½ï¼ˆå°¤å…¶æ˜¯æ—¶é—´å’Œå†…å­˜æ¶ˆè€—å’Œå…¶ä»–ç®—æ³•æ¯”å°å¾ˆå¤šã€‚ï¼‰</p>
<p>The Google Sentence Encoder is Googleâ€™s answer to Facebookâ€™s InferSent. It comes in two forms:</p>
<ul>
<li>an advanced model that takes the element-wise sum of the context-aware word representations produced by the encoding subgraph of a Transformer model.</li>
<li>a simpler Deep Averaging Network (DAN) where input embeddings for words and bigrams are averaged together and passed through a feed-forward deep neural network.<br>The Transformer-based model tends to give better results, but at the time of writing, only the DAN-based encoder was available. In contrast to InferSent, the Google Sentence Encoder was trained on a combination of unsupervised data (in a skip-thought-like task) and supervised data (the SNLI corpus).</li>
</ul>
<p>DAN<br>å…¶å®DAN(Deep Averaging Networks)åº”è¯¥å±äºBag of Wordsç±»çš„ç®—æ³•ã€‚å› ä¸ºæ¯”è¾ƒç‰¹æ®Šï¼Œå•ç‹¬åˆ—å‡ºæ¥ã€‚ å®ƒæ˜¯åœ¨å¯¹æ‰€æœ‰è¯è¯­å–å¹³å‡åï¼Œåœ¨ä¸Šé¢åŠ ä¸Šå‡ å±‚ç¥ç»ç½‘ç»œã€‚ç‰¹æ®Šçš„åœ°æ–¹åœ¨äºå®ƒåœ¨sentiment analysisä¸­è¡¨ç°ä¹Ÿä¸é”™ï¼Œè¿™åœ¨BOWç±»æ–¹æ³•ä¸­æ¯”è¾ƒç½•è§ã€‚</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3esxw2nilj20dh08ujth.jpg" alt=""></p>
<table>
<thead>
<tr>
<th>æ–°æ–¹æ³•</th>
<th>ç±»å‹</th>
<th>åŸºäºçš„æ—§ç®—æ³•</th>
<th>è´¡çŒ®</th>
</tr>
</thead>
<tbody>
<tr>
<td>SIF</td>
<td>æ— ç›‘ç£</td>
<td>BOW</td>
<td>ä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„baselineç®—æ³•</td>
</tr>
<tr>
<td>InferSent</td>
<td>ç›‘ç£</td>
<td>NA</td>
<td>æ‰¾åˆ°äº†NLPé¢†åŸŸçš„ImageNet â€“ SNLIï¼Œ å¹¶ç»™å‡ºäº†ä¸€ä¸ªstate-of-art ç®—æ³•</td>
</tr>
<tr>
<td>P-mean</td>
<td>æ— ç›‘ç£</td>
<td>BOW</td>
<td>æ¯”SIFæ›´ç®€å•ä¸”æœ‰æ•ˆçš„ä¸€ä¸ªç®—æ³•ä¸”é€‚ç”¨äºcross-lingual</td>
</tr>
<tr>
<td>Universal-sentence-encoder</td>
<td>ç›‘ç£</td>
<td>InferSent</td>
<td>æ›´åŠ ç®€å•çš„encoder</td>
</tr>
</tbody>
</table>
<p>æ–‡ç« å…±æå‡ºä¸¤ç§åŸºäºä¸åŒç½‘ç»œæ¶æ„çš„Universal Sentence Encoderï¼šTransformer and Deep Averaging Network (DAN).<br>Our two encoders have different design goals. One based on the transformer architecture targets high accuracy at the cost of greater model complexity and resource consumption. The other targets efficient inference with slightly reduced accuracy.</p>
<h2 id="deep-contextualized-word-representations"><a href="#deep-contextualized-word-representations" class="headerlink" title="deep contextualized word representations"></a>deep contextualized word representations</h2><p>introduction:</p>
<p>è¿™ç§embedding -context å¿…è¦æ€§çš„ä»‹ç»ï¼Œæ„Ÿè§‰æ˜¯æœ‰æ›´å¥½ï¼Œæ²¡æœ‰ä¹Ÿæ˜¯èƒ½å¤Ÿç†è§£çš„ã€‚<br>Why do we need contextualized representations?<br>As an illustrative example, take the following two sentences:</p>
<blockquote>
<p>â€œThe bank on the other end of the street was robbedâ€<br>â€œWe had a picnic on the bank of the riverâ€</p>
</blockquote>
<p>Both sentences use the word â€œbankâ€, but the meaning of the word differs completely between them. This phenomenon where two identical words change meaning depending on the context is known as â€œpolysemyâ€œ, and has been an issue in the NLP deep learning community ever since word embeddings really took off. Most current neural networks are bad at handling polysemy because they use a single vector to represent the meaning of the word â€œbankâ€, regardless of the context. In reality, the vector representing any word should change depending on the words around it.</p>
<p>ä»€ä¹ˆæ˜¯ä¸€ä¸ªå¥½çš„è¯å‘é‡ï¼š<br>ELMoèƒ½å¤Ÿå­¦ä¹ åˆ°è¯æ±‡ç”¨æ³•çš„å¤æ‚æ€§ï¼Œæ¯”å¦‚è¯­æ³•ã€è¯­ä¹‰ã€‚<br>ELMoèƒ½å¤Ÿå­¦ä¹ ä¸åŒä¸Šä¸‹æ–‡æƒ…å†µä¸‹çš„è¯æ±‡å¤šä¹‰æ€§ã€‚</p>
<p>ä¹‹å‰çš„åšæ³•çš„ç¼ºç‚¹æ˜¯å¯¹äºæ¯ä¸€ä¸ªå•è¯éƒ½æœ‰å”¯ä¸€çš„ä¸€ä¸ªembeddingè¡¨ç¤º, è€Œå¯¹äºå¤šä¹‰è¯æ˜¾ç„¶è¿™ç§åšæ³•ä¸ç¬¦åˆç›´è§‰, è€Œå•è¯çš„æ„æ€åˆå’Œä¸Šä¸‹æ–‡ç›¸å…³, ELMoçš„åšæ³•æ˜¯æˆ‘ä»¬åªé¢„è®­ç»ƒlanguage model, è€Œword embeddingæ˜¯é€šè¿‡è¾“å…¥çš„å¥å­å®æ—¶è¾“å‡ºçš„, è¿™æ ·å•è¯çš„æ„æ€å°±æ˜¯ä¸Šä¸‹æ–‡ç›¸å…³çš„äº†, è¿™æ ·å°±å¾ˆå¤§ç¨‹åº¦ä¸Šç¼“è§£äº†æ­§ä¹‰çš„å‘ç”Ÿ.</p>
<p>è¿™ç§ç®—æ³•çš„ç‰¹ç‚¹æ˜¯ï¼šæ¯ä¸€ä¸ªword representationéƒ½æ˜¯æ•´ä¸ªè¾“å…¥è¯­å¥çš„å‡½æ•°ã€‚å…·ä½“åšæ³•å°±æ˜¯å…ˆåœ¨å¤§è¯­æ–™ä¸Šä»¥language modelä¸ºç›®æ ‡è®­ç»ƒå‡ºbidirectional LSTMæ¨¡å‹ï¼Œç„¶ååˆ©ç”¨LSTMäº§ç”Ÿè¯è¯­çš„è¡¨å¾ã€‚ELMoæ•…è€Œå¾—å(Embeddings from Language Models)ã€‚ä¸ºäº†åº”ç”¨åœ¨ä¸‹æ¸¸çš„NLPä»»åŠ¡ä¸­ï¼Œä¸€èˆ¬å…ˆåˆ©ç”¨ä¸‹æ¸¸ä»»åŠ¡çš„è¯­æ–™åº“(æ³¨æ„è¿™é‡Œå¿½ç•¥æ‰label)è¿›è¡Œlanguage modelçš„å¾®è°ƒ,è¿™ç§å¾®è°ƒç›¸å½“äºä¸€ç§domain transfer; ç„¶åæ‰åˆ©ç”¨labelçš„ä¿¡æ¯è¿›è¡Œsupervised learningã€‚</p>
<p>ï¼ˆè¿™ä¸ªæè¿°è·Ÿ cv æ˜¯æƒŠäººçš„ç›¸ä¼¼ï¼‰<br>ELMoè¡¨å¾æ˜¯â€œæ·±â€çš„ï¼Œå°±æ˜¯è¯´å®ƒä»¬æ˜¯biLMçš„æ‰€æœ‰å±‚çš„å†…éƒ¨è¡¨å¾çš„å‡½æ•°ã€‚è¿™æ ·åšçš„å¥½å¤„æ˜¯èƒ½å¤Ÿäº§ç”Ÿä¸°å¯Œçš„è¯è¯­è¡¨å¾ã€‚é«˜å±‚çš„LSTMçš„çŠ¶æ€å¯ä»¥æ•æ‰è¯è¯­æ„ä¹‰ä¸­å’Œè¯­å¢ƒç›¸å…³çš„é‚£æ–¹é¢çš„ç‰¹å¾(æ¯”å¦‚å¯ä»¥ç”¨æ¥åšè¯­ä¹‰çš„æ¶ˆæ­§)ï¼Œè€Œä½å±‚çš„LSTMå¯ä»¥æ‰¾åˆ°è¯­æ³•æ–¹é¢çš„ç‰¹å¾(æ¯”å¦‚å¯ä»¥åšè¯æ€§æ ‡æ³¨)ã€‚å¦‚æœæŠŠå®ƒä»¬ç»“åˆåœ¨ä¸€èµ·ï¼Œåœ¨ä¸‹æ¸¸çš„NLPä»»åŠ¡ä¸­ä¼šä½“ç°ä¼˜åŠ¿ã€‚</p>
<p>Salient features<br>ELMo representations are:</p>
<ul>
<li>Contextual: The representation for each word depends on the entire context in which it is used.</li>
<li>Deep: The word representations combine all layers of a deep pre-trained neural network.</li>
<li>Character based: ELMo representations are purely character based, allowing the network to use morphological clues to form robust representations for out-of-vocabulary tokens unseen in training.</li>
</ul>
<p>related work:</p>
<p>é’ˆå¯¹ä¼ ç»Ÿè¯å‘é‡æ˜¯å›ºå®šçš„ï¼Œä¸ä¸Šä¸‹æ–‡è¯­å¢ƒæ— å…³çš„ç¼ºç‚¹ï¼Œå…ˆå‰çš„å·¥ä½œå¤šé€šè¿‡ä¸¤ç§æ–¹å¼æ¥è§£å†³ï¼š<br> (1) é€šè¿‡å¼•å…¥å­—ç¬¦çº§(subword)ä¿¡æ¯ä¸°å¯Œè¯å‘é‡è¡¨è¾¾ï¼›<br> (2) å­¦ä¹ æ¯ä¸ªå•è¯ä¸åŒå«ä¹‰çš„ç‹¬ç«‹å‘é‡ï¼›<br> ELMoä¹Ÿåˆ©ç”¨äº†å­—ç¬¦å·ç§¯ï¼ˆCharacter-Convolutionsï¼‰å¼•å…¥å­—ç¬¦çº§ä¿¡æ¯ï¼Œå¹¶åŒæ—¶ç»“åˆäº†æ·±åº¦åŒå‘è¯­è¨€æ¨¡å‹çš„å„å±‚éšçŠ¶æ€æ¥ä¸°å¯Œè¯å‘é‡è¡¨è¾¾ã€‚</p>
<p>P.s.ï¼šåŸºäºå­—ç¬¦çš„æ¨¡å‹ä¸ä»…èƒ½å¤Ÿé€šè¿‡å¼•å…¥å­—ç¬¦çº§ä¿¡æ¯ä¸°å¯Œè¯å‘é‡è¡¨è¾¾ï¼Œä¹Ÿèƒ½å¤Ÿåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šè§£å†³NLPé¢†åŸŸçš„OOVï¼ˆOut-Of-Vocabularyï¼‰é—®é¢˜ã€‚</p>
<p>ELMoç”¨åˆ°ä¸Šæ–‡æåˆ°çš„åŒå‘çš„language model, ç»™å®šNä¸ªtokens (t1, t2,â€¦,tN), language modelé€šè¿‡ç»™å®šå‰é¢çš„k-1ä¸ªä½ç½®çš„tokenåºåˆ—è®¡ç®—ç¬¬kä¸ªtokençš„å‡ºç°çš„æ¦‚ç‡:<br>$$<br>p \left( t _ { 1 } , t _ { 2 } , \ldots , t _ { N } \right) = \prod _ { k = 1 } ^ { N } p \left( t _ { k } | t _ { 1 } , t _ { 2 } , \ldots , t _ { k - 1 } \right)<br>$$<br>åå‘çš„è®¡ç®—æ–¹æ³•ä¸å‰å‘ç›¸ä¼¼:</p>
<p>$$<br>p \left( t _ { 1 } , t _ { 2 } , \ldots , t _ { N } \right) = \prod _ { k = 1 } ^ { N } p \left( t _ { k } | t _ { k + 1 } , t _ { k + 2 } , \ldots , t _ { N } \right)<br>$$<br>biLMè®­ç»ƒè¿‡ç¨‹ä¸­çš„ç›®æ ‡å°±æ˜¯æœ€å¤§åŒ–:<br>$$<br>\sum _ { k = 1 } ^ { N } \left( \log p \left( t _ { k } | t _ { 1 } , \ldots , t _ { k - 1 } ; \Theta _ { x } , \vec { \Theta } _ { L S T M } , \Theta _ { s } \right) + \log p \left( t _ { k } | t _ { k + 1 } , \ldots , t _ { N } ; \Theta _ { x } , \overline { \Theta } _ { L S T M } , \Theta _ { s } \right) \right)<br>$$</p>
<p>ELMoå¯¹äºæ¯ä¸ªtoken $t_k$, é€šè¿‡ä¸€ä¸ªLå±‚çš„biLMè®¡ç®—å‡º2L+1ä¸ªè¡¨ç¤º:<br>$$<br>R_{ k } = \left{ x _ { k } ^ { L M } , \vec { h } _ { k , j } ^ { L M } , h _ { k , j } ^ { L M } | j = 1 , \ldots , L \right} = \left{ h _ { k , j } ^ { L M } | j = 0 , \ldots , L \right}<br>$$<br>å…¶ä¸­$h _ { k , 0 } ^ { L M }$æ˜¯å¯¹tokenè¿›è¡Œç›´æ¥ç¼–ç çš„ç»“æœ(è¿™é‡Œæ˜¯å­—ç¬¦é€šè¿‡CNNç¼–ç ), $h _ { k , j } ^ { L M } = \left[ \vec { h } _ { k , j } ^ { L M } ; \overline { h } _ { k , j } \right]$ æ˜¯æ¯ä¸ªbiLSTMå±‚è¾“å‡ºçš„ç»“æœ. åœ¨å®éªŒä¸­è¿˜å‘ç°ä¸åŒå±‚çš„biLMçš„è¾“å‡ºçš„tokenè¡¨ç¤ºå¯¹äºä¸åŒçš„ä»»åŠ¡æ•ˆæœä¸åŒ.</p>
<p>åº”ç”¨ä¸­å°†ELMoä¸­æ‰€æœ‰å±‚çš„è¾“å‡ºRå‹ç¼©ä¸ºå•ä¸ªå‘é‡, ELMok=E(Rk;Î˜Ïµ), æœ€ç®€å•çš„å‹ç¼©æ–¹æ³•æ˜¯å–æœ€ä¸Šå±‚çš„ç»“æœåšä¸ºtokençš„è¡¨ç¤º:$E \left( R _ { k } \right) = h _ { k , L } ^ { L M }$ æ›´é€šç”¨çš„åšæ³•æ˜¯é€šè¿‡ä¸€äº›å‚æ•°æ¥è”åˆæ‰€æœ‰å±‚çš„ä¿¡æ¯:<br>$$E L M o _ { k } ^ { t a s k } = E \left( R _ { k } ; \Theta ^ { t a s k } \right) = \gamma ^ { t a s k } \sum _ { j = 0 } ^ { L } s _ { j } ^ { t a s k } h _ { k , j } ^ { L M }$$</p>
<p>å…¶ä¸­$s_j$æ˜¯ä¸€ä¸ªsoftmaxå‡ºæ¥çš„ç»“æœ, $Î³$æ˜¯ä¸€ä¸ªä»»åŠ¡ç›¸å…³çš„scaleå‚æ•°, æˆ‘è¯•äº†å¹³å‡æ¯ä¸ªå±‚çš„ä¿¡æ¯å’Œå­¦å‡ºæ¥$s_j$å‘ç°å­¦ä¹ å‡ºæ¥çš„æ•ˆæœä¼šå¥½å¾ˆå¤š. æ–‡ä¸­æåˆ°$Î³$åœ¨ä¸åŒä»»åŠ¡ä¸­å–ä¸åŒçš„å€¼æ•ˆæœä¼šæœ‰è¾ƒå¤§çš„å·®å¼‚, éœ€è¦æ³¨æ„, åœ¨SQuADä¸­è®¾ç½®ä¸º0.01å–å¾—çš„æ•ˆæœè¦å¥½äºè®¾ç½®ä¸º1æ—¶.</p>
<p>ELMo: Context Matters</p>
<p>Instead of using a fixed embedding for each word, ELMo looks at the entire sentence before assigning each word in it an embedding. It uses a bi-directional LSTM trained on a specific task to be able to create those embeddings.<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3fub67ulaj20u20h3wfx.jpg" alt=""></p>
<p>ELMo provided a significant step towards pre-training in the context of NLP. The ELMo LSTM would be trained on a massive dataset in the language of our dataset, and then we can use it as a component in other models that need to handle language.</p>
<p>Whatâ€™s ELMoâ€™s secret?</p>
<p>ELMo gained its language understanding from being trained to predict the next word in a sequence of words - a task called Language Modeling. This is convenient because we have vast amounts of text data that such a model can learn from without needing labels.</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3fubpu9ibj20li0m1q5b.jpg" alt=""></p>
<p>We can see the hidden state of each unrolled-LSTM step peaking out from behind ELMoâ€™s head. Those come in handy in the embedding proecss after this pre-training is done.</p>
<p>ELMo actually goes a step further and trains a bi-directional LSTM â€“ so that its language model doesnâ€™t only have a sense of the next word, but also the previous word.<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3fuc693mrj211z0hbjur.jpg" alt=""><br>ELMo comes up with the contextualized embedding through grouping together the hidden states (and initial embedding) in a certain way (concatenation followed by weighted summation).<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3fuci4xodj213j0kitcq.jpg" alt=""></p>
<p>lstm-based language model<br>In case you are unfamiliar with language models, a language model is simply a model that can predict how â€œlikelyâ€ a certain sequence of words is to be a real piece of text. This is generally done by training a model to take a part of sentence (say, the first n words) and predict the next word â€“ or more precisely, output the probability of each word in the vocabulary being the next word (In this blog post, weâ€™ll focus on LSTM-based language models which are the focus of this paper). </p>
<p>One trick that this paper uses is to train a language model with reversed sentences that the authors call the â€œbackwardâ€ language model.<br>è¿™ç§æ¨¡å‹ï¼šä¸Šä¸€ä¸ªæ¨¡å‹çš„è¾“å‡ºåˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹è¾“å…¥<br>Furthermore, instead of using a single-layer LSTM, this paper uses a stacked, multi-layer LSTM. Whereas a single-layer LSTM would take the sequence of words as input, a multi-layer LSTM trains multiple LSTMs to take the output sequence of the LSTM in the previous layer as input (of course, the first layer takes the sequence of words as input). This is best illustrated in the following illustration:<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3flokoc0mj20ab07474a.jpg" alt=""></p>
<p>æœ€åçš„embedding æ˜¯æ˜¯å°†ä¸åŒçš„å±‚ combinationèµ·æ¥ï¼Œè¿™ä¸ªç³»æ•°æ˜¯é€šè¿‡å­¦ä¹ å‡ºæ¥çš„ã€‚<br>In ELMo, the part that is task specific is the combination of the task-agnostic representations. The weight is learned for each task and normalized using the softmax function. The parameter $\gamma$ is a task-dependent value that allows for scaling the entire vector, which is important during optimization.</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/05/27/Dynamic-Programming-Examples/" rel="next" title="Dynamic Programming Examples">
                <i class="fa fa-chevron-left"></i> Dynamic Programming Examples
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/06/01/nlp-papers-reading-sentence-embedding/" rel="prev" title="NLP  Papers Reading-Sentence Embedding">
                NLP  Papers Reading-Sentence Embedding <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpeg"
                alt="Jijeng Jia" />
            
              <p class="site-author-name" itemprop="name">Jijeng Jia</p>
              <p class="site-description motion-element" itemprop="description">Stay Hungry, Stay Foolish</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">54</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">31</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/jijeng" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:jia1509309698@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          <script type="text/javascript" src="//rf.revolvermaps.com/0/0/5.js?i=5kk0u0mm50w&amp;m=0&amp;c=54ff00&amp;cr1=ff0000" async="async"></script>

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#attention-is-all-you-need"><span class="nav-number">1.</span> <span class="nav-text">attention is all you need</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#A-simple-but-tough-to-beat-baseline-for-sentence-embeddings"><span class="nav-number">2.</span> <span class="nav-text">A simple but tough-to-beat baseline for sentence embeddings</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Supervised-Learning-of-Universal-Sentence-Representations-from-Natural-Language-Inference-Data"><span class="nav-number">3.</span> <span class="nav-text">Supervised Learning of Universal Sentence Representations from Natural Language Inference Data</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Universal-Sentence-Encoder"><span class="nav-number">4.</span> <span class="nav-text">Universal Sentence Encoder</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#deep-contextualized-word-representations"><span class="nav-number">5.</span> <span class="nav-text">deep contextualized word representations</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jijeng Jia</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>

<div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
Total  <span id="busuanzi_value_site_pv"></span> views
You got  <span id="busuanzi_value_site_uv"></span> visitors
</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://https-jijeng-github-io.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2019/05/27/paper-reading-nlp/';
          this.page.identifier = '2019/05/27/paper-reading-nlp/';
          this.page.title = 'NLP Papers Reading- BERT';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://https-jijeng-github-io.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
