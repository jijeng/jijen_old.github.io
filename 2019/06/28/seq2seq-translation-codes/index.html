<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="seq2seq,translation," />










<meta name="description" content="基于 tensorflow 的英文文本的预处理和基于 keras 的中英文本预处理。主要是代码，辅助注释。预处理比较详细的步骤：  unicode to ascii normalize string tokenization (choose one-hot or not) padding (find proper length of tokenization)  需要选择一个框架 tensorfl">
<meta name="keywords" content="seq2seq,translation">
<meta property="og:type" content="article">
<meta property="og:title" content="Seq2Seq Translation (English to Chinese)">
<meta property="og:url" content="http://yoursite.com/2019/06/28/seq2seq-translation-codes/index.html">
<meta property="og:site_name" content="Jijeng&#39;s blog">
<meta property="og:description" content="基于 tensorflow 的英文文本的预处理和基于 keras 的中英文本预处理。主要是代码，辅助注释。预处理比较详细的步骤：  unicode to ascii normalize string tokenization (choose one-hot or not) padding (find proper length of tokenization)  需要选择一个框架 tensorfl">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2019-07-01T08:22:03.957Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Seq2Seq Translation (English to Chinese)">
<meta name="twitter:description" content="基于 tensorflow 的英文文本的预处理和基于 keras 的中英文本预处理。主要是代码，辅助注释。预处理比较详细的步骤：  unicode to ascii normalize string tokenization (choose one-hot or not) padding (find proper length of tokenization)  需要选择一个框架 tensorfl">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/06/28/seq2seq-translation-codes/"/>







<script>
	(function(){
		if(''){
			if (prompt('请输入文章密码','') !== ''){
				alert('密码错误！');
				history.back();
			}
		}
	})();
</script>

  <title>Seq2Seq Translation (English to Chinese) | Jijeng's blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jijeng's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/28/seq2seq-translation-codes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jijeng Jia">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jijeng's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Seq2Seq Translation (English to Chinese)</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-06-28T20:31:33+08:00">
                2019-06-28
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-07-01T16:22:03+08:00">
                2019-07-01
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/06/28/seq2seq-translation-codes/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/06/28/seq2seq-translation-codes/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>基于 tensorflow 的英文文本的预处理和基于 keras 的中英文本预处理。主要是代码，辅助注释。预处理比较详细的步骤：</p>
<ul>
<li>unicode to ascii</li>
<li>normalize string</li>
<li>tokenization (choose one-hot or not)</li>
<li>padding (find proper length of tokenization)</li>
</ul>
<p>需要选择一个框架 tensorflow or keras 去实现。大量数据建议选择 tensorflow，小模型使用 keras 就行。</p>
<a id="more"></a>
<h3 id="热身"><a href="#热身" class="headerlink" title="热身"></a>热身</h3><p>Text data typically requires some cleanup before it can be embedded in vector space and fed to a machine learning model. </p>
<ul>
<li>Remove tags. For example, “&lt;i>Hello&lt;/i> &lt;b>World&lt;/b>!” is converted to “Hello World!”</li>
<li>Remove repeating whitespace characters (spaces, tabs, line breaks). Convert tabs and line breaks to spaces.</li>
<li>Remove stopwords. These include the most commonly occurring words in a language, like “the,” “on,” “is,” etc. NLP libraries like gensim provide a default list of stopwords.</li>
<li>Convert all text to lowercase.</li>
<li>Perform Porter stemming. Porter stemming reduces inflections like “fishing,” “fished,” and “fisher” to the root “fish.” This makes it easier for an ML model to learn how to glean meaning or intent form a sequence of words.</li>
</ul>
<p>调用 gensim 框架实现预处理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.parsing.preprocessing <span class="keyword">import</span> preprocess_string, strip_tags, strip_multiple_whitespaces, remove_stopwords, stem_text</span><br><span class="line">custom_filters = [strip_tags, strip_multiple_whitespaces, remove_stopwords, stem_text]</span><br><span class="line"><span class="comment"># 生成器函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_tokenized_questions</span><span class="params">(X)</span>:</span></span><br><span class="line">    series = pd.Series(pd.concat([X[<span class="string">'question1'</span>], X[<span class="string">'question2'</span>]]),dtype=str)</span><br><span class="line">    series.dropna()</span><br><span class="line">    <span class="keyword">for</span> question <span class="keyword">in</span> series:</span><br><span class="line">        <span class="keyword">yield</span> preprocess_string(question, custom_filters)</span><br></pre></td></tr></table></figure>
<p>All by yourself:  将英文  punctuation characters 和字母以空格隔开。</p>
<pre><code>输入： s = &apos;bla. bla? bla.bla! bla...&apos;
输出： bla . bla ? bla . bla ! bla . . .
</code></pre><p>python2 版本，基于库函数 re 实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">s = <span class="string">'bla. bla? bla.bla! bla...'</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="comment"># 这个符号是可以选择的</span></span><br><span class="line">s = re.sub(<span class="string">'([.,!?()])'</span>, <span class="string">r' \1 '</span>, s) <span class="comment">#  use a regular expression to match the punctuation characters you are interested and surround them by spaces,</span></span><br><span class="line">s = re.sub(<span class="string">'\s&#123;2,&#125;'</span>, <span class="string">' '</span>, s) <span class="comment">#  use a second step to collapse multiple spaces anywhere in the document:</span></span><br><span class="line">print(s)</span><br><span class="line"></span><br><span class="line"><span class="comment"># replacing everything with space except (a-z, A-Z, ".", "?", "!", ",")</span></span><br><span class="line">w = re.sub(<span class="string">r"[^a-zA-Z?.!,¿]+"</span>, <span class="string">" "</span>, w)</span><br><span class="line">w = w.rstrip().strip()</span><br><span class="line">w = <span class="string">'&lt;start&gt; '</span> + w + <span class="string">' &lt;end&gt;'</span> <span class="comment"># 这个是可选的，在首尾加上 'start' or 'end'</span></span><br></pre></td></tr></table></figure>
<p>python3 版本，基于 translate实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在python3 中可以使用 translate() 这个方法</span></span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line">text = text.translate(str.maketrans(&#123;key: <span class="string">" &#123;0&#125; "</span>.format(key) <span class="keyword">for</span> key <span class="keyword">in</span> string.punctuation&#125;))</span><br></pre></td></tr></table></figure>
<h3 id="tensorflow-text-preprocessing"><a href="#tensorflow-text-preprocessing" class="headerlink" title="tensorflow text preprocessing"></a>tensorflow text preprocessing</h3><p>基于 tensorflow 的文本预处理， 适合大量数据，可以使用batch 输入到模型中去。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> unicodedata</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">raw_data = (</span><br><span class="line">    (<span class="string">'What a ridiculous concept!'</span>, <span class="string">'Quel concept ridicule !'</span>),</span><br><span class="line">    (<span class="string">'Your idea is not entirely crazy.'</span>, <span class="string">"Votre idée n'est pas complètement folle."</span>),</span><br><span class="line">    (<span class="string">"A man's worth lies in what he is."</span>, <span class="string">"La valeur d'un homme réside dans ce qu'il est."</span>),</span><br><span class="line">    (<span class="string">'What he did is very wrong.'</span>, <span class="string">"Ce qu'il a fait est très mal."</span>),</span><br><span class="line">    (<span class="string">"All three of you need to do that."</span>, <span class="string">"Vous avez besoin de faire cela, tous les trois."</span>),</span><br><span class="line">    (<span class="string">"Are you giving me another chance?"</span>, <span class="string">"Me donnez-vous une autre chance ?"</span>),</span><br><span class="line">    (<span class="string">"Both Tom and Mary work as models."</span>, <span class="string">"Tom et Mary travaillent tous les deux comme mannequins."</span>),</span><br><span class="line">    (<span class="string">"Can I have a few minutes, please?"</span>, <span class="string">"Puis-je avoir quelques minutes, je vous prie ?"</span>),</span><br><span class="line">    (<span class="string">"Could you close the door, please?"</span>, <span class="string">"Pourriez-vous fermer la porte, s'il vous plaît ?"</span>),</span><br><span class="line">    (<span class="string">"Did you plant pumpkins this year?"</span>, <span class="string">"Cette année, avez-vous planté des citrouilles ?"</span>),</span><br><span class="line">    (<span class="string">"Do you ever study in the library?"</span>, <span class="string">"Est-ce que vous étudiez à la bibliothèque des fois ?"</span>),</span><br><span class="line">    (<span class="string">"Don't be deceived by appearances."</span>, <span class="string">"Ne vous laissez pas abuser par les apparences."</span>),</span><br><span class="line">    (<span class="string">"Excuse me. Can you speak English?"</span>, <span class="string">"Je vous prie de m'excuser ! Savez-vous parler anglais ?"</span>),</span><br><span class="line">    (<span class="string">"Few people know the true meaning."</span>, <span class="string">"Peu de gens savent ce que cela veut réellement dire."</span>),</span><br><span class="line">    (<span class="string">"Germany produced many scientists."</span>, <span class="string">"L'Allemagne a produit beaucoup de scientifiques."</span>),</span><br><span class="line">    (<span class="string">"Guess whose birthday it is today."</span>, <span class="string">"Devine de qui c'est l'anniversaire, aujourd'hui !"</span>),</span><br><span class="line">    (<span class="string">"He acted like he owned the place."</span>, <span class="string">"Il s'est comporté comme s'il possédait l'endroit."</span>),</span><br><span class="line">    (<span class="string">"Honesty will pay in the long run."</span>, <span class="string">"L'honnêteté paye à la longue."</span>),</span><br><span class="line">    (<span class="string">"How do we know this isn't a trap?"</span>, <span class="string">"Comment savez-vous qu'il ne s'agit pas d'un piège ?"</span>),</span><br><span class="line">    (<span class="string">"I can't believe you're giving up."</span>, <span class="string">"Je n'arrive pas à croire que vous abandonniez."</span>),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># convert the unicode file to ascii, 主要是统一编码方式，然后去除 重音符号</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unicode_to_ascii</span><span class="params">(s)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">''</span>.join(</span><br><span class="line">        c <span class="keyword">for</span> c <span class="keyword">in</span> unicodedata.normalize(<span class="string">'NFD'</span>, s) <span class="comment"># UCD是Unicode字符数据库（Unicode Character DataBase）的缩写。</span></span><br><span class="line">        <span class="keyword">if</span> unicodedata.category(c) != <span class="string">'Mn'</span>) <span class="comment"># 去除 重音符号</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 类似于热身中的功能</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize_string</span><span class="params">(s)</span>:</span></span><br><span class="line">    s = unicode_to_ascii(s)</span><br><span class="line">    s = re.sub(<span class="string">r'([!.?])'</span>, <span class="string">r' \1'</span>, s) <span class="comment"># 如果是这三个符号，那么是需要前面加上一个空格</span></span><br><span class="line">    s = re.sub(<span class="string">r'[^a-zA-Z.!?]+'</span>, <span class="string">r' '</span>, s) <span class="comment"># 除去不是这些符号的字符</span></span><br><span class="line">    s = re.sub(<span class="string">r'\s+'</span>, <span class="string">r' '</span>, s) <span class="comment"># 出现多个空格，就去除直到1个</span></span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">raw_data_en, raw_data_fr = list(zip(*raw_data)) <span class="comment"># 变量名称前加 *，表示传入的是一个元组，两个星号表示是一个dictionary</span></span><br><span class="line"><span class="comment"># 从运行的结果看，由原来的 tuple of tuple 变成了两个string of tuple，并没有list 什么事情</span></span><br><span class="line"></span><br><span class="line">raw_data_en, raw_data_fr = list(raw_data_en), list(raw_data_fr) <span class="comment"># from tuple to list 这个是转换了</span></span><br><span class="line">raw_data_en = [normalize_string(data) <span class="keyword">for</span> data <span class="keyword">in</span> raw_data_en]</span><br><span class="line"><span class="comment"># 这个是decoder的输入，decoder 是有两个输入的，一个是encoder的输出，一个是 其中一个start destination sentence， 最后是一个 end</span></span><br><span class="line"><span class="comment"># 是用来计算 loss的</span></span><br><span class="line">raw_data_fr_in = [<span class="string">'&lt;start&gt; '</span> + normalize_string(data) <span class="keyword">for</span> data <span class="keyword">in</span> raw_data_fr]</span><br><span class="line">raw_data_fr_out = [normalize_string(data) + <span class="string">' &lt;end&gt;'</span> <span class="keyword">for</span> data <span class="keyword">in</span> raw_data_fr] <span class="comment"># 这种操作比较简洁哈</span></span><br><span class="line"></span><br><span class="line">en_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=<span class="string">''</span>)</span><br><span class="line"><span class="comment"># 默认是会把 ? . or ! 去掉, 因为我们不想让其 filter 掉 上述三个字符，所有自己进行了处理</span></span><br><span class="line">en_tokenizer.fit_on_texts(raw_data_en)</span><br><span class="line">data_en = en_tokenizer.texts_to_sequences(raw_data_en)</span><br><span class="line"><span class="comment"># 这个padding 是为了之后创建 tf.data.Dataset object 使用的，所以还是比较nice的</span></span><br><span class="line">data_en = tf.keras.preprocessing.sequence.pad_sequences(data_en,</span><br><span class="line">                                                        padding=<span class="string">'post'</span>)</span><br><span class="line"></span><br><span class="line">fr_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=<span class="string">''</span>)</span><br><span class="line"><span class="comment"># 都是先使用 fit_on_texts() 然后才使用 texts_to_sequence() ，前者相当于训练，后者是输出的结果，我的理解</span></span><br><span class="line"><span class="comment"># A mid-way notice though, we can call fit_on_texts multiple times on different corpora and it will update vocabulary automatically.</span></span><br><span class="line"></span><br><span class="line">fr_tokenizer.fit_on_texts(raw_data_fr_in)</span><br><span class="line">fr_tokenizer.fit_on_texts(raw_data_fr_out)</span><br><span class="line">data_fr_in = fr_tokenizer.texts_to_sequences(raw_data_fr_in)</span><br><span class="line">data_fr_in = tf.keras.preprocessing.sequence.pad_sequences(data_fr_in,</span><br><span class="line">                                                           padding=<span class="string">'post'</span>)</span><br><span class="line"></span><br><span class="line">data_fr_out = fr_tokenizer.texts_to_sequences(raw_data_fr_out)</span><br><span class="line">data_fr_out = tf.keras.preprocessing.sequence.pad_sequences(data_fr_out,</span><br><span class="line">                                                            padding=<span class="string">'post'</span>)</span><br></pre></td></tr></table></figure>
<p>in addition：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 真正在做实验的时候需要注意的事情：</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 一种常见的手段就是 limit the size of the dataset to experiment faster (optimal)</span></span><br><span class="line"><span class="comment"># 使用tensorflow 中的dataset 的时候，有意识的 shuffle() 数据集 并且使用batch 的思想</span></span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)</span><br><span class="line">dataset = dataset.batch(BATCH_SIZE, drop_remainder=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># 这个和上面的语句是搭配使用的</span></span><br><span class="line">example_input_batch, example_target_batch = next(iter(dataset))</span><br><span class="line">example_input_batch.shape, example_target_batch.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 就是在真正的实验的过程中， 网络中的shape (batch_size, embedding_size, )</span></span><br><span class="line"><span class="comment"># 超级常用的处理的手段， preprocess_sentence() 是一个函数, apply(lambda )</span></span><br><span class="line">data[<span class="string">"eng"</span>] = data.eng.apply(<span class="keyword">lambda</span> w: preprocess_sentence(w))</span><br><span class="line">data[<span class="string">"es"</span>] = data.es.apply(<span class="keyword">lambda</span> w: preprocess_sentence(w))</span><br></pre></td></tr></table></figure>
<h3 id="keras-text-preprocessing"><a href="#keras-text-preprocessing" class="headerlink" title="keras text preprocessing"></a>keras text preprocessing</h3><p>这个版本的代码适用于小的数据量，因为当数据量达到百万的时候，应该使用batch 去训练模型，不应一下子读入到内存中，容易爆内存。比较有特点的 filter 中文的字符使用translate 进行处理。一般从经验上讲是不建议 filter 掉 “？。，” 这三个中文字符的，其他的可以filter 掉，对应英文中的 “? , .” 这三个字符。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> array, argmax, random, take</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_text</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="comment"># open the file</span></span><br><span class="line">    file = open(filename, mode=<span class="string">'rt'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="comment"># read all text</span></span><br><span class="line">    text = file.read()</span><br><span class="line">    file.close()</span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_lines</span><span class="params">(text)</span>:</span></span><br><span class="line">    sents = text.strip().split(<span class="string">'\n'</span>)</span><br><span class="line">    sents = [i.split(<span class="string">'\t'</span>) <span class="keyword">for</span> i <span class="keyword">in</span> sents]</span><br><span class="line">    <span class="keyword">return</span> sents</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_array</span><span class="params">(path, debug)</span>:</span></span><br><span class="line"></span><br><span class="line">    data =read_text(path)</span><br><span class="line">    <span class="keyword">import</span> gc</span><br><span class="line">   </span><br><span class="line">    eng_ch =to_lines(data)</span><br><span class="line">    <span class="keyword">del</span> data</span><br><span class="line">    gc.collect()</span><br><span class="line">    <span class="comment">#import ipdb</span></span><br><span class="line">    <span class="comment">#ipdb.set_trace()</span></span><br><span class="line"></span><br><span class="line">    eng_ch =np.asarray(eng_ch) <span class="comment"># max memory</span></span><br><span class="line">    <span class="comment">#eng_ch =np.asarray(eng_ch[:5000000])</span></span><br><span class="line">    <span class="keyword">if</span> debug:</span><br><span class="line">        <span class="comment">#eng_ch =eng_ch[:4, :]# just for chinese dict test</span></span><br><span class="line">        eng_ch =eng_ch[:<span class="number">2000</span>, :]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> eng_ch</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pre_process</span><span class="params">(eng_ch)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> jieba</span><br><span class="line">    cn_punctuation = <span class="string">"！？｡ ？。? ＃＄％＆ !（）. ＊＋－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾 〿–—‘ ’ ‛ “ ” „ ‟ …‧﹏"</span></span><br><span class="line"></span><br><span class="line">    eng_ch[:, <span class="number">0</span>] = [s.translate(str.maketrans(<span class="string">''</span>, <span class="string">''</span>, string.punctuation)) <span class="keyword">for</span> s <span class="keyword">in</span> eng_ch[:, <span class="number">0</span>]]</span><br><span class="line">    eng_ch[:, <span class="number">1</span>] = [s.translate(str.maketrans(<span class="string">''</span>, <span class="string">''</span>, cn_punctuation)) <span class="keyword">for</span> s <span class="keyword">in</span> eng_ch[:, <span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(eng_ch)):</span><br><span class="line">        eng_ch[i, <span class="number">0</span>] =eng_ch[i, <span class="number">0</span>].lower()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(eng_ch)):</span><br><span class="line">        seg_list =jieba.cut(eng_ch[i, <span class="number">1</span>])</span><br><span class="line">        eng_ch[i, <span class="number">1</span>] =<span class="string">' '</span>.join(seg_list)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> eng_ch</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sentence_length</span><span class="params">(eng_ch)</span>:</span></span><br><span class="line"></span><br><span class="line">    eng_l =[]</span><br><span class="line">    ch_l =[]</span><br><span class="line">    <span class="comment"># 这里需要看一下 english的数据是否前后有 空格</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> eng_ch[:, <span class="number">0</span>]:</span><br><span class="line">        eng_l.append(len(i.split()))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> eng_ch[:,<span class="number">1</span>]:</span><br><span class="line">        ch_l.append(len(i))</span><br><span class="line">    length_df =pd.DataFrame(&#123;<span class="string">'eng'</span>: eng_l, <span class="string">'ch'</span>:ch_l&#125;)</span><br><span class="line"></span><br><span class="line">    length_df.hist(bins =<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">    plt.savefig(<span class="string">'data-dist-cn.png'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenization</span><span class="params">(lines)</span>:</span></span><br><span class="line">    tokenizer = Tokenizer()</span><br><span class="line">    tokenizer.fit_on_texts(lines)</span><br><span class="line">    <span class="keyword">return</span> tokenizer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encode_sequences</span><span class="params">(tokenizer, length, lines)</span>:</span></span><br><span class="line">    seq =tokenizer.texts_to_sequences(lines)</span><br><span class="line">    seq = pad_sequences(seq, maxlen=length, padding=<span class="string">'post'</span>)</span><br><span class="line">    <span class="keyword">return</span> seq</span><br></pre></td></tr></table></figure>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/seq2seq/" rel="tag"># seq2seq</a>
          
            <a href="/tags/translation/" rel="tag"># translation</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/06/21/similarity-measures/" rel="next" title="Similarity Measures">
                <i class="fa fa-chevron-left"></i> Similarity Measures
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/06/29/nlp-papers-reading-machine-translation/" rel="prev" title="NLP Papers Reading-Machine Translation">
                NLP Papers Reading-Machine Translation <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpeg"
                alt="Jijeng Jia" />
            
              <p class="site-author-name" itemprop="name">Jijeng Jia</p>
              <p class="site-description motion-element" itemprop="description">Stay Hungry, Stay Foolish</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">62</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">39</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/jijeng" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:jia1509309698@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          <script type="text/javascript" src="//rf.revolvermaps.com/0/0/5.js?i=5kk0u0mm50w&amp;m=0&amp;c=54ff00&amp;cr1=ff0000" async="async"></script>

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#热身"><span class="nav-number">1.</span> <span class="nav-text">热身</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tensorflow-text-preprocessing"><span class="nav-number">2.</span> <span class="nav-text">tensorflow text preprocessing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#keras-text-preprocessing"><span class="nav-number">3.</span> <span class="nav-text">keras text preprocessing</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jijeng Jia</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>

<div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
Total  <span id="busuanzi_value_site_pv"></span> views
You got  <span id="busuanzi_value_site_uv"></span> visitors
</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://https-jijeng-github-io.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2019/06/28/seq2seq-translation-codes/';
          this.page.identifier = '2019/06/28/seq2seq-translation-codes/';
          this.page.title = 'Seq2Seq Translation (English to Chinese)';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://https-jijeng-github-io.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
