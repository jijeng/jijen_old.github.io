<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="LR,Decision tree," />










<meta name="description" content="本文主要介绍逻辑回归（logistics regression）和决策树（Decision Tree）。逻辑回归从线性回归出发到逻辑回归，然后手推公式和相关的一些特点；介绍一下决策树的特点。">
<meta name="keywords" content="LR,Decision tree">
<meta property="og:type" content="article">
<meta property="og:title" content="逻辑回归概念">
<meta property="og:url" content="http://yoursite.com/2019/06/09/lr/index.html">
<meta property="og:site_name" content="Jijeng&#39;s blog">
<meta property="og:description" content="本文主要介绍逻辑回归（logistics regression）和决策树（Decision Tree）。逻辑回归从线性回归出发到逻辑回归，然后手推公式和相关的一些特点；介绍一下决策树的特点。">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://ws1.sinaimg.cn/large/e9a223b5ly1g449t85fofj20rs075a9y.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g468268n4gj20jm04k0sn.jpg">
<meta property="og:image" content="https://s2.ax1x.com/2019/07/20/Zzs1Vf.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/07/20/Zzs3a8.png">
<meta property="og:updated_time" content="2019-07-20T07:07:20.475Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="逻辑回归概念">
<meta name="twitter:description" content="本文主要介绍逻辑回归（logistics regression）和决策树（Decision Tree）。逻辑回归从线性回归出发到逻辑回归，然后手推公式和相关的一些特点；介绍一下决策树的特点。">
<meta name="twitter:image" content="http://ws1.sinaimg.cn/large/e9a223b5ly1g449t85fofj20rs075a9y.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/06/09/lr/"/>







<script>
	(function(){
		if(''){
			if (prompt('请输入文章密码','') !== ''){
				alert('密码错误！');
				history.back();
			}
		}
	})();
</script>

  <title>逻辑回归概念 | Jijeng's blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jijeng's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/09/lr/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jijeng Jia">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jijeng's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">逻辑回归概念</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-06-09T12:08:16+08:00">
                2019-06-09
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-07-20T15:07:20+08:00">
                2019-07-20
              </time>
            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/06/09/lr/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/06/09/lr/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>本文主要介绍逻辑回归（logistics regression）和决策树（Decision Tree）。逻辑回归从线性回归出发到逻辑回归，然后手推公式和相关的一些特点；介绍一下决策树的特点。</p>
<a id="more"></a>
<h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><p>逻辑回归是线性模型，虽然叫做”回归“，究其原因 逻辑回归从线性回归引申而来，对回归的结果进行 logistic 函数运算，将范围限制在[0,1]区间，并更改损失函数为二值交叉熵损失，使其可用于2分类问题(通过得到的概率值与阈值比较进行分类)。<br>逻辑回归是广义上的线性模型，然后最后的sigmoid 加入了非线性。是处理线性问题的。</p>
<h3 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h3><p>从线性回归问题到逻辑回归过程的推导。</p>
<p><strong>线性二分模型：</strong></p>
<p>$$<br>f ( x ) = \theta ^ { T } x<br>$$</p>
<p>逻辑回归决策函数是将此线性二分类嵌套一个sigmoid函数：</p>
<p>$$<br> f ( x ) = \frac { 1 } { 1 + e ^ { - \theta ^ { T } x } }<br>$$</p>
<p><strong> 损失函数：</strong><br>如果用平方误差（MSE）作为逻辑回归的损失函数,那么函数曲线将是跳跃式的,非凸的(non-convex),原因是logistic函数将数据范围限制在[0,1]区间,而真实标签值非0即1.最小化 MSE 损失容易陷入局部极小点.逻辑回归损失是如下的分情况的凸函数(单个x与y的损失)。</p>
<p>$$<br>P ( y = 1 | x ; \theta ) = h _ { \theta } ( x )<br>$$</p>
<p>$$<br>P ( y = 0 | x ; \theta ) = 1 - h _ { \theta } ( x )<br>$$<br>最初是上述的分段函数，合并成下面的函数，方便计算。<br>$$<br>p ( y | x ; \theta ) = \left( h _ { \theta } ( x ) \right) ^ { y } \left( 1 - h _ { \theta } ( x ) \right) ^ { 1 - y }<br>$$<br>使用最大似然的思想求解。假设我们有n个独立的训练样本{(x1, y1) ,(x2, y2),…, (xn, yn)}，y={0, 1}。那每一个观察到的样本(xi, yi)出现的概率是：<br><img src="http://ws1.sinaimg.cn/large/e9a223b5ly1g449t85fofj20rs075a9y.jpg" alt=""></p>
<p>上述似然函数乘法太难算了，然后使用log 将其改为加法，变成了对数似然函数。<br>$$<br>J( \theta ) = \log ( L ( \theta ) ) = \sum _ { i = 1 } ^ { m } y ^ { ( i ) } \log \left( h \left( x ^ { ( i ) } \right) \right) + \left( 1 - y ^ { ( i ) } \right) \log \left( 1 - h \left( x ^ { ( i ) } \right) \right)<br>$$</p>
<p><strong>求导优化问题</strong><br>sigmoid 函数的特殊性质：<br>$$<br>\sigma ^ { \prime } ( x ) = \sigma ( x ) ( 1 - \sigma ( x ) )<br>$$</p>
<p>分成三部分求导：<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g468268n4gj20jm04k0sn.jpg" alt=""></p>
<p>用L(θ)对θ求导，得到：<br>$$<br>\begin{split}<br>\frac { d } { d \theta _ { i } } \operatorname { loss } ( \theta ) &amp;= \left( y \frac { 1 } { \sigma \left( \theta ^ { T } x \right) } - ( 1 - y ) \frac { 1 } { 1 - \sigma \left( \theta ^ { T } x \right) } \right) \frac { d } { d \theta _ { i } } \sigma \left( \theta ^ { T } x \right) \\<br>&amp;= \left( y \frac { 1 } { \sigma \left( \theta ^ { T } x \right) } - ( 1 - y ) \frac { 1 } { 1 - \sigma \left( \theta ^ { T } x \right) } \right) \sigma \left( \theta ^ { T } x \right) \left( 1 - \sigma \left( \theta ^ { T } x \right) \right) \frac { d } { d \theta _ { i } } \theta ^ { T } x \\<br>&amp;= \left( y \left( 1 - \sigma \left( \theta ^ { T } x \right) \right) - ( 1 - y ) \sigma \left( \theta ^ { T } x \right) \right) x _ { i } \\<br>&amp;= \left( y - h _ { \theta } ( x ) \right) x _ { i }<br>\end{split}<br>$$</p>
<p>注意一会儿有 $\sum$ 一会儿没有的，其实我们更倾向于不用，采用矩阵相乘的方式更加简洁。只是在表达似然函数，使用$ \sum$更加直观<br>$$<br>\theta _ { i } : = \theta _ { j } + \alpha \left( y ^ { ( i ) } - h _ { \theta } \left( x ^ { ( i ) } \right) \right) x _ { j } ^ { ( i ) }<br>$$</p>
<h3 id="逻辑回归的特点"><a href="#逻辑回归的特点" class="headerlink" title="逻辑回归的特点"></a>逻辑回归的特点</h3><p><strong> 优点：</strong><br> LR 能以概率的形式输出结果,而非只是 0,1 判定， 可以做 ranking model；<br> LR 的可解释性强,可控度高；<br> 训练快</p>
<p><strong> 缺点：</strong><br> 容易欠拟合，一般准确度不太高<br> 只能处理两分类问题. (可以应用多个逻辑回归实现多分类,类似SVM的方式; 另外对于父子类别同时分类的情况,使用逻辑回归要比Softmax等方式效果好)</p>
<p>“海量离散特征+简单模型” 同“少量连续特征+复杂模型”的权衡。既可以离散化用线性模型，也可以用连续特征加深度学习</p>
<p><strong> 为什么对特征进行离散化</strong></p>
<p>特征从连续变量状态到离散化的初衷在于我们认为不同的区间对于最后的结果的重要性是不同的。同样在工业界，很少直接将连续值作为逻辑回归模型的特征输入，而是将连续特征离散化为一系列0、1特征(one-hot编码)交给逻辑回归模型，这样做的优势有以下几点</p>
<ul>
<li>离散特征的增加和减少都很容易，易于模型的快速迭代；</li>
<li>稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展；</li>
<li>离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄&gt;30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰；</li>
<li>单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合</li>
<li>离散化后可以进行特征交叉</li>
</ul>
<p>究其原因，使用 LR+离散模型在于可控可解释。而GBDT 直接使用连续的变量，一方面的原因在于如果特征过多，那么GBDT 是跑不动的。</p>
<p><strong> 为什么LR模型的损失函数是交叉熵,而线性回归模型的损失函数却是最小二乘呢？能否随意确定一个损失函数作为目标呢？</strong></p>
<p>模型的损失函数由各自的响应变量y的概率分布决定，对于线性回归模型，其输出是连续值，所以我们对于该问题假设y服从正态分布；相对的，LR模型一般用来解决二分类问题，所以其输出是0/1，故而我们假设其输出服从伯努利分布；而进一步地，两者的损失函数都是通过极大似然估计推导的来的，所以模型的损失函数并非随意确定。<br>分类模型与回归模型之间有种种联系,比如 SVM 模型可以看作逻辑回归加L2正则项, 并使用了不同的损失函数.</p>
<p>为什么不使用回归模型来做分类?<br>这是一种不好的做法, 因为阈值不好确定, 随着数据集的变动, 阈值也需要有较大变化.</p>
<p><strong>正则项</strong></p>
<ul>
<li>L2 解决过拟合</li>
<li>L1 解决数据稀疏性 </li>
</ul>
<p><strong> L1和L2正则先验分别服从什么分布</strong><br>从信息论的角度看，向系统加入了正确先验这个信息，肯定会提高系统的性能。两者的差别感性的理解？L1是拉普拉斯分布，L2是高斯分布。<br>拉普拉斯分布：<br>$$<br>f ( x | \mu , b ) = \frac { 1 } { 2 b } e ^ { - \frac { | x - \mu | } { b } }<br>$$<br>高斯分布：<br>$$<br>f \left( x | \mu , \sigma ^ { 2 } \right) = \frac { 1 } { \sqrt { 2 \pi \sigma ^ { 2 } } } e ^ { - \frac { ( x - \mu ) ^ { 2 } } { 2 \sigma ^ { 2 } } }<br>$$</p>
<h2 id="Decision-tree"><a href="#Decision-tree" class="headerlink" title="Decision tree"></a>Decision tree</h2><p>主要介绍一下 决策树的特点。</p>
<p>从这次学习中明显的感受到这个 decision tree 是非常容易过拟合的。</p>
<blockquote>
<p>We can make our tree more complex by increasing its size , which will result in more and more partitions trying to emulate the circular boundary.</p>
</blockquote>
<p>优点在于：可以handle 非线性的变化。decision tree 给人的感觉就是线性或者离散的(category)的都是可以使用，因为decision tree 得到就是一个离散的结果，最大的缺点就是容易过拟合。 </p>
<blockquote>
<p>This brings us to the biggest problem associated with Decision Trees, that is, they are highly biased class of models. You can make a decision tree model on your training set which might outperform all other algorithms but it’ll prove to be a poor predictor on your test set. You’ll have to rely heavily on pruning and cross validation to get a non-over-fitting model with Decision Trees.</p>
</blockquote>
<p>过拟合是可以通过剪枝或者 cross validation 进行缓解 overfit的效果的或者使用 random forest随机性进行”中和“。</p>
<blockquote>
<p>This problem of over-fitting is overcome to large extent by using Random Forests, which are nothing but a very clever extension of decision trees. But random forest take away easy to explain business rules because now you have thousands of such trees and their majority votes to make things complex. Also by decision trees have forced interactions between variables , which makes them rather inefficient if most of your variables have no or very weak interactions.</p>
</blockquote>
<p><strong> 使用范围：</strong><br>1 数值型：数值型目标变量则可以从无限的数值集合中取值，如0.100，42.001等 (数值型目标变量主要用于回归分析)<br>2 标称型：标称型目标变量的结果只在有限目标集中取值，如真与假(标称型目标变量主要用于分类)</p>
<h3 id="决策树的工作原理"><a href="#决策树的工作原理" class="headerlink" title="决策树的工作原理"></a>决策树的工作原理</h3><p>原始的数据集：</p>
<p>编号    色泽    根蒂    敲声    纹理    脐部    触感    好瓜<br>1    青绿    蜷缩    浊响    清晰    凹陷    硬滑    是<br>2    乌黑    蜷缩    沉闷    清晰    凹陷    硬滑    是<br>3    乌黑    蜷缩    浊响    清晰    凹陷    硬滑    是<br>4    青绿    蜷缩    沉闷    清晰    凹陷    硬滑    是<br>5    浅白    蜷缩    浊响    清晰    凹陷    硬滑    是<br>6    青绿    稍蜷    浊响    清晰    稍凹    软粘    是<br>7    乌黑    稍蜷    浊响    稍糊    稍凹    软粘    是<br>8    乌黑    稍蜷    浊响    清晰    稍凹    硬滑    是<br>9    乌黑    稍蜷    沉闷    稍糊    稍凹    硬滑    否<br>10    青绿    硬挺    清脆    清晰    平坦    软粘    否<br>11    浅白    硬挺    清脆    模糊    平坦    硬滑    否<br>12    浅白    蜷缩    浊响    模糊    平坦    软粘    否<br>13    青绿    稍蜷    浊响    稍糊    凹陷    硬滑    否<br>14    浅白    稍蜷    沉闷    稍糊    凹陷    硬滑    否<br>15    乌黑    稍蜷    浊响    清晰    稍凹    软粘    否<br>16    浅白    蜷缩    浊响    模糊    平坦    硬滑    否<br>17    青绿    蜷缩    沉闷    稍糊    稍凹    硬滑    否</p>
<p><strong>信息熵和信息增益</strong></p>
<p>熵（entropy）： 熵指的是体系的混乱的程度<br>信息增益（information gain）： 在划分数据集前后信息发生的变化称为信息增益，信息增益越大，确定性越强。</p>
<p><strong> 决策树的生成过程就是 最优划分属性的选择的过程。 </strong> 一共有三种策略可以进行选择，大致分为了 ID3 [Quinlan, 1986]、C4.5 [Quinlan, 1993]、CART [Breiman et al., 1984] 三种。一般来说我们希望选择一个属性之后，其分支节点所包含的样本尽可能属于同一个类别，即结点的纯度 (purity)越来越高。</p>
<p><strong>ID3 树中最优划分属性计算举例</strong></p>
<p><strong>信息增益</strong><br>使用上面的数据集进行说明。在决策树学习开始时，根结点包含 𝐷 中所有样例，正例占 $p _ { 1 } = \frac { 8 } { 17 }$，反例占$ p_2=\frac{9}{17}$。根结点的信息熵（下面我们都以比特为单位计算）为：</p>
<p>$$<br>H ( D ) = - \sum _ { k = 1 } ^ { 2 } p ( k ) \log _ { 2 } p ( k ) = - \left( \frac { 7 } { 17 } \log _ { 2 } \frac { 7 } { 17 } + \frac { 9 } { 17 } \log _ { 2 } \frac { 9 } { 17 } \right) = 0.998<br>$$</p>
<p>然后我们要计算出与当前属性集合 {色泽、根蒂、敲声、纹理、脐部、触感}中每个属性的<strong><em> 信息增益，也就是对应的互信息</em></strong>。以属性“色泽”为例，它有 3 个可能取值：{青绿、乌黑、浅白}。以该属性对数据集进行划分，可以得到 3 个子集，分别为：$D_1(色泽=青绿) $、$ D_2(色泽=乌黑)$ 、$D_3(色泽=浅白)$。</p>
<p>对子集$ D_1$ 来说，包含了编号为 {1,4,6,10,13,17} 的 6 个样例，其中正例为 {1,4,6}，占$ p_1=36$ ；反例为 {10,13,17}，占 $p_1=36$。计算其熵为：<br>$$<br>H \left( D _ { 1 } \right) = - \left( \frac { 3 } { 6 } \log _ { 2 } \frac { 3 } { 6 } + \frac { 3 } { 6 } \log _ { 2 } \frac { 3 } { 6 } \right) = 1.000<br>$$</p>
<p>依次可以计算另外两个子集的信息熵为：<br>$$<br>H \left( D _ { 2 } \right) = 0.918<br>$$<br>$$<br>H \left( D _ { 3 } \right) = 0.722<br>$$<br>最终可以计算数据集 $D$ 的类别信息在属性“色泽”熵的信息增益（也可以理解为类别与“色泽”属性之间的互信息）为：</p>
<p>$$<br>\begin{split}<br>Gain(D, 色泽) &amp;= H ( D ) - \sum _ { v = 1 } ^ { 3 } p ( v ) H \left( D _ { v } \right) \\<br>&amp;= 0.998 - \left( \frac { 6 } { 17 } \times 1.000 + \frac { 6 } { 17 } \times 0.918 + \frac { 5 } { 17 } \times 0.722 \right) \\<br>&amp;= 0.109<br>\end{split}<br>$$<br>重复上述的计算步骤，我们可以计算出其他属性的信息增益：</p>
<p>$$<br>\begin{split}<br>Gain(𝐷,根蒂)  &amp;=0.143 \\<br>Gain(𝐷,敲声) &amp;= 0.141 \\<br>Gain(𝐷,纹理) &amp;= 0.381\\<br>Gain(𝐷,脐部) &amp;= 0.289 \\<br>Gain(𝐷,触感) &amp;=0.006<br>\end{split}<br>$$</p>
<p>经过比较，发现采用“纹理”进行划分得到的信息增益最大，于是它被选为划分属性。下图给出了根据“纹理”属性划分之后的数据子集：</p>
<p><img src="https://s2.ax1x.com/2019/07/20/Zzs1Vf.png" alt="Zzs1Vf.png"></p>
<p>对每一个数据子集按照上边的步骤继续划分下去就能得到最终的决策树（需要注意的是每次样例子集中的属性不包含父结点中划分所依赖的属性），如下图所示：</p>
<p><img src="https://s2.ax1x.com/2019/07/20/Zzs3a8.png" alt="Zzs3a8.png"></p>
<p><strong> 信息增益率 </strong></p>
<p>采用信息增益来进行划分属性的决策有一个潜在的问题，当某一个属性的取值种类非常多时，对应每一个属性取值的样本子集，其分类的信息熵可能会变得很小。</p>
<p>$$<br>\begin{split}<br>Gain ( D , a ) &amp;= H ( D ) - \sum _ { v = 1 } ^ { V } \frac { \left| D _ { v } \right| } { | D | } H \left( \left| D _ { v } \right| \right) \\<br>&amp;= - \frac { 8 } { 17 } \log _ { 2 } \frac { 8 } { 17 } - \frac { 8 } { 17 } \log _ { 2 } \frac { 8 } { 17 } - \sum _ { v = 1 } ^ { 17 } \frac { 1 } { 17 } \times 0 \\<br>&amp;= 0.9975<br>\end{split}<br>$$<br>最后计算出来的信息增益很大。但是显然，用“编号”属性来作为结点的划分是没有意义的。思考其中的问题在于，对数函数并不是线性的，信息量的减少速度大于类别数量的增加速度。信息增益准则对取值数目较多的属性有所偏好，为了减小这种偏好，C4.5 决策树 采用 信息增益率 (gain ratio) 来选择最优划分属性。其定义如下：<br>$$<br>Gain_ { \mathrm { ratio } } ( D , a ) = \frac { \operatorname { Gain } ( \mathrm { D } , \mathrm { a } ) } { \mathrm { IV } ( \mathrm { a } ) }<br>$$</p>
<p>其中<br>$$<br>\mathrm { IV } ( a ) = - \sum _ { v = 1 } ^ { V } \frac { \left| D _ { v } \right| } { | D | } \log \frac { \left| D _ { v } \right| } { | D | } = H ( a )<br>$$<br>到这里，我们就可以发现，信息增益率是用属性分类的信息熵对由属性分类引起的互信息熵进行了归一。属性的种类越多其信息熵通常也会越大。</p>
<p>最后一点需要注意的是，增益率准则虽然减少了对取值数目较多的属性依赖，但是增加了对取值数目较少的属性偏好。因此， C4.5 并没有直接选择增益率最大的候选划分属性，而是使用了一个启发式：先从候选划分属性中找出 信息增益 高于 平均水平 的属性，再从中选择 增益率 最高的。</p>
<p><strong>基尼指数 - CART</strong></p>
<p>最后介绍一种选择划分属性的依据是使用 基尼指数 (Gini index)。数据集合 𝐷 的纯度可用基尼指数来度量：<br>$$<br>Gini ( D ) = \sum _ { k = 1 } ^ { | \mathcal { Y } | } \sum _ { k ^ { \prime } \neq k } p _ { k } p _ { k ^ { \prime } } = 1 - \sum _ { k = 1 } ^ { \mathcal { V } } p _ { k } ^ { 2 }<br>$$<br>直观来看，$Gini(𝐷) $ 反映了从数据集 𝐷 中随机抽取两个样本，其类别标记不一致的概率。因此，$Gini(𝐷) $ 越小，则数据集 𝐷 的纯度越高。</p>
<p>对特定属性 𝑎 的基尼指数定义如下：<br>$$<br>Gini_{index}( D , a ) = \sum _ { v = 1 } ^ { V } \frac { \left| D _ { v } \right| } { | D | } \operatorname { Gini } \left( D _ { v } \right)</p>
<p>$$<br>我们在候选属性集合 𝐴 中，选择那个使得划分后基尼指数最小的属性作为最优划分属性，即：</p>
<p>$$<br>a _ { * } = \arg \min _ { a \in A } Gini_{index } ( D , a )<br>$$</p>
<p>采用基尼指数作为划分属性的判据的决策树是一种 CART 决策树。</p>
<h3 id="决策树的优缺点"><a href="#决策树的优缺点" class="headerlink" title="决策树的优缺点"></a>决策树的优缺点</h3><p>优点：</p>
<p>决策树易于理解（能够写出判断的路径，逻辑表达式）和实现， 人们知道该如何去优化。<br>可以处理缺省数据，意味着数据的准备工作是比较简单的。相对比其他的技术，往往需要一般化之类的操作。<br>能够处理数值型和常规性属性。</p>
<p>缺点：</p>
<p>容易过拟合<br>对于各个类别不一致的数据，决策树当中信息增益的结果偏向于那些具有更多数值的特征。</p>
<p><strong>参考文献</strong></p>
<p><a href="https://www.anmou.me/20180722-Decision_Tree/" target="_blank" rel="noopener">决策树及决策树生成与剪枝</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/LR/" rel="tag"># LR</a>
          
            <a href="/tags/Decision-tree/" rel="tag"># Decision tree</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/06/08/svm-all-you-need/" rel="next" title="SVM All You Need to Know">
                <i class="fa fa-chevron-left"></i> SVM All You Need to Know
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/06/16/leetcode-array/" rel="prev" title="LeetCode- Array">
                LeetCode- Array <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpeg"
                alt="Jijeng Jia" />
            
              <p class="site-author-name" itemprop="name">Jijeng Jia</p>
              <p class="site-description motion-element" itemprop="description">Stay Hungry, Stay Foolish</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">63</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">39</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/jijeng" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:jia1509309698@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          <script type="text/javascript" src="//rf.revolvermaps.com/0/0/5.js?i=5kk0u0mm50w&amp;m=0&amp;c=54ff00&amp;cr1=ff0000" async="async"></script>

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#逻辑回归"><span class="nav-number">1.</span> <span class="nav-text">逻辑回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#公式推导"><span class="nav-number">1.1.</span> <span class="nav-text">公式推导</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#逻辑回归的特点"><span class="nav-number">1.2.</span> <span class="nav-text">逻辑回归的特点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Decision-tree"><span class="nav-number">2.</span> <span class="nav-text">Decision tree</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#决策树的工作原理"><span class="nav-number">2.1.</span> <span class="nav-text">决策树的工作原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#决策树的优缺点"><span class="nav-number">2.2.</span> <span class="nav-text">决策树的优缺点</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jijeng Jia</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>

<div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
Total  <span id="busuanzi_value_site_pv"></span> views
You got  <span id="busuanzi_value_site_uv"></span> visitors
</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://https-jijeng-github-io.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2019/06/09/lr/';
          this.page.identifier = '2019/06/09/lr/';
          this.page.title = '逻辑回归概念';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://https-jijeng-github-io.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
