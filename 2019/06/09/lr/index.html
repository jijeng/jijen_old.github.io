<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="LR," />










<meta name="description" content="本文主要介绍逻辑回归（logistics regression）和决策树（Decision Tree）。逻辑回归从线性回归出发到逻辑回归，然后手推公式和相关的一些特点；介绍一下决策树的特点。">
<meta name="keywords" content="LR">
<meta property="og:type" content="article">
<meta property="og:title" content="逻辑回归概念">
<meta property="og:url" content="http://yoursite.com/2019/06/09/lr/index.html">
<meta property="og:site_name" content="Jijeng&#39;s blog">
<meta property="og:description" content="本文主要介绍逻辑回归（logistics regression）和决策树（Decision Tree）。逻辑回归从线性回归出发到逻辑回归，然后手推公式和相关的一些特点；介绍一下决策树的特点。">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://ws1.sinaimg.cn/large/e9a223b5ly1g449t85fofj20rs075a9y.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g468268n4gj20jm04k0sn.jpg">
<meta property="og:updated_time" content="2019-11-23T04:02:54.281Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="逻辑回归概念">
<meta name="twitter:description" content="本文主要介绍逻辑回归（logistics regression）和决策树（Decision Tree）。逻辑回归从线性回归出发到逻辑回归，然后手推公式和相关的一些特点；介绍一下决策树的特点。">
<meta name="twitter:image" content="http://ws1.sinaimg.cn/large/e9a223b5ly1g449t85fofj20rs075a9y.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/06/09/lr/"/>







<script>
	(function(){
		if(''){
			if (prompt('请输入文章密码','') !== ''){
				alert('密码错误！');
				history.back();
			}
		}
	})();
</script>

  <title>逻辑回归概念 | Jijeng's blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jijeng's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/09/lr/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jijeng Jia">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jijeng's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">逻辑回归概念</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-06-09T12:08:16+08:00">
                2019-06-09
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-11-23T12:02:54+08:00">
                2019-11-23
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/06/09/lr/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/06/09/lr/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>本文主要介绍逻辑回归（logistics regression）和决策树（Decision Tree）。逻辑回归从线性回归出发到逻辑回归，然后手推公式和相关的一些特点；介绍一下决策树的特点。</p>
<a id="more"></a>
<h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><p>逻辑回归是线性模型，虽然叫做”回归“，究其原因 逻辑回归从线性回归引申而来，对回归的结果进行 logistic 函数运算，将范围限制在[0,1]区间，并更改损失函数为二值交叉熵损失，使其可用于2分类问题(通过得到的概率值与阈值比较进行分类)。<br>逻辑回归是广义上的线性模型，然后最后的sigmoid 加入了非线性。是处理线性问题的。</p>
<h3 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h3><p>从线性回归问题到逻辑回归过程的推导。</p>
<p><strong>线性二分模型：</strong></p>
<p>$$<br>f ( x ) = \theta ^ { T } x<br>$$</p>
<p>逻辑回归决策函数是将此线性二分类嵌套一个sigmoid函数：</p>
<p>$$<br> f ( x ) = \frac { 1 } { 1 + e ^ { - \theta ^ { T } x } }<br>$$</p>
<p><strong> 损失函数：</strong><br>如果用平方误差（MSE）作为逻辑回归的损失函数,那么函数曲线将是跳跃式的,非凸的(non-convex),原因是logistic函数将数据范围限制在[0,1]区间,而真实标签值非0即1.最小化 MSE 损失容易陷入局部极小点.逻辑回归损失是如下的分情况的凸函数(单个x与y的损失)。</p>
<p>$$<br>P ( y = 1 | x ; \theta ) = h _ { \theta } ( x )<br>$$</p>
<p>$$<br>P ( y = 0 | x ; \theta ) = 1 - h _ { \theta } ( x )<br>$$<br>最初是上述的分段函数，合并成下面的函数，方便计算。<br>$$<br>p ( y | x ; \theta ) = \left( h _ { \theta } ( x ) \right) ^ { y } \left( 1 - h _ { \theta } ( x ) \right) ^ { 1 - y }<br>$$<br>使用最大似然的思想求解。假设我们有n个独立的训练样本{(x1, y1) ,(x2, y2),…, (xn, yn)}，y={0, 1}。那每一个观察到的样本(xi, yi)出现的概率是：<br><img src="http://ws1.sinaimg.cn/large/e9a223b5ly1g449t85fofj20rs075a9y.jpg" alt=""></p>
<p>上述似然函数乘法太难算了，然后使用log 将其改为加法，变成了对数似然函数。<br>$$<br>J( \theta ) = \log ( L ( \theta ) ) = \sum _ { i = 1 } ^ { m } y ^ { ( i ) } \log \left( h \left( x ^ { ( i ) } \right) \right) + \left( 1 - y ^ { ( i ) } \right) \log \left( 1 - h \left( x ^ { ( i ) } \right) \right)<br>$$</p>
<p><strong>求导优化问题</strong><br>sigmoid 函数的特殊性质：<br>$$<br>\sigma ^ { \prime } ( x ) = \sigma ( x ) ( 1 - \sigma ( x ) )<br>$$</p>
<p>分成三部分求导：<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g468268n4gj20jm04k0sn.jpg" alt=""></p>
<p>用L(θ)对θ求导，得到：<br>$$<br>\begin{split}<br>\frac { d } { d \theta _ { i } } \operatorname { loss } ( \theta ) &amp;= \left( y \frac { 1 } { \sigma \left( \theta ^ { T } x \right) } - ( 1 - y ) \frac { 1 } { 1 - \sigma \left( \theta ^ { T } x \right) } \right) \frac { d } { d \theta _ { i } } \sigma \left( \theta ^ { T } x \right) \\<br>&amp;= \left( y \frac { 1 } { \sigma \left( \theta ^ { T } x \right) } - ( 1 - y ) \frac { 1 } { 1 - \sigma \left( \theta ^ { T } x \right) } \right) \sigma \left( \theta ^ { T } x \right) \left( 1 - \sigma \left( \theta ^ { T } x \right) \right) \frac { d } { d \theta _ { i } } \theta ^ { T } x \\<br>&amp;= \left( y \left( 1 - \sigma \left( \theta ^ { T } x \right) \right) - ( 1 - y ) \sigma \left( \theta ^ { T } x \right) \right) x _ { i } \\<br>&amp;= \left( y - h _ { \theta } ( x ) \right) x _ { i }<br>\end{split}<br>$$</p>
<p>注意一会儿有 $\sum$ 一会儿没有的，其实我们更倾向于不用，采用矩阵相乘的方式更加简洁。只是在表达似然函数，使用$ \sum$更加直观<br>$$<br>\theta _ { i } : = \theta _ { j } + \alpha \left( y ^ { ( i ) } - h _ { \theta } \left( x ^ { ( i ) } \right) \right) x _ { j } ^ { ( i ) }<br>$$</p>
<h3 id="为什么使用-logistics-function"><a href="#为什么使用-logistics-function" class="headerlink" title="为什么使用 logistics function"></a>为什么使用 logistics function</h3><p>一种解释是可以。</p>
<ul>
<li>sigmoid 函数连续，单调递增</li>
<li>对 sigmoid 函数求导非常的方便</li>
<li>可以将负无穷到正无穷的数值映射到 [0, 1] 这样的区间</li>
</ul>
<p>另外一种维度是从伯努利分布的角度去解释。</p>
<p>$$<br>f(x ; p)=p^{x}(1-p)^{1-x} \quad x=0,1<br>$$<br>其中 $p$ 是成功的概率。如果进行一次投掷，那么均值是 $p$ 方差是 $p (1-p)$。 然后再看二分类任务，样本的标签$y$ 服从二项分布。</p>
<p>$$<br>p ( y | x ; \theta ) = \left( h _ { \theta } ( x ) \right) ^ { y } \left( 1 - h _ { \theta } ( x ) \right) ^ { 1 - y }<br>$$<br>详细的推导可以看这里：</p>
<p>[img]<a href="https://ftp.bmp.ovh/imgs/2019/09/39e481f9fd958d4b.png[/img]" target="_blank" rel="noopener">https://ftp.bmp.ovh/imgs/2019/09/39e481f9fd958d4b.png[/img]</a></p>
<h3 id="逻辑回归的特点"><a href="#逻辑回归的特点" class="headerlink" title="逻辑回归的特点"></a>逻辑回归的特点</h3><p><strong> 优点：</strong><br> LR 能以概率的形式输出结果,而非只是 0,1 判定， 可以做 ranking model；<br> LR 的可解释性强,可控度高；<br> 训练快</p>
<p><strong> 缺点：</strong><br> 容易欠拟合，一般准确度不太高<br> 只能处理两分类问题. (可以应用多个逻辑回归实现多分类,类似SVM的方式; 另外对于父子类别同时分类的情况,使用逻辑回归要比Softmax等方式效果好)</p>
<p>“海量离散特征+简单模型” 同“少量连续特征+复杂模型”的权衡。既可以离散化用线性模型，也可以用连续特征加深度学习</p>
<p><strong> 为什么对特征进行离散化</strong></p>
<p>特征从连续变量状态到离散化的初衷在于我们认为不同的区间对于最后的结果的重要性是不同的。同样在工业界，很少直接将连续值作为逻辑回归模型的特征输入，而是将连续特征离散化为一系列0、1特征(one-hot编码)交给逻辑回归模型，这样做的优势有以下几点</p>
<ul>
<li>离散特征的增加和减少都很容易，易于模型的快速迭代；</li>
<li>稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展；</li>
<li>离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄&gt;30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰；</li>
<li>单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合</li>
<li>离散化后可以进行特征交叉</li>
</ul>
<p>究其原因，使用 LR+离散模型在于可控可解释。而GBDT 直接使用连续的变量，一方面的原因在于如果特征过多，那么GBDT 是跑不动的。</p>
<p><strong> 为什么LR模型的损失函数是交叉熵,而线性回归模型的损失函数却是最小二乘呢？能否随意确定一个损失函数作为目标呢？</strong></p>
<p>模型的损失函数由各自的响应变量y的概率分布决定，对于线性回归模型，其输出是连续值，所以我们对于该问题假设y服从正态分布；相对的，LR模型一般用来解决二分类问题，所以其输出是0/1，故而我们假设其输出服从伯努利分布；而进一步地，两者的损失函数都是通过极大似然估计推导的来的，所以模型的损失函数并非随意确定。<br>分类模型与回归模型之间有种种联系,比如 SVM 模型可以看作逻辑回归加L2正则项, 并使用了不同的损失函数.</p>
<p>为什么不使用回归模型来做分类?<br>这是一种不好的做法, 因为阈值不好确定, 随着数据集的变动, 阈值也需要有较大变化.</p>
<p><strong>正则项</strong></p>
<ul>
<li>L2 解决过拟合</li>
<li>L1 解决数据稀疏性 </li>
</ul>
<p><strong> L1和L2正则先验分别服从什么分布</strong><br>从信息论的角度看，向系统加入了正确先验这个信息，肯定会提高系统的性能。两者的差别感性的理解？L1是拉普拉斯分布，L2是高斯分布。<br>拉普拉斯分布：<br>$$<br>f ( x | \mu , b ) = \frac { 1 } { 2 b } e ^ { - \frac { | x - \mu | } { b } }<br>$$<br>高斯分布：<br>$$<br>f \left( x | \mu , \sigma ^ { 2 } \right) = \frac { 1 } { \sqrt { 2 \pi \sigma ^ { 2 } } } e ^ { - \frac { ( x - \mu ) ^ { 2 } } { 2 \sigma ^ { 2 } } }<br>$$</p>
<h2 id="Decision-tree"><a href="#Decision-tree" class="headerlink" title="Decision tree"></a>Decision tree</h2><p>主要介绍一下 决策树的特点。</p>
<p>从这次学习中明显的感受到这个 decision tree 是非常容易过拟合的。</p>
<blockquote>
<p>We can make our tree more complex by increasing its size , which will result in more and more partitions trying to emulate the circular boundary.</p>
</blockquote>
<p>优点在于：可以handle 非线性的变化。decision tree 给人的感觉就是线性或者离散的(category)的都是可以使用，因为decision tree 得到就是一个离散的结果，最大的缺点就是容易过拟合。 </p>
<blockquote>
<p>This brings us to the biggest problem associated with Decision Trees, that is, they are highly biased class of models. You can make a decision tree model on your training set which might outperform all other algorithms but it’ll prove to be a poor predictor on your test set. You’ll have to rely heavily on pruning and cross validation to get a non-over-fitting model with Decision Trees.</p>
</blockquote>
<p>过拟合是可以通过剪枝或者 cross validation 进行缓解 overfit的效果的或者使用 random forest随机性进行”中和“。</p>
<blockquote>
<p>This problem of over-fitting is overcome to large extent by using Random Forests, which are nothing but a very clever extension of decision trees. But random forest take away easy to explain business rules because now you have thousands of such trees and their majority votes to make things complex. Also by decision trees have forced interactions between variables , which makes them rather inefficient if most of your variables have no or very weak interactions.</p>
</blockquote>
<h2 id="LR-vs-SVM"><a href="#LR-vs-SVM" class="headerlink" title="LR vs. SVM"></a>LR vs. SVM</h2><p>单独<a href="https://jijeng.github.io/2019/06/08/svm-all-you-need/" target="_blank" rel="noopener">讲解SVM</a>。这里主要是比较两种的异同。</p>
<p><strong>相同点</strong></p>
<ol>
<li>LR和SVM都是分类算法。（svm 可以作为回归模型）</li>
<li>LR和SVM都是监督学习算法。监督是体现在有标签。</li>
<li>两者都属于判别模型。（相对于bayes 模型）</li>
</ol>
<p>判别模型会生成一个表示$P(Y|X) $的判别函数（或预测模型），而生成模型先计算联合概率$P(Y,X) $然后通过贝叶斯公式转化为条件概率。常见的判别模型有：：KNN、SVM、LR。常见的生成模型有：朴素贝叶斯，隐马尔可夫模型。</p>
<p><strong>不同点</strong></p>
<p>从数据和模型的角度分析。</p>
<ol>
<li>数据</li>
</ol>
<p>SVM 中边界附近的点会起到决策的作用，在线上的点叫做支持向量。而LR 是全局信息，全部的数据集都会参与到决策， 如果数据是严重的 unbalanced, 那么需要是对数据进行 balance 操作，因为模型是依赖于数据概率分布。</p>
<ol start="2">
<li>loss function 的不同</li>
</ol>
<p>LR 的损失函数</p>
<p>$$<br>J( \theta ) = \log ( L ( \theta ) ) = \sum _ { i = 1 } ^ { m } y ^ { ( i ) } \log \left( h \left( x ^ { ( i ) } \right) \right) + \left( 1 - y ^ { ( i ) } \right) \log \left( 1 - h \left( x ^ { ( i ) } \right) \right)<br>$$</p>
<p>SVM的损失函数(在线性的可分的条件下)</p>
<p>$$<br>L ( w , b , \alpha ) = \frac { 1 } { 2 } | w | ^ { 2 } + \sum _ { i } \alpha _ { i } [ 1 - y _ { i } ( w ^ { T } x _ { i } + b ) ]<br>$$<br>(本质上使用拉格朗日进行最小化的求解)</p>
<ol start="3">
<li>数据预处理</li>
</ol>
<p>简单来说，​逻辑回归方法基于概率理论，一个样本通过sigmoid 函数进行概率表示，然后使用极大似然的方式估计出参数的值。支持向量是基于几何间隔最大化原理，存在几何间隔最大的超平面，基于几何距离的测量函数，一般需要对数据做normalization，而LR 则不受这个因素影响。</p>
<ol start="4">
<li>增量训练</li>
</ol>
<p>当训练好一个 SVM 和LR，然后来了一批新的数据，对于SVM 的决策平面变化比较小，而对于LR 就是要重新进行训练。</p>
<ol start="5">
<li>正则项</li>
</ol>
<p>SVM 的损失函数中自带正则 ($ \frac { 1 } { 2 } | w | ^ { 2 }$, 这就类似L2 正则项)，这就是为什么SVM是结构风险最小化算法的原因。（所谓结构风险最小化，意思就是在训练误差和模型复杂度之间寻求平衡，防止过拟合）。而LR 想要得到更好的泛化性能，需要手动加上正则项。</p>
<p><strong>选择标准</strong>（吴恩达课程）</p>
<p>n是数据中特征的数量 m是样本数</p>
<p>1、如果n相对于m来说很大，则使用LR算法或者不带核函数的SVM（线性分类）<br>n远大于m，n=10000，m=10-1000<br>2、如果n很小，m的数量适中（n=1-1000，m=10-10000）<br>使用带有核函数的SVM算法<br>3、如果n很小，m很大（n=1-1000，m=50000+）<br>增加更多的feature然后使用LR算法或者不带核函数的SVM<br>LR和不带核函数的SVM比较类似。</p>
<p>简单说，如果特征相对于数据量来说很大，那么使用 LR或者线性SVM 算法；如果相反，那么使用带有核函数的SVM。</p>
<h2 id="总结分类模型区别"><a href="#总结分类模型区别" class="headerlink" title="总结分类模型区别"></a>总结分类模型区别</h2><p>LR  vs. SVM  vs. Bayes</p>
<p><strong>数据</strong></p>
<p>LR 数据处理是 balanced（依赖于概率分布）；SVM 一般是要normalization（空间距离函数）</p>
<p><strong>loss function</strong></p>
<p>LR 是log loss，使用最大似然估计求解 \theta ； SVM 是拉格朗日定量求解。</p>
<p><strong>正则项</strong></p>
<p>LR 需要手动加上；SVM自带，SVM是结构风险最小化算法的</p>
<p><strong>增量学习</strong><br>LR 收到新来的数据的影响， SVM 不受（基本上只是依赖 支持向量 的点），bayes 支持增量学习。</p>
<p><strong>实战</strong><br>LR 和不带核函数的SVM 比较类似。（基本上可以互用）</p>
<p>m 是样本数（数据量），n 是特征数<br>特征数n 远大于数据量 m，选择LR 模型 （n =1w，m&lt; 1000）<br>特征n 小，m 适中 （n &lt; 1000, m ~1w）使用带有核函数的SVM 算法<br>特征n 很小，m 很大 （m &gt; 5w） 增加特征</p>
<h2 id="LR-和朴素贝叶斯的区别"><a href="#LR-和朴素贝叶斯的区别" class="headerlink" title="LR 和朴素贝叶斯的区别"></a>LR 和朴素贝叶斯的区别</h2>
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/LR/" rel="tag"># LR</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/06/09/笔试总结/" rel="next" title="笔试总结">
                <i class="fa fa-chevron-left"></i> 笔试总结
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/06/16/attention/" rel="prev" title="注意力机制介绍">
                注意力机制介绍 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpeg"
                alt="Jijeng Jia" />
            
              <p class="site-author-name" itemprop="name">Jijeng Jia</p>
              <p class="site-description motion-element" itemprop="description">Stay Hungry, Stay Foolish</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">101</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">66</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/jijeng" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:jia1509309698@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          <script type="text/javascript" src="//rf.revolvermaps.com/0/0/5.js?i=5kk0u0mm50w&amp;m=0&amp;c=54ff00&amp;cr1=ff0000" async="async"></script>


  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
  <script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <script src="//cdn.bootcss.com/blueimp-md5/1.1.0/js/md5.min.js"></script>
  <script>
      var gitalk = new Gitalk({
        clientID: '8c6403951ee3eab4e420',
        clientSecret: 'd842e48ca0c28ec41200f973ba52f96ba975b441',
        repo: 'jijeng.github.io',
        owner: 'jia1509309698@163.com',
        admin: 'jia1509309698@163.com',
        id: md5(location.pathname),
        distractionFreeMode: 'true'
      });
      var div = document.createElement('div');
      div.setAttribute("id", "gitalk_comments");
      div.setAttribute("class", "post-nav");
      var bro = document.getElementById('posts').getElementsByTagName('article');
      bro = bro[0].getElementsByClassName('post-block');
      bro = bro[0].getElementsByTagName('footer');
      bro = bro[0];
      bro.appendChild(div);
      gitalk.render('gitalk_comments');
  </script>

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#逻辑回归"><span class="nav-number">1.</span> <span class="nav-text">逻辑回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#公式推导"><span class="nav-number">1.1.</span> <span class="nav-text">公式推导</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么使用-logistics-function"><span class="nav-number">1.2.</span> <span class="nav-text">为什么使用 logistics function</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#逻辑回归的特点"><span class="nav-number">1.3.</span> <span class="nav-text">逻辑回归的特点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Decision-tree"><span class="nav-number">2.</span> <span class="nav-text">Decision tree</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LR-vs-SVM"><span class="nav-number">3.</span> <span class="nav-text">LR vs. SVM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结分类模型区别"><span class="nav-number">4.</span> <span class="nav-text">总结分类模型区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LR-和朴素贝叶斯的区别"><span class="nav-number">5.</span> <span class="nav-text">LR 和朴素贝叶斯的区别</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jijeng Jia</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>

<div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
Total  <span id="busuanzi_value_site_pv"></span> views
You got  <span id="busuanzi_value_site_uv"></span> visitors
</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://https-jijeng-github-io.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2019/06/09/lr/';
          this.page.identifier = '2019/06/09/lr/';
          this.page.title = '逻辑回归概念';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://https-jijeng-github-io.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
   <script type="text/javascript">
        var gitalk = new Gitalk({
          clientID: '',
          clientSecret: '',
          repo: 'jijeng.github.io',
          owner: '',
          admin: [''],
          id: location.pathname,
          distractionFreeMode: ''
        })
        gitalk.render('gitalk-container')           
       </script>


  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
