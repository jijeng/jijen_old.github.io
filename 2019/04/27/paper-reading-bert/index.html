<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="æ€»ç»“ GPT, ELMO å’ŒBERT æ¨¡å‹ã€‚">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP Papers Reading- BERT">
<meta property="og:url" content="http://yoursite.com/2019/04/27/paper-reading-bert/index.html">
<meta property="og:site_name" content="Jijeng&#39;s blog">
<meta property="og:description" content="æ€»ç»“ GPT, ELMO å’ŒBERT æ¨¡å‹ã€‚">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3env74i1dj20rs0f8dge.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3enz4w1tmj21bu0r0q6v.jpg">
<meta property="og:image" content="https://upload.cc/i1/2019/07/19/w5lozQ.png">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eo6o8obxj20l00d6wee.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eo7eiu73j20rs0i342d.jpg">
<meta property="og:image" content="https://i.bmp.ovh/imgs/2019/07/cc9c0e4d7401f315.png">
<meta property="og:image" content="https://i.loli.net/2019/07/19/5d31a365bd27877659.png">
<meta property="og:image" content="https://i.loli.net/2019/07/19/5d31a58f26ba185562.png">
<meta property="og:image" content="https://i.loli.net/2019/07/19/5d31b16df013d57040.png">
<meta property="og:image" content="https://i.loli.net/2019/07/19/5d31b16de13f475380.png">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3enq6lqouj20uq0eoq4u.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3ep38emyqj20bl03o3zj.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3ftfz3uxij206e088aa2.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eobewbqoj20c50bhq4y.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eof674adj20ii0dfgoe.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3fub67ulaj20u20h3wfx.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3fubpu9ibj20li0m1q5b.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3fuc693mrj211z0hbjur.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3fuci4xodj213j0kitcq.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3flokoc0mj20ab07474a.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3dw277xiyj20pi0c10ww.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3dvg2o3wwj20qo0grdgp.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eqwkv9tlj20kd097gm4.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eqyoxmknj20ey0d640u.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3esxw2nilj20dh08ujth.jpg">
<meta property="og:image" content="https://upload.cc/i1/2019/08/04/2VsB5g.png">
<meta property="og:image" content="https://i.loli.net/2019/08/31/mJVuLDAM1sOXrYE.png">
<meta property="og:image" content="https://i.bmp.ovh/imgs/2019/07/6c304cd1ba04192c.png">
<meta property="og:image" content="https://i.loli.net/2019/08/31/iKZ1mdzIfgEtraS.png">
<meta property="og:image" content="https://upload.cc/i1/2019/10/04/cVA3uE.jpg">
<meta property="og:updated_time" content="2019-12-14T14:15:18.951Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="NLP Papers Reading- BERT">
<meta name="twitter:description" content="æ€»ç»“ GPT, ELMO å’ŒBERT æ¨¡å‹ã€‚">
<meta name="twitter:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g3env74i1dj20rs0f8dge.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/04/27/paper-reading-bert/">







<script>
	(function(){
		if(''){
			if (prompt('è¯·è¾“å…¥æ–‡ç« å¯†ç ','') !== ''){
				alert('å¯†ç é”™è¯¯ï¼');
				history.back();
			}
		}
	})();
</script>

  <title>NLP Papers Reading- BERT | Jijeng's blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jijeng's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/27/paper-reading-bert/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jijeng Jia">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jijeng's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">NLP Papers Reading- BERT</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-27T14:13:14+08:00">
                2019-04-27
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-12-14T22:15:18+08:00">
                2019-12-14
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/04/27/paper-reading-bert/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/04/27/paper-reading-bert/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>æ€»ç»“ GPT, ELMO å’ŒBERT æ¨¡å‹ã€‚</p>
<a id="more"></a>
<h2 id="attention-is-all-you-need"><a href="#attention-is-all-you-need" class="headerlink" title="attention is all you need"></a>attention is all you need</h2><p>Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.</p>
<p>An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed cy a compatibility function of the query with the corresponding key.</p>
<p>ä¸­æ–‡çš„ç†è§£ï¼š<br>æ·±åº¦å­¦ä¹ é‡Œçš„Attention modelå…¶å®æ¨¡æ‹Ÿçš„æ˜¯äººè„‘çš„æ³¨æ„åŠ›æ¨¡å‹ï¼Œä¸¾ä¸ªä¾‹å­æ¥è¯´ï¼Œå½“æˆ‘ä»¬è§‚èµä¸€å¹…ç”»æ—¶ï¼Œè™½ç„¶æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ•´å¹…ç”»çš„å…¨è²Œï¼Œä½†æ˜¯åœ¨æˆ‘ä»¬æ·±å…¥ä»”ç»†åœ°è§‚å¯Ÿæ—¶ï¼Œå…¶å®çœ¼ç›èšç„¦çš„å°±åªæœ‰å¾ˆå°çš„ä¸€å—ï¼Œè¿™ä¸ªæ—¶å€™äººçš„å¤§è„‘ä¸»è¦å…³æ³¨åœ¨è¿™ä¸€å°å—å›¾æ¡ˆä¸Šï¼Œä¹Ÿå°±æ˜¯è¯´è¿™ä¸ªæ—¶å€™äººè„‘å¯¹æ•´å¹…å›¾çš„å…³æ³¨å¹¶ä¸æ˜¯å‡è¡¡çš„ï¼Œæ˜¯æœ‰ä¸€å®šçš„æƒé‡åŒºåˆ†çš„ã€‚è¿™å°±æ˜¯æ·±åº¦å­¦ä¹ é‡Œçš„AttentionModelçš„æ ¸å¿ƒæ€æƒ³ã€‚æ‰€è°“æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°±æ˜¯è¯´åœ¨ç”Ÿæˆæ¯ä¸ªè¯çš„æ—¶å€™ï¼Œå¯¹ä¸åŒçš„è¾“å…¥è¯ç»™äºˆä¸åŒçš„å…³æ³¨æƒé‡ã€‚é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶ï¼Œæˆ‘ä»¬å°†è¾“å…¥å¥å­ç¼–ç ä¸ºä¸€ä¸ªå‘é‡åºåˆ—ï¼Œå¹¶è‡ªé€‚åº”åœ°é€‰æ‹©è¿™äº›å‘é‡çš„ä¸€ä¸ªå­é›†ï¼ŒåŒæ—¶å¯¹è¯‘æ–‡è¿›è¡Œè¯‘ç ï¼Œä¾‹å¦‚where are youâ€”â€”&gt;ä½ åœ¨å“ªï¼Ÿç°åœ¨æˆ‘ä»¬åœ¨ç¿»è¯‘â€œä½ â€çš„æ—¶å€™ç»™â€youâ€æ›´å¤šçš„æƒé‡ï¼Œé‚£ä¹ˆå°±å¯ä»¥æœ‰æ•ˆçš„è§£å†³å¯¹é½é—®é¢˜ã€‚</p>
<p>Background:</p>
<p>ä¸»è¦æ˜¯é¢ä¸´çš„ä¸‰ä¸ªé—®é¢˜ã€‚<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3env74i1dj20rs0f8dge.jpg" alt></p>
<p>Transformer çš„ç»“æ„ç¤ºæ„å›¾:<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3enz4w1tmj21bu0r0q6v.jpg" alt><br>(transformer å°±æ˜¯è®¨è®ºäº†å¦‚ä½•å®ç°ä¸Šè¿°çš„ self-attention ç»“æ„)</p>
<p>Encoder: encoderç”±6ä¸ªç›¸åŒçš„å±‚å †å è€Œæˆï¼Œæ¯ä¸ªå±‚æœ‰ä¸¤ä¸ªå­å±‚ã€‚ç¬¬ä¸€ä¸ªå­å±‚æ˜¯å¤šå¤´è‡ªæˆ‘æ³¨æ„åŠ›æœºåˆ¶(multi-head self-attention mechanism)ï¼Œç¬¬äºŒå±‚æ˜¯ç®€å•çš„ä½ç½®çš„å…¨è¿æ¥å‰é¦ˆç½‘ç»œ(position-wise fully connected feed-forward network)ã€‚åœ¨ä¸¤ä¸ªå­å±‚ä¸­ä¼šä½¿ç”¨ä¸€ä¸ªæ®‹å·®è¿æ¥ï¼Œæ¥ç€è¿›è¡Œå±‚æ ‡å‡†åŒ–(layer normalization)ã€‚ä¹Ÿå°±æ˜¯è¯´æ¯ä¸€ä¸ªå­å±‚çš„è¾“å‡ºéƒ½æ˜¯LayerNorm(x + sublayer(x))ã€‚ç½‘ç»œè¾“å…¥æ˜¯ä¸‰ä¸ªç›¸åŒçš„å‘é‡q, kå’Œvï¼Œæ˜¯word embeddingå’Œposition embeddingç›¸åŠ å¾—åˆ°çš„ç»“æœã€‚ä¸ºäº†æ–¹ä¾¿è¿›è¡Œæ®‹å·®è¿æ¥ï¼Œæˆ‘ä»¬éœ€è¦å­å±‚çš„è¾“å‡ºå’Œè¾“å…¥éƒ½æ˜¯ç›¸åŒçš„ç»´åº¦ã€‚</p>
<p>Decoder: decoderä¹Ÿæ˜¯ç”±Nï¼ˆN=6ï¼‰ä¸ªå®Œå…¨ç›¸åŒçš„Layerç»„æˆï¼Œdecoderä¸­çš„Layerç”±encoderçš„Layerä¸­æ’å…¥ä¸€ä¸ªMulti-Head Attention + Add&amp;Normç»„æˆã€‚è¾“å‡ºçš„embeddingä¸è¾“å‡ºçš„position embeddingæ±‚å’Œåšä¸ºdecoderçš„è¾“å…¥ï¼Œç»è¿‡ä¸€ä¸ªMulti-HeadAttention + Add&amp;Normï¼ˆï¼ˆMA-1ï¼‰å±‚ï¼ŒMA-1å±‚çš„è¾“å‡ºåšä¸ºä¸‹ä¸€Multi-Head Attention + Add&amp;Normï¼ˆMA-2ï¼‰çš„queryï¼ˆQï¼‰è¾“å…¥ï¼ŒMA-2å±‚çš„Keyå’ŒValueè¾“å…¥ï¼ˆä»å›¾ä¸­çœ‹ï¼Œåº”è¯¥æ˜¯encoderä¸­ç¬¬iï¼ˆi = 1,2,3,4,5,6ï¼‰å±‚çš„è¾“å‡ºå¯¹äºdecoderä¸­ç¬¬iï¼ˆi = 1,2,3,4ï¼Œ5,6ï¼‰å±‚çš„è¾“å…¥ï¼‰ã€‚MA-2å±‚çš„è¾“å‡ºè¾“å…¥åˆ°ä¸€ä¸ªå‰é¦ˆå±‚ï¼ˆFFï¼‰ï¼Œç»è¿‡ANæ“ä½œåï¼Œç»è¿‡ä¸€ä¸ªçº¿æ€§+softmaxå˜æ¢å¾—åˆ°æœ€åç›®æ ‡è¾“å‡ºçš„æ¦‚ç‡ã€‚<br> å¯¹äºdecoderä¸­çš„ç¬¬ä¸€ä¸ªå¤šå¤´æ³¨æ„åŠ›å­å±‚ï¼Œéœ€è¦æ·»åŠ maskingï¼Œç¡®ä¿é¢„æµ‹ä½ç½®içš„æ—¶å€™ä»…ä»…ä¾èµ–äºä½ç½®å°äºiçš„è¾“å‡ºã€‚<br> å±‚ä¸å±‚ä¹‹é—´ä½¿ç”¨çš„Position-wise feed forward networkã€‚</p>
<h3 id="transformer-çš„ç»“æ„"><a href="#transformer-çš„ç»“æ„" class="headerlink" title="transformer çš„ç»“æ„"></a>transformer çš„ç»“æ„</h3><p>è°ˆåŠ transformerï¼Œé¦–å…ˆåº”è¯¥æåˆ°æ˜¯ è®¡ç®—æ•ˆç‡çš„å¤§å¤§æé«˜ï¼Œä»åŸå…ˆçš„RNN çš„çº¿æ€§O(N)æå‡çš„å¾ˆå¤šï¼Œè¿™ä¸ªçš„å®ç°æ˜¯åŸºäºå¤šçº¿ç¨‹çš„ã€‚è€Œåè€…æ˜¯å› ä¸ºæ˜¯æœ‰é¡ºåºçš„çº¿æ€§æ¨¡å‹ï¼Œæ‰€ä»¥æ˜¯æ— æ³•ä½¿ç”¨å¹¶è¡Œè¿ç®—çš„ã€‚</p>
<p><img src="https://upload.cc/i1/2019/07/19/w5lozQ.png" alt><br>å¯¹äº RNN æ¥è¯´ï¼Œå¥é¦–çš„ä¿¡æ¯è¦ä¼ é€’åˆ°å¥å°¾ï¼Œéœ€è¦ç»è¿‡ n æ¬¡ RNN çš„è®¡ç®—ï¼›è€Œ Self-Attention å¯ä»¥ç›´æ¥è¿æ¥ä»»æ„ä¸¤ä¸ªèŠ‚ç‚¹.</p>
<p>ä»æ•´ä½“ä¸Šæ¥çœ‹ï¼ŒTransformerä¾æ—§æ˜¯ä¸€ä¸ªâ€œSequence to Sequenceâ€æ¡†æ¶ï¼Œæ‹¥æœ‰Encoderå’ŒDecoderä¸¤éƒ¨åˆ†ï¼š</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eo6o8obxj20l00d6wee.jpg" alt></p>
<p><strong>transformer çš„ç»“æ„</strong></p>
<p>è®ºæ–‡ä¸­encoderå±‚ç”±6ä¸ªencoderå †å åœ¨ä¸€èµ·ï¼Œdecoderå±‚ä¹Ÿä¸€æ ·ã€‚</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eo7eiu73j20rs0i342d.jpg" alt></p>
<p>æ¯ä¸€ä¸ª encoder å’Œ decoder çš„å†…éƒ¨ç®€å›¾å¦‚ä¸‹ï¼š<br><img src="https://i.bmp.ovh/imgs/2019/07/cc9c0e4d7401f315.png" alt></p>
<p><strong> encoder éƒ¨åˆ†</strong></p>
<p>å¯¹äºencoderï¼ŒåŒ…å«ä¸¤å±‚ï¼Œä¸€ä¸ªself-attentionå±‚å’Œä¸€ä¸ªå‰é¦ˆç¥ç»ç½‘ç»œï¼Œself-attentionèƒ½å¸®åŠ©å½“å‰èŠ‚ç‚¹ä¸ä»…ä»…åªå…³æ³¨å½“å‰çš„è¯ï¼Œä»è€Œèƒ½è·å–åˆ°ä¸Šä¸‹æ–‡çš„è¯­ä¹‰ã€‚decoderä¹ŸåŒ…å«encoderæåˆ°çš„ä¸¤å±‚ç½‘ç»œï¼Œä½†æ˜¯åœ¨è¿™ä¸¤å±‚ä¸­é—´è¿˜æœ‰ä¸€å±‚attentionå±‚ï¼Œå¸®åŠ©å½“å‰èŠ‚ç‚¹è·å–åˆ°å½“å‰éœ€è¦å…³æ³¨çš„é‡ç‚¹å†…å®¹ã€‚</p>
<p><strong> self-attention</strong></p>
<p>å…ˆè¯´ä¸€ä¸‹ attention æœºåˆ¶çš„å®ç°ï¼š</p>
<p><img src="https://i.loli.net/2019/07/19/5d31a365bd27877659.png" alt="20190322151729943.png"></p>
<p>å½“ä½¿ç”¨ selfçš„æ—¶å€™ï¼Œquery, key and value è¿™ä¸‰ä¸ªå°±éƒ½æ˜¯ç›¸åŒçš„ã€‚ç»è¿‡softmax() å¾—åˆ°å°±æ˜¯ä¸€ä¸ªæƒé‡ï¼Œç”¨äºæ ‡è®°å’Œ å½“å‰å¤„ç†çš„è¯è¯­çš„å…³ç³»ã€‚self-attentionæ˜¯Transformerç”¨æ¥å°†å…¶ä»–ç›¸å…³å•è¯çš„â€œç†è§£â€è½¬æ¢æˆæˆ‘ä»¬æ­£åœ¨å¤„ç†çš„å•è¯çš„ä¸€ç§æ€è·¯ï¼Œattention å°±æ˜¯ä¸€ç§åŠ æƒå¹³å‡æ•°ï¼Œself-attention å¯ä»¥è¿›ä¸€æ­¥ä¸‹æ”¾ï¼Œå½“å‰å¥å­ä¸­å¯¹å½“å‰å¤„ç†çš„è¯è¯­æœ€é‡è¦çš„æ˜¯å“ªäº›éƒ¨åˆ†ã€‚</p>
<p><strong>Multi-Headed Attention</strong></p>
<p>æˆ‘çš„ç†è§£å°±æ˜¯ åœ¨CNNä¸­ä½¿ç”¨å¤šä¸ªfilter çš„ç±»ä¼¼äº§ç‰©ã€‚è¯¥æœºåˆ¶ç†è§£èµ·æ¥å¾ˆç®€å•ï¼Œå°±æ˜¯è¯´ä¸ä»…ä»…åªåˆå§‹åŒ–ä¸€ç»„Qã€Kã€Vçš„çŸ©é˜µï¼Œè€Œæ˜¯åˆå§‹åŒ–å¤šç»„ï¼Œtranformeræ˜¯ä½¿ç”¨äº†8ç»„ï¼Œæ‰€ä»¥æœ€åå¾—åˆ°çš„ç»“æœæ˜¯8ä¸ªçŸ©é˜µã€‚</p>
<p><strong> è¿™æ ·åšçš„ä¸»è¦ç›®çš„æ˜¯ä»ä¸åŒçš„è¯­ä¹‰ç©ºé—´æŠ•å°„åŸæ–‡æœ¬ï¼Œèƒ½å¤Ÿä»æ›´å¤šçš„è§’åº¦è¡¨å¾ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ‹“å±•æ¨¡å‹å¯¹ä¸åŒä½ç½®çš„å…³æ³¨èƒ½åŠ›ã€‚</strong></p>
<p>è¿™ç»™æˆ‘ä»¬ç•™ä¸‹äº†ä¸€ä¸ªå°çš„æŒ‘æˆ˜ï¼Œå‰é¦ˆç¥ç»ç½‘ç»œæ²¡æ³•è¾“å…¥8ä¸ªçŸ©é˜µå‘€ï¼Œè¿™è¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿæ‰€ä»¥æˆ‘ä»¬éœ€è¦ä¸€ç§æ–¹å¼ï¼ŒæŠŠ8ä¸ªçŸ©é˜µé™ä¸º1ä¸ªï¼Œé¦–å…ˆï¼Œæˆ‘ä»¬æŠŠ8ä¸ªçŸ©é˜µè¿åœ¨ä¸€èµ·ï¼Œè¿™æ ·ä¼šå¾—åˆ°ä¸€ä¸ªå¤§çš„çŸ©é˜µï¼Œå†éšæœºåˆå§‹åŒ–ä¸€ä¸ªçŸ©é˜µå’Œè¿™ä¸ªç»„åˆå¥½çš„çŸ©é˜µç›¸ä¹˜ï¼Œæœ€åå¾—åˆ°ä¸€ä¸ªæœ€ç»ˆçš„çŸ©é˜µã€‚è¿™ä¸ªå°±æ˜¯ multi-head attention æœºåˆ¶çš„å…¨éƒ¨çš„æµç¨‹äº†ã€‚<br><img src="https://i.loli.net/2019/07/19/5d31a58f26ba185562.png" alt="2019032215173034.png"></p>
<p><strong>Positional Encoding </strong></p>
<p>transformerç»™encoderå±‚å’Œdecoderå±‚çš„è¾“å…¥æ·»åŠ äº†ä¸€ä¸ªé¢å¤–çš„å‘é‡Positional Encodingï¼Œç»´åº¦å’Œembeddingçš„ç»´åº¦ä¸€æ ·ï¼Œè¿™ä¸ªå‘é‡é‡‡ç”¨äº†ä¸€ç§å¾ˆç‹¬ç‰¹çš„æ–¹æ³•æ¥è®©æ¨¡å‹å­¦ä¹ åˆ°è¿™ä¸ªå€¼ï¼Œè¿™ä¸ªå‘é‡èƒ½å†³å®šå½“å‰è¯çš„ä½ç½®ï¼Œæˆ–è€…è¯´åœ¨ä¸€ä¸ªå¥å­ä¸­ä¸åŒçš„è¯ä¹‹é—´çš„è·ç¦»ã€‚è¿™ä¸ªä½ç½®å‘é‡çš„å…·ä½“è®¡ç®—æ–¹æ³•æœ‰å¾ˆå¤šç§ï¼Œè®ºæ–‡ä¸­çš„è®¡ç®—æ–¹æ³•å¦‚ä¸‹ï¼š</p>
<p>$$<br>P E ( p o s , 2 i ) = \sin \left( p o s / 10000 ^ { 2 i } / d _ { m } \text {odel} \right)<br>$$</p>
<p>$$<br>P E ( p o s , 2 i + 1 ) = \cos \left( p o s / 10000 ^ { 2 i } / d _ { m } o d e l \right)<br>$$<br>å…¶ä¸­posæ˜¯æŒ‡å½“å‰è¯åœ¨å¥å­ä¸­çš„ä½ç½®ï¼Œiæ˜¯æŒ‡å‘é‡ä¸­æ¯ä¸ªå€¼çš„indexï¼Œå¯ä»¥çœ‹å‡ºï¼Œåœ¨å¶æ•°ä½ç½®ï¼Œä½¿ç”¨æ­£å¼¦ç¼–ç ï¼Œåœ¨å¥‡æ•°ä½ç½®ï¼Œä½¿ç”¨ä½™å¼¦ç¼–ç .</p>
<p>æœ€åæŠŠè¿™ä¸ªPositional Encodingä¸embeddingçš„å€¼ç›¸åŠ ï¼Œä½œä¸ºè¾“å…¥é€åˆ°ä¸‹ä¸€å±‚ã€‚</p>
<p><strong>layer normalization</strong></p>
<p>Normalizationæœ‰å¾ˆå¤šç§ï¼Œä½†æ˜¯å®ƒä»¬éƒ½æœ‰ä¸€ä¸ªå…±åŒçš„ç›®çš„ï¼Œé‚£å°±æ˜¯æŠŠè¾“å…¥è½¬åŒ–æˆå‡å€¼ä¸º0æ–¹å·®ä¸º1çš„æ•°æ®ã€‚æˆ‘ä»¬åœ¨æŠŠæ•°æ®é€å…¥æ¿€æ´»å‡½æ•°ä¹‹å‰è¿›è¡Œnormalizationï¼ˆå½’ä¸€åŒ–ï¼‰ï¼Œå› ä¸ºæˆ‘ä»¬ä¸å¸Œæœ›è¾“å…¥æ•°æ®è½åœ¨æ¿€æ´»å‡½æ•°çš„é¥±å’ŒåŒºã€‚</p>
<p>batch normalization å’Œlayer normalization çš„åŒºåˆ«ï¼Œç®€å•æ¥è¯´å‰è€…ä¾èµ–äº batch sizeï¼Œæ˜¯åœ¨ä¸åŒçš„æ ·æœ¬çš„åŒä¸€ä¸ªç‰¹å¾ä¸Šè¿›è¡Œå½’ä¸€åŒ–ï¼Œåœ¨CNN ä¸Šçš„æ•ˆæœæ›´å¥½ï¼Œåè€…åœ¨ä¸€ä¸ªæ ·æœ¬ä¸Šè¿›è¡Œå½’ä¸€åŒ–ï¼Œ åœ¨ RNNçš„ç½‘ç»œç»“æœä¸­æ•ˆæœæ›´å¥½ã€‚æ›´å¤šè¯¦ç»†çš„å†…å®¹å¯ä»¥å‚è€ƒ<a href="https://jijeng.github.io/2019/07/21/overfit/" target="_blank" rel="noopener">è¿™ç¯‡åšå®¢</a>.</p>
<p>BNçš„ä¸»è¦æ€æƒ³å°±æ˜¯ï¼šåœ¨æ¯ä¸€å±‚çš„æ¯ä¸€æ‰¹æ•°æ®ä¸Šè¿›è¡Œå½’ä¸€åŒ–ã€‚æˆ‘ä»¬å¯èƒ½ä¼šå¯¹è¾“å…¥æ•°æ®è¿›è¡Œå½’ä¸€åŒ–ï¼Œä½†æ˜¯ç»è¿‡è¯¥ç½‘ç»œå±‚çš„ä½œç”¨åï¼Œæˆ‘ä»¬çš„æ•°æ®å·²ç»ä¸å†æ˜¯å½’ä¸€åŒ–çš„äº†ã€‚éšç€è¿™ç§æƒ…å†µçš„å‘å±•ï¼Œæ•°æ®çš„åå·®è¶Šæ¥è¶Šå¤§ï¼Œæˆ‘çš„åå‘ä¼ æ’­éœ€è¦è€ƒè™‘åˆ°è¿™äº›å¤§çš„åå·®ï¼Œè¿™å°±è¿«ä½¿æˆ‘ä»¬åªèƒ½ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡æ¥é˜²æ­¢æ¢¯åº¦æ¶ˆå¤±æˆ–è€…æ¢¯åº¦çˆ†ç‚¸ã€‚<br><img src="https://i.loli.net/2019/07/19/5d31b16df013d57040.png" alt="1.png"><br>å¯ä»¥çœ‹åˆ°ï¼Œå³åŠè¾¹æ±‚å‡å€¼æ˜¯æ²¿ç€æ•°æ® batch_sizeçš„æ–¹å‘è¿›è¡Œçš„</p>
<p><img src="https://i.loli.net/2019/07/19/5d31b16de13f475380.png" alt><br>ä¸è¿‡ LN æ˜¯åœ¨æ¯ä¸€ä¸ªæ ·æœ¬ä¸Šè®¡ç®—å‡å€¼å’Œæ–¹å·®ï¼Œè€Œä¸æ˜¯BNé‚£ç§åœ¨æ‰¹æ–¹å‘è®¡ç®—å‡å€¼å’Œæ–¹å·®ï¼</p>
<p><strong> decoder  éƒ¨åˆ†</strong></p>
<p>decoderéƒ¨åˆ†å…¶å®å’Œencoderéƒ¨åˆ†å¤§åŒå°å¼‚ï¼Œä¸è¿‡åœ¨æœ€ä¸‹é¢é¢å¤–å¤šäº†ä¸€ä¸ªmasked mutil-head attetionï¼Œè¿™é‡Œçš„maskä¹Ÿæ˜¯transformerä¸€ä¸ªå¾ˆå…³é”®çš„æŠ€æœ¯ã€‚</p>
<p>Transformer æ¨¡å‹é‡Œé¢æ¶‰åŠä¸¤ç§ maskï¼Œåˆ†åˆ«æ˜¯ padding mask å’Œ sequence maskã€‚å…¶ä¸­ padding mask åœ¨æ‰€æœ‰çš„ scaled dot-product attention é‡Œé¢éƒ½éœ€è¦ç”¨åˆ°ï¼Œè€Œ sequence mask åªæœ‰åœ¨ decoder çš„ self-attention é‡Œé¢ç”¨åˆ°ã€‚å‰è€…å°±æ˜¯ä¸€ç§å¡«å……æŠ€æœ¯ï¼Œä½¿å¾— ä¸å®šé•¿çš„sequence å˜æˆå®šé•¿çš„sequenceä¹‹ååšå‡ºçš„ä¸€äº›å¤„ç†ã€‚</p>
<p><strong> Padding Mask </strong></p>
<p>ä»€ä¹ˆæ˜¯ padding mask å‘¢ï¼Ÿå› ä¸ºæ¯ä¸ªæ‰¹æ¬¡è¾“å…¥åºåˆ—é•¿åº¦æ˜¯ä¸ä¸€æ ·çš„ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬è¦å¯¹è¾“å…¥åºåˆ—è¿›è¡Œå¯¹é½ã€‚å…·ä½“æ¥è¯´ï¼Œå°±æ˜¯ç»™åœ¨è¾ƒçŸ­çš„åºåˆ—åé¢å¡«å…… 0ã€‚ä½†æ˜¯å¦‚æœè¾“å…¥çš„åºåˆ—å¤ªé•¿ï¼Œåˆ™æ˜¯æˆªå–å·¦è¾¹çš„å†…å®¹ï¼ŒæŠŠå¤šä½™çš„ç›´æ¥èˆå¼ƒã€‚å› ä¸ºè¿™äº›å¡«å……çš„ä½ç½®ï¼Œå…¶å®æ˜¯æ²¡ä»€ä¹ˆæ„ä¹‰çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„attentionæœºåˆ¶ä¸åº”è¯¥æŠŠæ³¨æ„åŠ›æ”¾åœ¨è¿™äº›ä½ç½®ä¸Šï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦è¿›è¡Œä¸€äº›å¤„ç†ã€‚<br>å…·ä½“çš„åšæ³•æ˜¯ï¼ŒæŠŠè¿™äº›ä½ç½®çš„å€¼åŠ ä¸Šä¸€ä¸ªéå¸¸å¤§çš„è´Ÿæ•°(è´Ÿæ— ç©·)ï¼Œè¿™æ ·çš„è¯ï¼Œç»è¿‡ softmaxï¼Œè¿™äº›ä½ç½®çš„æ¦‚ç‡å°±ä¼šæ¥è¿‘0ï¼</p>
<p><strong> Sequence mask</strong><br>sequence mask æ˜¯ä¸ºäº†ä½¿å¾— decoder ä¸èƒ½çœ‹è§æœªæ¥çš„ä¿¡æ¯ã€‚ä¹Ÿå°±æ˜¯å¯¹äºä¸€ä¸ªåºåˆ—ï¼Œåœ¨ time_step ä¸º t çš„æ—¶åˆ»ï¼Œæˆ‘ä»¬çš„è§£ç è¾“å‡ºåº”è¯¥åªèƒ½ä¾èµ–äº t æ—¶åˆ»ä¹‹å‰çš„è¾“å‡ºï¼Œè€Œä¸èƒ½ä¾èµ– t ä¹‹åçš„è¾“å‡ºã€‚å› æ­¤æˆ‘ä»¬éœ€è¦æƒ³ä¸€ä¸ªåŠæ³•ï¼ŒæŠŠ t ä¹‹åçš„ä¿¡æ¯ç»™éšè—èµ·æ¥ã€‚é‚£ä¹ˆå…·ä½“æ€ä¹ˆåšå‘¢ï¼Ÿä¹Ÿå¾ˆç®€å•ï¼šäº§ç”Ÿä¸€ä¸ªä¸Šä¸‰è§’çŸ©é˜µï¼Œä¸Šä¸‰è§’çš„å€¼å…¨ä¸º1ã€‚æŠŠè¿™ä¸ªçŸ©é˜µä½œç”¨åœ¨æ¯ä¸€ä¸ªåºåˆ—ä¸Šï¼Œå°±å¯ä»¥è¾¾åˆ°æˆ‘ä»¬çš„ç›®çš„ã€‚</p>
<p><strong> ç¼ºç‚¹ï¼š</strong></p>
<p>é—®é¢˜ä¸€ï¼š é•¿è¾“å…¥</p>
<p>åœ¨æ–‡æœ¬åªè¦ç­‰ç¯‡ç« çº§åˆ«çš„ä»»åŠ¡é‡ï¼Œ transformer å› ä¸ºè®¡ç®—é‡çš„å¤æ‚æ€§ï¼Œæ‰€ä»¥é€Ÿåº¦å›æ€¥é€Ÿå˜æ…¢ã€‚æ‰€ä»¥çŸ­æœŸå†…ï¼Œè¿™äº›æ–¹é¢ä»ç„¶æ˜¯RNN æˆ–è€…CNNçš„åº”ç”¨åœºæ™¯ï¼ˆè™½ç„¶ä¸¤è€…åšçš„ä¹Ÿä¸æ˜¯å¾ˆå¥½ï¼‰ã€‚</p>
<p>transformer çš„æ”¹è¿›æ€è·¯ï¼š</p>
<p>æ¯”å¦‚å¯ä»¥æŠŠé•¿è¾“å…¥åˆ‡æ–­åˆ†æˆKä»½ï¼Œå¼ºåˆ¶æŠŠé•¿è¾“å…¥åˆ‡çŸ­ï¼Œå†å¥—ä¸ŠTransformerä½œä¸ºç‰¹å¾æŠ½å–å™¨ï¼Œé«˜å±‚å¯ä»¥ç”¨RNNæˆ–è€…å¦å¤–ä¸€å±‚Transformeræ¥æ¥åŠ›ï¼Œå½¢æˆTransformerçš„å±‚çº§ç»“æ„ï¼Œè¿™æ ·å¯ä»¥æŠŠnå¹³æ–¹çš„è®¡ç®—é‡æå¤§å‡å°‘ã€‚ï¼ˆåˆ†è€Œæ²»ä¹‹çš„æ€è·¯æ˜¯çœŸçš„æ¯”è¾ƒå¸¸è§å‘€ï¼‰</p>
<p>é—®é¢˜äºŒï¼š ç½‘ç»œç»“æ„è¿‡äºå¤æ‚</p>
<p>å¦‚ä½•æ›´æ·±åˆ»è®¤è¯†å®ƒçš„ä½œç”¨æœºç†ï¼Œç„¶åè¿›ä¸€æ­¥ç®€åŒ–å®ƒï¼Œè¿™ä¹Ÿæ˜¯ä¸€ä¸ªå¥½çš„æ¢ç´¢æ–¹å‘ã€‚ ä¸Šé¢åœ¨åšè¯­ä¹‰ç‰¹å¾æŠ½å–èƒ½åŠ›æ¯”è¾ƒæ—¶ï¼Œç»“è®ºæ˜¯å¯¹äºè·ç¦»è¿œä¸13çš„é•¿è·ç¦»ç‰¹å¾ï¼ŒTransformeræ€§èƒ½å¼±äºRNN</p>
<p>åˆ†ç•Œçº¿ - -  - - - â€“ - - - - - -  - - - - -  åˆ† ç•Œçº¿ï¼ˆå¦å¤–çš„è§£è¯»æ–¹å¼ï¼‰</p>
<p>Encoderå’ŒDecoderçš„å†…éƒ¨ç»“æ„ï¼š<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3enq6lqouj20uq0eoq4u.jpg" alt></p>
<p>æ¨¡å‹çš„ç‰¹ç‚¹ï¼š<br>Positional embeddingï¼›ï¼ˆä½ç½®åµŒå…¥å‘é‡â€”â€”å…¶å®ç±»ä¼¼word2vecï¼Œå¤„ç†çš„è¯­åºçš„ä¿¡æ¯ï¼‰ã€‚<br>multi-head attention; (å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶â€”â€”ç‚¹ä¹˜æ³¨æ„åŠ›çš„å‡çº§ç‰ˆæœ¬ï¼Œ è¿™ä¸ªå°±ç±»ä¼¼ensembleçš„æ€æƒ³ï¼Œä¸åŒçš„å­ç©ºé—´çš„attention è¿›è¡Œèåˆï¼‰<br>Position-wise Feed-Forward Networksï¼ˆä½ç½®å…¨é“¾æ¥å‰é¦ˆç½‘ç»œâ€”â€”MLPå˜å½¢ï¼‰</p>
<p>æœ‰ä¸¤ç§å¸¸ç”¨çš„æ³¨æ„åŠ›å‡½æ•°ï¼Œä¸€ç§æ˜¯åŠ æ³•æ³¨æ„åŠ›(additive attention)ï¼Œå¦å¤–ä¸€ç§æ˜¯ç‚¹ä¹˜æ³¨æ„åŠ›(dot-productattention)ï¼Œè®ºæ–‡æ‰€é‡‡ç”¨çš„å°±æ˜¯ç‚¹ä¹˜æ³¨æ„åŠ›ï¼Œè¿™ç§æ³¨æ„åŠ›æœºåˆ¶å¯¹äºåŠ æ³•æ³¨æ„åŠ›è€Œè¨€ï¼Œæ›´å¿«ï¼ŒåŒæ—¶æ›´èŠ‚çœç©ºé—´ã€‚</p>
<p>åŠ æ³•æ³¨æ„åŠ›<br>è¿˜æ˜¯ä»¥ä¼ ç»Ÿçš„RNNçš„seq2seqé—®é¢˜ä¸ºä¾‹å­ï¼ŒåŠ æ€§æ³¨æ„åŠ›æ˜¯æœ€ç»å…¸çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ƒä½¿ç”¨äº†æœ‰ä¸€ä¸ªéšè—å±‚çš„å‰é¦ˆç½‘ç»œï¼ˆå…¨è¿æ¥ï¼‰æ¥è®¡ç®—æ³¨æ„åŠ›åˆ†é…ï¼š<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3ep38emyqj20bl03o3zj.jpg" alt></p>
<p>å…¬å¼:<br>$$<br>\alpha _ { i j } = \frac { \exp \left( e _ { i j } \right) } { \sum _ { k = 1 } ^ { L } e _ { i k } }<br>$$</p>
<p>Scaled Dot-Product<br>è¿™ç¯‡è®ºæ–‡è®¡ç®—queryå’Œkeyç›¸ä¼¼åº¦ä½¿ç”¨äº†dot-product attentionï¼Œå³queryå’Œkeyè¿›è¡Œç‚¹ä¹˜ï¼ˆå†…ç§¯ï¼‰æ¥è®¡ç®—ç›¸ä¼¼åº¦ã€‚<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3ftfz3uxij206e088aa2.jpg" alt></p>
<p>Multi-Head Attention:<br>ï¼ˆå°†å•ä¸ªè®¡ç®—ç»„æˆçŸ©é˜µè¿ç®—ï¼Œæœ‰åˆ©äºå¹¶è¡Œè¿ç®—ï¼‰<br>åœ¨å®é™…ä¸­ä¸ºäº†å¹¶è¡Œè®¡ç®—ï¼Œå¯ä»¥åœ¨ä¸€ç»„queriesä¸Šè®¡ç®—æ³¨æ„åŠ›å‡½æ•°ï¼Œå°†å¤šä¸ªqueryå †å æˆQï¼ŒåŒç†keyså’Œvaluesä¹Ÿè¢«å †å æˆKå’ŒVï¼Œé€šè¿‡ä¸‹é¢çš„å…¬å¼æ¥è®¡ç®—çŸ©é˜µè¾“å‡º:<br>self-attention æ¨¡å‹å°±æ˜¯è‡ªå·±å¯¹è‡ªå·±æ±‚attentionï¼Œå³ğ‘„=ğ¾=ğ‘‰<br>$$<br>\text { Attention } ( Q , K , V ) = \operatorname { softmax } \left( \frac { Q K ^ { T } } { \sqrt { d _ { k } } } \right) V<br>$$<br>ä¹‹æ‰€ä»¥ç”¨å†…ç§¯é™¤ä»¥ç»´åº¦çš„å¼€æ–¹ï¼Œè®ºæ–‡ç»™å‡ºçš„è§£é‡Šæ˜¯ï¼šå‡è®¾Qå’ŒKéƒ½æ˜¯ç‹¬ç«‹çš„éšæœºå˜é‡ï¼Œæ»¡è¶³å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼Œåˆ™ç‚¹ä¹˜åç»“æœå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸ºdkã€‚ä¹Ÿå³æ–¹å·®ä¼šéšç»´åº¦dkçš„å¢å¤§è€Œå¢å¤§ï¼Œè€Œå¤§çš„æ–¹å·®å¯¼è‡´æå°çš„æ¢¯åº¦(æˆ‘è®¤ä¸ºå¤§æ–¹å·®å¯¼è‡´æœ‰çš„è¾“å‡ºå•å…ƒaï¼ˆaæ˜¯softmaxçš„ä¸€ä¸ªè¾“å‡ºï¼‰å¾ˆå°ï¼Œsoftmaxåå‘ä¼ æ’­æ¢¯åº¦å°±å¾ˆå°ï¼ˆæ¢¯åº¦å’Œaæœ‰å…³ï¼‰ï¼‰ã€‚ä¸ºäº†é¿å…è¿™ç§å¤§æ–¹å·®å¸¦æ¥çš„è®­ç»ƒé—®é¢˜ï¼Œè®ºæ–‡ä¸­ç”¨å†…ç§¯é™¤ä»¥ç»´åº¦çš„å¼€æ–¹ï¼Œä½¿ä¹‹å˜ä¸ºå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ã€‚</p>
<p>é™¤äº†è®¡ç®—ä¸€ä¸ªå•ç‹¬çš„æ³¨æ„åŠ›å‡½æ•°ï¼Œè®ºæ–‡æå‡ºå¯¹queriesï¼Œkeyså’Œvaluesåšhæ¬¡ä¸åŒçš„æŠ•å½±, ç„¶åéƒ½ç»è¿‡Scaled Dot-Product Attentionï¼Œå°†ç»“æœæ‹¼æ¥åœ¨ä¸€èµ·ï¼Œæœ€åé€šè¿‡ä¸€ä¸ªçº¿æ€§æ˜ å°„è¾“å‡ºï¼Œé€šè¿‡å¤šå¤´æ³¨æ„åŠ›ï¼Œæ¨¡å‹èƒ½å¤Ÿè·å¾—ä¸åŒå­ç©ºé—´ä¸‹çš„ä½ç½®ä¿¡æ¯ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå…¬å¼å¦‚ä¸‹:<br>$$<br>\text {MultiHead} ( Q , K , V ) =Concat(head_1, head_2, â€¦, head_h)  W ^ { o }$$</p>
<p>Self-Attention<br>é‚£ä¹ˆé¦–å…ˆè¦æ˜ç™½ä»€ä¹ˆæ˜¯Attentionã€‚ä»è¯­è¨€å­¦çš„è§’åº¦ï¼Œå®ƒæ˜¯è¡¨ç¤ºè¯ä¸è¯ä¹‹é—´çš„å…³è”å…³ç³»ï¼ˆè¿™ç§å…³ç³»æ˜¯é€šè¿‡åå‘ä¼ æ’­å­¦ä¹ åˆ°çš„ï¼‰ã€‚è€Œ self-attention è¡¨ç¤ºå¥å­å†…éƒ¨è¯äºè¯ä¹‹é—´çš„å…³è”å…³ç³»ï¼Œå¦‚ä¸‹å›¾ä¸­çš„it å’Œå…¶ä»–ä½ç½®è¯çš„å…³ç³»ï¼Œé¢œè‰²è¶Šæ·±è¡¨ç¤ºå…³ç³»è¶Šç´§å¯†ï¼Œ ä»å›¾ä¸­å¯ä»¥çœ‹åˆ° it æ­£ç¡®çš„å…³è”åˆ°äº† animal å®ƒæ‰€æŒ‡ä»£çš„ä¸€ä¸ªè¯ã€‚</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eobewbqoj20c50bhq4y.jpg" alt></p>
<p>Positional Encoding<br>transformeræ˜¯ä½¿ç”¨ positional encoding åŠ å…¥äº†ä½ç½®ä¿¡æ¯ï¼Œä¿æŒäº†è¯è¯­ä¹‹é—´çš„ä¸Šä¸‹æ–‡å…³ç³»ã€‚å®ç°çš„çš„æ—¶å€™ï¼Œåœ¨å¶æ•°ä½ç½®ï¼Œä½¿ç”¨æ­£å¼¦ç¼–ç ï¼Œåœ¨å¥‡æ•°ä½ç½®ï¼Œä½¿ç”¨ä½™å¼¦ç¼–ç .</p>
<p>Residual connectionå’Œlayer-normalization</p>
<p>å¯¹äºå­¦ä¹ CVçš„äººä¼°è®¡å¯¹è¿™ä¸ªç»“æ„ä¸€ç‚¹ä¹Ÿä¸é™Œç”Ÿï¼ŒResidual connectionæ˜¯å¯¹äºè¾ƒä¸ºæ·±å±‚çš„ç¥ç»ç½‘ç»œæœ‰æ¯”è¾ƒå¥½çš„ä½œç”¨ï¼Œæ¯”å¦‚ç½‘ç»œå±‚å¾ˆæ·±æ—¶ï¼Œæ•°å€¼çš„ä¼ æ’­éšç€weightä¸æ–­çš„å‡å¼±ï¼ŒResidual connectionæ˜¯ä»è¾“å…¥çš„éƒ¨åˆ†ï¼Œå°±æ˜¯å›¾ä¸­è™šçº¿çš„éƒ¨åˆ†ï¼Œå®é™…è¿åˆ°å®ƒè¾“å‡ºå±‚çš„éƒ¨åˆ†ï¼ŒæŠŠè¾“å…¥çš„ä¿¡æ¯åŸå°ä¸åŠ¨copyåˆ°è¾“å‡ºçš„éƒ¨åˆ†ï¼Œå‡å°‘ä¿¡æ¯çš„æŸå¤±ã€‚</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eof674adj20ii0dfgoe.jpg" alt><br>layer-normalizationè¿™ç§å½’ä¸€åŒ–å±‚æ˜¯ä¸ºäº†é˜²æ­¢åœ¨æŸäº›å±‚ä¸­ç”±äºæŸäº›ä½ç½®è¿‡å¤§æˆ–è€…è¿‡å°å¯¼è‡´æ•°å€¼è¿‡å¤§æˆ–è¿‡å°ï¼Œå¯¹ç¥ç»ç½‘ç»œæ¢¯åº¦å›ä¼ æ—¶æœ‰è®­ç»ƒçš„é—®é¢˜ï¼Œä¿è¯è®­ç»ƒçš„ç¨³å®šæ€§ï¼Œè¿™æ˜¯ç¥ç»ç½‘ç»œè®¾è®¡æ¯”è¾ƒå¸¸ç”¨çš„caseã€‚</p>
<p>ç»“è®ºï¼š<br>self-attentionå±‚çš„å¥½å¤„æ˜¯èƒ½å¤Ÿä¸€æ­¥åˆ°ä½æ•æ‰åˆ°å…¨å±€çš„è”ç³»ï¼Œè§£å†³äº†é•¿è·ç¦»ä¾èµ–ï¼Œå› ä¸ºå®ƒç›´æ¥æŠŠåºåˆ—ä¸¤ä¸¤æ¯”è¾ƒï¼ˆä»£ä»·æ˜¯è®¡ç®—é‡å˜ä¸º O(n2)ï¼Œå½“ç„¶ç”±äºæ˜¯çº¯çŸ©é˜µè¿ç®—ï¼Œè¿™ä¸ªè®¡ç®—é‡ç›¸å½“ä¹Ÿä¸æ˜¯å¾ˆä¸¥é‡ï¼‰ï¼Œè€Œä¸”æœ€é‡è¦çš„æ˜¯å¯ä»¥è¿›è¡Œå¹¶è¡Œè®¡ç®—ï¼Œå› ä¸ºè¿™ä¸ªæ“ä½œæ˜¯å¯ä»¥ä½¿ç”¨çŸ©é˜µè¿ç®—çš„ã€‚<br>ç›¸æ¯”ä¹‹ä¸‹ï¼ŒRNN éœ€è¦ä¸€æ­¥æ­¥é€’æ¨æ‰èƒ½æ•æ‰åˆ°ï¼Œå¹¶ä¸”å¯¹äºé•¿è·ç¦»ä¾èµ–å¾ˆéš¾æ•æ‰ã€‚è€Œ CNN åˆ™éœ€è¦é€šè¿‡å±‚å æ¥æ‰©å¤§æ„Ÿå—é‡ï¼ˆæ„Ÿå—é‡çš„æ¦‚å¿µï¼Œæ›´åƒæ˜¯ æœ€åç»è¿‡CNN çš„ä¸€ä¸ªç‚¹åœ¨åŸå§‹çš„å›¾åƒä¸­æ˜¯å¤šå¤§çš„é¢ç§¯ï¼Œè¿™ç§ç®¡ä¸­çª¥è±¹çš„æ„Ÿè§‰ï¼‰ï¼Œè¿™æ˜¯ Attention å±‚çš„æ˜æ˜¾ä¼˜åŠ¿ã€‚</p>
<h2 id="Deep-Contextualized-Word-Representations"><a href="#Deep-Contextualized-Word-Representations" class="headerlink" title="Deep Contextualized Word Representations"></a>Deep Contextualized Word Representations</h2><p>ï¼ˆå¯ä»¥å¾—åˆ°æœ‰ä¸Šä¸‹æ–‡å…³ç³»çš„è¯å‘é‡ï¼Œ è¿™ä¸ªç‰¹ç‚¹æ˜¯ç›¸å¯¹äº word2vec æˆ–è€… glove çš„ï¼‰<br>è¿™ç¯‡è®ºæ–‡çš„æƒ³æ³•å…¶å®éå¸¸éå¸¸ç®€å•ï¼Œä½†æ˜¯å–å¾—äº†éå¸¸å¥½çš„æ•ˆæœã€‚å®ƒçš„æ€è·¯æ˜¯ç”¨æ·±åº¦çš„åŒå‘RNN(LSTM)åœ¨å¤§é‡æœªæ ‡æ³¨æ•°æ®ä¸Šè®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ç„¶ååœ¨å®é™…çš„ä»»åŠ¡ä¸­ï¼Œå¯¹äºè¾“å…¥çš„å¥å­ï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªè¯­è¨€æ¨¡å‹æ¥å¯¹å®ƒå¤„ç†ï¼Œå¾—åˆ°è¾“å‡ºçš„å‘é‡ï¼Œå› æ­¤è¿™å¯ä»¥çœ‹æˆæ˜¯ä¸€ç§ç‰¹å¾æå–ã€‚ä½†æ˜¯å’Œæ™®é€šçš„Word2Vecæˆ–è€…GloVeçš„pretrainingä¸åŒï¼ŒELMoå¾—åˆ°çš„Embeddingæ˜¯æœ‰ä¸Šä¸‹æ–‡çš„ã€‚æ¯”å¦‚æˆ‘ä»¬ä½¿ç”¨Word2Vecä¹Ÿå¯ä»¥å¾—åˆ°è¯â€bankâ€çš„Embeddingï¼Œæˆ‘ä»¬å¯ä»¥è®¤ä¸ºè¿™ä¸ªEmbeddingåŒ…å«äº†bankçš„è¯­ä¹‰ã€‚ä½†æ˜¯bankæœ‰å¾ˆå¤šæ„æ€ï¼Œå¯ä»¥æ˜¯é“¶è¡Œä¹Ÿå¯ä»¥æ˜¯æ°´è¾¹ï¼Œä½¿ç”¨æ™®é€šçš„Word2Vecä½œä¸ºPretrainingçš„Embeddingï¼Œåªèƒ½åŒæ—¶æŠŠè¿™ä¸¤ç§è¯­ä¹‰éƒ½ç¼–ç è¿›å‘é‡é‡Œï¼Œç„¶åé åé¢çš„æ¨¡å‹æ¯”å¦‚RNNæ¥æ ¹æ®ä¸Šä¸‹æ–‡é€‰æ‹©åˆé€‚çš„è¯­ä¹‰â€”â€”æ¯”å¦‚ä¸Šä¸‹æ–‡æœ‰moneyï¼Œé‚£ä¹ˆå®ƒæ›´å¯èƒ½æ˜¯é“¶è¡Œï¼›è€Œå¦‚æœä¸Šä¸‹æ–‡æ˜¯riverï¼Œé‚£ä¹ˆæ›´å¯èƒ½æ˜¯æ°´è¾¹çš„æ„æ€ã€‚ä½†æ˜¯RNNè¦å­¦åˆ°è¿™ç§ä¸Šä¸‹æ–‡çš„å…³ç³»ï¼Œéœ€è¦è¿™ä¸ªä»»åŠ¡æœ‰å¤§é‡ç›¸å…³çš„æ ‡æ³¨æ•°æ®ï¼Œè¿™åœ¨å¾ˆå¤šæ—¶å€™æ˜¯æ²¡æœ‰çš„ã€‚è€ŒELMoçš„ç‰¹å¾æå–å¯ä»¥çœ‹æˆæ˜¯ä¸Šä¸‹æ–‡ç›¸å…³çš„ï¼Œå¦‚æœè¾“å…¥å¥å­æœ‰moneyï¼Œé‚£ä¹ˆå®ƒå°±(æˆ–è€…æˆ‘ä»¬æœŸæœ›)åº”è¯¥èƒ½çŸ¥é“bankæ›´å¯èƒ½çš„è¯­ä¹‰ï¼Œä»è€Œå¸®æˆ‘ä»¬é€‰æ‹©æ›´åŠ åˆé€‚çš„ç¼–ç ã€‚</p>
<p>æˆ‘ä»¬æŠŠè¿™ä¸¤ä¸ªæ–¹å‘çš„RNNåˆå¹¶èµ·æ¥å°±å¾—åˆ°Bi-LSTMã€‚æˆ‘ä»¬ä¼˜åŒ–çš„æŸå¤±å‡½æ•°æ˜¯ä¸¤ä¸ªLSTMçš„äº¤å‰ç†µåŠ èµ·æ¥æ˜¯æœ€å°çš„ï¼š</p>
<p>ä¸»è¦è´¡çŒ®ï¼š</p>
<ul>
<li>æå‡ºäº†ä¸€ä¸ªåŒå‘è®­ç»ƒçš„ language modelï¼Œä½¿ç”¨å‰K-1 ä¸ªè¯è¯­è®­ç»ƒ ç¬¬K ä¸ªè¯è¯­ï¼Œç„¶åä½¿ç”¨å N-K+1 ä¸ªè¯è¯­è®­ç»ƒç¬¬K ä¸ªè¯è¯­ï¼Œæ‰€ä»¥ç¬¬ K ä¸ªè¯è¯­æ˜¯combine äº†ä¸Šä¸‹æ–‡çš„ä¿¡æ¯çš„ã€‚</li>
<li>word embedding çš„è¡¨ç¤ºæ˜¯ä¸åŒlayer ç´¯åŠ çš„ç»“æœï¼Œweights çš„è®¾å®šæ˜¯å­¦ä¹ è€Œå¾—ã€‚</li>
</ul>
<p>Why do we need contextualized representations?</p>
<p>è¯è¯­çš„æ„æ€æ˜¯ç”±ä¸Šä¸‹æ–‡æ‰€å†³å®šçš„ã€‚æ‰€ä»¥ä¸€ä¸ªå›ºå®šçš„ word embedding ä¸èƒ½å‡†ç¡®çš„è¡¨ç¤ºä¸åŒåœºæ™¯ä¸‹ word çš„å«ä¹‰ã€‚</p>
<p>As an illustrative example, take the following two sentences:</p>
<blockquote>
<p>â€œThe bank on the other end of the street was robbedâ€<br>â€œWe had a picnic on the bank of the riverâ€</p>
</blockquote>
<p>Both sentences use the word â€œbankâ€, but the meaning of the word differs completely between them. This phenomenon where two identical words change meaning depending on the context is known as â€œpolysemyâ€œ, and has been an issue in the NLP deep learning community ever since word embeddings really took off. Most current neural networks are bad at handling polysemy because they use a single vector to represent the meaning of the word â€œbankâ€, regardless of the context. In reality, the vector representing any word should change depending on the words around it.</p>
<p>ä¹‹å‰çš„åšæ³•çš„ç¼ºç‚¹æ˜¯å¯¹äºæ¯ä¸€ä¸ªå•è¯éƒ½æœ‰å”¯ä¸€çš„ä¸€ä¸ªembeddingè¡¨ç¤º, è€Œå¯¹äºå¤šä¹‰è¯æ˜¾ç„¶è¿™ç§åšæ³•ä¸ç¬¦åˆç›´è§‰, è€Œå•è¯çš„æ„æ€åˆå’Œä¸Šä¸‹æ–‡ç›¸å…³, ELMoçš„åšæ³•æ˜¯æˆ‘ä»¬åªé¢„è®­ç»ƒlanguage model, è€Œword embeddingæ˜¯é€šè¿‡è¾“å…¥çš„å¥å­å®æ—¶è¾“å‡ºçš„, è¿™æ ·å•è¯çš„æ„æ€å°±æ˜¯ä¸Šä¸‹æ–‡ç›¸å…³çš„äº†, è¿™æ ·å°±å¾ˆå¤§ç¨‹åº¦ä¸Šç¼“è§£äº†æ­§ä¹‰çš„å‘ç”Ÿ.</p>
<p>è¿™ç§ç®—æ³•çš„ç‰¹ç‚¹æ˜¯ï¼šæ¯ä¸€ä¸ªword representationéƒ½æ˜¯æ•´ä¸ªè¾“å…¥è¯­å¥çš„å‡½æ•°ã€‚å…·ä½“åšæ³•å°±æ˜¯å…ˆåœ¨å¤§è¯­æ–™ä¸Šä»¥language modelä¸ºç›®æ ‡è®­ç»ƒå‡ºbidirectional LSTMæ¨¡å‹ï¼Œç„¶ååˆ©ç”¨LSTMäº§ç”Ÿè¯è¯­çš„è¡¨å¾ã€‚ELMoæ•…è€Œå¾—å(Embeddings from Language Models)ã€‚ä¸ºäº†åº”ç”¨åœ¨ä¸‹æ¸¸çš„NLPä»»åŠ¡ä¸­ï¼Œä¸€èˆ¬å…ˆåˆ©ç”¨ä¸‹æ¸¸ä»»åŠ¡çš„è¯­æ–™åº“(æ³¨æ„è¿™é‡Œå¿½ç•¥æ‰label)è¿›è¡Œlanguage modelçš„å¾®è°ƒ,è¿™ç§å¾®è°ƒç›¸å½“äºä¸€ç§domain transfer; ç„¶åæ‰åˆ©ç”¨labelçš„ä¿¡æ¯è¿›è¡Œsupervised learningã€‚</p>
<p>ELMoè¡¨å¾æ˜¯â€œæ·±â€çš„ï¼Œå°±æ˜¯è¯´å®ƒä»¬æ˜¯biLMçš„æ‰€æœ‰å±‚çš„å†…éƒ¨è¡¨å¾çš„å‡½æ•°ã€‚è¿™æ ·åšçš„å¥½å¤„æ˜¯èƒ½å¤Ÿäº§ç”Ÿä¸°å¯Œçš„è¯è¯­è¡¨å¾ã€‚é«˜å±‚çš„LSTMçš„çŠ¶æ€å¯ä»¥æ•æ‰è¯è¯­æ„ä¹‰ä¸­å’Œè¯­å¢ƒç›¸å…³çš„é‚£æ–¹é¢çš„ç‰¹å¾(æ¯”å¦‚å¯ä»¥ç”¨æ¥åšè¯­ä¹‰çš„æ¶ˆæ­§)ï¼Œè€Œä½å±‚çš„LSTMå¯ä»¥æ‰¾åˆ°è¯­æ³•æ–¹é¢çš„ç‰¹å¾(æ¯”å¦‚å¯ä»¥åšè¯æ€§æ ‡æ³¨)ã€‚å¦‚æœæŠŠå®ƒä»¬ç»“åˆåœ¨ä¸€èµ·ï¼Œåœ¨ä¸‹æ¸¸çš„NLPä»»åŠ¡ä¸­ä¼šä½“ç°ä¼˜åŠ¿ã€‚</p>
<p>æ‰€ä»¥ï¼Œæœ€åçš„ embedding ä½¿ç”¨ä¸åŒå±‚è¿›è¡Œweights çš„ç´¯åŠ ï¼Œè¿™ç§ç†è®ºä¸Šæ˜¯ç«™å¾—ä½è„šçš„ã€‚ä¸Šé¢çš„æè¿°å’Œ CV æ˜¯æƒŠäººçš„ç›¸ä¼¼ã€‚</p>
<p>Salient features<br>ELMo representations are:</p>
<ul>
<li>Contextual: The representation for each word depends on the entire context in which it is used.</li>
<li>Deep: The word representations combine all layers of a deep pre-trained neural network.</li>
<li>Character based: ELMo representations are purely character based, allowing the network to use morphological clues to form robust representations for out-of-vocabulary tokens unseen in training.</li>
</ul>
<p>related work:</p>
<p>é’ˆå¯¹ä¼ ç»Ÿè¯å‘é‡æ˜¯å›ºå®šçš„ï¼Œä¸ä¸Šä¸‹æ–‡è¯­å¢ƒæ— å…³çš„ç¼ºç‚¹ï¼Œå…ˆå‰çš„å·¥ä½œå¤šé€šè¿‡ä¸¤ç§æ–¹å¼æ¥è§£å†³ï¼š<br> (1) é€šè¿‡å¼•å…¥å­—ç¬¦çº§(subword)ä¿¡æ¯ä¸°å¯Œè¯å‘é‡è¡¨è¾¾ï¼›<br> (2) å­¦ä¹ æ¯ä¸ªå•è¯ä¸åŒå«ä¹‰çš„ç‹¬ç«‹å‘é‡ï¼›<br> ELMoä¹Ÿåˆ©ç”¨äº†å­—ç¬¦å·ç§¯ï¼ˆCharacter-Convolutionsï¼‰å¼•å…¥å­—ç¬¦çº§ä¿¡æ¯ï¼Œå¹¶åŒæ—¶ç»“åˆäº†æ·±åº¦åŒå‘è¯­è¨€æ¨¡å‹çš„å„å±‚éšçŠ¶æ€æ¥ä¸°å¯Œè¯å‘é‡è¡¨è¾¾ã€‚</p>
<p>P.s.ï¼šåŸºäºå­—ç¬¦çš„æ¨¡å‹ä¸ä»…èƒ½å¤Ÿé€šè¿‡å¼•å…¥å­—ç¬¦çº§ä¿¡æ¯ä¸°å¯Œè¯å‘é‡è¡¨è¾¾ï¼Œä¹Ÿèƒ½å¤Ÿåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šè§£å†³NLPé¢†åŸŸçš„OOVï¼ˆOut-Of-Vocabularyï¼‰é—®é¢˜ã€‚</p>
<p>ELMoç”¨åˆ°ä¸Šæ–‡æåˆ°çš„åŒå‘çš„language model, ç»™å®šNä¸ªtokens (t1, t2,â€¦,tN), language modelé€šè¿‡ç»™å®šå‰é¢çš„k-1ä¸ªä½ç½®çš„tokenåºåˆ—è®¡ç®—ç¬¬kä¸ªtokençš„å‡ºç°çš„æ¦‚ç‡:<br>$$<br>p \left( t _ { 1 } , t _ { 2 } , \ldots , t _ { N } \right) = \prod _ { k = 1 } ^ { N } p \left( t _ { k } | t _ { 1 } , t _ { 2 } , \ldots , t _ { k - 1 } \right)<br>$$<br>åå‘çš„è®¡ç®—æ–¹æ³•ä¸å‰å‘ç›¸ä¼¼:<br>$$<br>p \left( t _ { 1 } , t _ { 2 } , \ldots , t _ { N } \right) = \prod _ { k = 1 } ^ { N } p \left( t _ { k } | t _ { k + 1 } , t _ { k + 2 } , \ldots , t _ { N } \right)<br>$$<br>biLMè®­ç»ƒè¿‡ç¨‹ä¸­çš„ç›®æ ‡å°±æ˜¯æœ€å¤§åŒ–:<br>$$<br>\sum _ { k = 1 } ^ { N } \left( \log p \left( t _ { k } | t _ { 1 } , \ldots , t _ { k - 1 } ; \Theta _ { x } , \vec { \Theta } _ { L S T M } , \Theta _ { s } \right) + \log p \left( t _ { k } | t _ { k + 1 } , \ldots , t _ { N } ; \Theta _ { x } , \overline { \Theta } _ { L S T M } , \Theta _ { s } \right) \right)<br>$$<br>ELMoå¯¹äºæ¯ä¸ªtoken $t_k$, é€šè¿‡ä¸€ä¸ªLå±‚çš„biLMè®¡ç®—å‡º2L+1ä¸ªè¡¨ç¤º:<br>$$<br>R_{ k } = { x _ { k } ^ { L M } , \vec { h } _ { k , j } ^ { L M } , h _ { k , j } ^ { L M } | j = 1 , \ldots , L } = { h _ { k , j } ^ { L M } | j = 0 , \ldots , L }<br>$$<br>å…¶ä¸­$h _ { k , 0 } ^ { L M }$æ˜¯å¯¹tokenè¿›è¡Œç›´æ¥ç¼–ç çš„ç»“æœ(è¿™é‡Œæ˜¯å­—ç¬¦é€šè¿‡CNNç¼–ç ), $h _ { k , j } ^ { L M } = \left[ \vec { h } _ { k , j } ^ { L M } ; \overline { h } _ { k , j } \right]$ æ˜¯æ¯ä¸ªbiLSTMå±‚è¾“å‡ºçš„ç»“æœ. åœ¨å®éªŒä¸­è¿˜å‘ç°ä¸åŒå±‚çš„biLMçš„è¾“å‡ºçš„tokenè¡¨ç¤ºå¯¹äºä¸åŒçš„ä»»åŠ¡æ•ˆæœä¸åŒ.</p>
<p>åº”ç”¨ä¸­å°†ELMoä¸­æ‰€æœ‰å±‚çš„è¾“å‡ºRå‹ç¼©ä¸ºå•ä¸ªå‘é‡, ELMok=E(Rk;Î˜Ïµ), æœ€ç®€å•çš„å‹ç¼©æ–¹æ³•æ˜¯å–æœ€ä¸Šå±‚çš„ç»“æœåšä¸ºtokençš„è¡¨ç¤º:$E \left( R _ { k } \right) = h _ { k , L } ^ { L M }$ æ›´é€šç”¨çš„åšæ³•æ˜¯é€šè¿‡ä¸€äº›å‚æ•°æ¥è”åˆæ‰€æœ‰å±‚çš„ä¿¡æ¯:<br>$$E L M o _ { k } ^ { t a s k } = E \left( R _ { k } ; \Theta ^ { t a s k } \right) = \gamma ^ { t a s k } \sum _ { j = 0 } ^ { L } s _ { j } ^ { t a s k } h _ { k , j } ^ { L M }$$</p>
<p>å…¶ä¸­$s_j$æ˜¯ä¸€ä¸ªsoftmaxå‡ºæ¥çš„ç»“æœ, $Î³$æ˜¯ä¸€ä¸ªä»»åŠ¡ç›¸å…³çš„scaleå‚æ•°, æˆ‘è¯•äº†å¹³å‡æ¯ä¸ªå±‚çš„ä¿¡æ¯å’Œå­¦å‡ºæ¥$s_j$å‘ç°å­¦ä¹ å‡ºæ¥çš„æ•ˆæœä¼šå¥½å¾ˆå¤š. æ–‡ä¸­æåˆ°$Î³$åœ¨ä¸åŒä»»åŠ¡ä¸­å–ä¸åŒçš„å€¼æ•ˆæœä¼šæœ‰è¾ƒå¤§çš„å·®å¼‚, éœ€è¦æ³¨æ„, åœ¨SQuADä¸­è®¾ç½®ä¸º0.01å–å¾—çš„æ•ˆæœè¦å¥½äºè®¾ç½®ä¸º1æ—¶.</p>
<p>ELMo: Context Matters</p>
<p>Instead of using a fixed embedding for each word, ELMo looks at the entire sentence before assigning each word in it an embedding. It uses a bi-directional LSTM trained on a specific task to be able to create those embeddings.<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3fub67ulaj20u20h3wfx.jpg" alt></p>
<p>ELMo provided a significant step towards pre-training in the context of NLP. The ELMo LSTM would be trained on a massive dataset in the language of our dataset, and then we can use it as a component in other models that need to handle language.</p>
<p>Whatâ€™s ELMoâ€™s secret?</p>
<p>ELMo gained its language understanding from being trained to predict the next word in a sequence of words - a task called Language Modeling. This is convenient because we have vast amounts of text data that such a model can learn from without needing labels.</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3fubpu9ibj20li0m1q5b.jpg" alt></p>
<p>We can see the hidden state of each unrolled-LSTM step peaking out from behind ELMoâ€™s head. Those come in handy in the embedding proecss after this pre-training is done.</p>
<p>ELMo actually goes a step further and trains a bi-directional LSTM â€“ so that its language model doesnâ€™t only have a sense of the next word, but also the previous word.<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3fuc693mrj211z0hbjur.jpg" alt><br>ELMo comes up with the contextualized embedding through grouping together the hidden states (and initial embedding) in a certain way (concatenation followed by weighted summation).<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3fuci4xodj213j0kitcq.jpg" alt></p>
<p>lstm-based language model<br>In case you are unfamiliar with language models, a language model is simply a model that can predict how â€œlikelyâ€ a certain sequence of words is to be a real piece of text. This is generally done by training a model to take a part of sentence (say, the first n words) and predict the next word â€“ or more precisely, output the probability of each word in the vocabulary being the next word (In this blog post, weâ€™ll focus on LSTM-based language models which are the focus of this paper). </p>
<p>One trick that this paper uses is to train a language model with reversed sentences that the authors call the â€œbackwardâ€ language model.<br>è¿™ç§æ¨¡å‹ï¼šä¸Šä¸€ä¸ªæ¨¡å‹çš„è¾“å‡ºåˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹è¾“å…¥<br>Furthermore, instead of using a single-layer LSTM, this paper uses a stacked, multi-layer LSTM. Whereas a single-layer LSTM would take the sequence of words as input, a multi-layer LSTM trains multiple LSTMs to take the output sequence of the LSTM in the previous layer as input (of course, the first layer takes the sequence of words as input). This is best illustrated in the following illustration:<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3flokoc0mj20ab07474a.jpg" alt></p>
<p>æœ€åçš„embedding æ˜¯æ˜¯å°†ä¸åŒçš„å±‚ combinationèµ·æ¥ï¼Œè¿™ä¸ªç³»æ•°æ˜¯é€šè¿‡å­¦ä¹ å‡ºæ¥çš„ã€‚<br>In ELMo, the part that is task specific is the combination of the task-agnostic representations. The weight is learned for each task and normalized using the softmax function. The parameter $\gamma$ is a task-dependent value that allows for scaling the entire vector, which is important during optimization.</p>
<p>ä¼˜ç¼ºç‚¹ï¼š</p>
<p>åœ¨ELMoä¸­ï¼ŒåµŒå…¥åŸºäºä¸€ä¸ªåŒå±‚çš„åŒå‘è¯­è¨€æ¨¡å‹ï¼ˆbiLMï¼‰çš„å†…éƒ¨çŠ¶æ€è®¡ç®—ï¼ŒELMoä¹Ÿæ˜¯å› æ­¤å¾—åçš„ï¼šEmbeddings from Language Modelsï¼ˆæ¥è‡ªè¯­è¨€æ¨¡å‹çš„åµŒå…¥ï¼‰ã€‚<br>ELMoçš„ç‰¹æ€§ï¼š<br>ELMoçš„è¾“å…¥æ˜¯å­—ç¬¦è€Œä¸æ˜¯å•è¯ã€‚è¿™ä½¿å¾—å®ƒå¯ä»¥åˆ©ç”¨å­å­—ï¼ˆsub-wordï¼‰å•å…ƒä¸ºè¯æ±‡è¡¨ä»¥å¤–çš„å•è¯è®¡ç®—æœ‰æ„ä¹‰çš„è¡¨ç¤ºï¼ˆå’ŒFastTextç±»ä¼¼ï¼‰ã€‚<br>ELMoæ˜¯biLMçš„å¤šå±‚æ¿€æ´»çš„è¿æ¥ï¼ˆconcatenationï¼‰ã€‚è¯­è¨€æ¨¡å‹çš„ä¸åŒå±‚ç¼–ç äº†å•è¯çš„ä¸åŒä¿¡æ¯ã€‚è¿æ¥æ‰€æœ‰å±‚ä½¿å¾—ELMoå¯ä»¥ç»„åˆå¤šç§è¯è¡¨ç¤ºï¼Œä»¥æå‡ä¸‹æ¸¸ä»»åŠ¡çš„è¡¨ç°ã€‚</p>
<h2 id="OpenAI-GPT"><a href="#OpenAI-GPT" class="headerlink" title="OpenAI GPT"></a>OpenAI GPT</h2><p>å®ƒçš„æ€æƒ³å…¶å®ä¹Ÿå¾ˆç®€å•ï¼Œä½¿ç”¨Transformeræ¥å­¦ä¹ ä¸€ä¸ªè¯­è¨€æ¨¡å‹ï¼Œå¯¹å¥å­è¿›è¡Œæ— ç›‘ç£çš„Embeddingï¼Œç„¶åæ ¹æ®å…·ä½“ä»»åŠ¡å¯¹Transformerçš„å‚æ•°è¿›è¡Œå¾®è°ƒã€‚</p>
<p>è¿™ç¯‡è®ºæ–‡ä¸­çš„ å¤šä»»åŠ¡å­¦ä¹ æ˜¯å¦‚ä½•ä½“ç°çš„å‘¢ï¼Ÿ<br>é¦–å…ˆæ˜¯æ— ç›‘ç£çš„pretraining ä¸­æœ‰ä¸€ä¸ªè¯­è¨€æ¨¡å‹ï¼Œéœ€è¦ä¼˜åŒ–ä¸€ä¸ªæœ€å¤§ä¼¼ç„¶ä¼°è®¡ L1ï¼Œç„¶åå†ç›‘ç£çš„fine-tuning ä¸­æœ‰ä¸€ä¸ªäº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œè¿™é‡Œä¹Ÿæ˜¯æœ‰ä¸€ä¸ªloss ï¼Œè®°ä¸ºL2ã€‚æ­£å¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åº”è¯¥è°ƒæ•´å‚æ•°æœ€å¤§åŒ–L2ï¼Œ ä½†æ˜¯æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯å¤šä»»åŠ¡å­¦ä¹ ï¼ŒåŒæ—¶è®©å®ƒæœ€å¤§ä¼¼ç„¶L1 å’ŒL2ã€‚<br>$$<br>L_{3}(\mathcal{C})=L_{2}(\mathcal{C})+\lambda \times L_{1}(\mathcal{C})<br>$$</p>
<h2 id="A-simple-but-tough-to-beat-baseline-for-sentence-embeddings"><a href="#A-simple-but-tough-to-beat-baseline-for-sentence-embeddings" class="headerlink" title="A simple but tough-to-beat baseline for sentence embeddings"></a>A simple but tough-to-beat baseline for sentence embeddings</h2><p>Taking the average of the word embeddings in a sentence tends to give too much weight to words that are quite irrelevant, semantically speaking. Smooth Inverse Frequency tries to solve this problem in two ways:</p>
<ul>
<li>Weighting: like our tf-idf baseline above, SIF takes the weighted average of the word embeddings in the sentence. Every word embedding is weighted by a/(a + p(w)), where a is a parameter that is typically set to 0.001 and p(w) is the estimated frequency of the word in a reference corpus. (ä½¿ç”¨æ–°çš„è¯æƒé‡è®¡ç®—æ–¹æ³•ï¼Œä¸æ˜¯tf-idf, é¢‘ç‡è¶Šé«˜ï¼Œæƒé‡è¶Šä½ï¼ŒæŠ‘åˆ¶é«˜é¢‘è¯)</li>
<li>Common component removal: next, SIF computes the principal component of the resulting embeddings for a set of sentences. It then subtracts from these sentence embeddings their projections on their first principal component. This should remove variation related to frequency and syntax that is less relevant semantically.<br>As a result, SIF downgrades unimportant words such as but, just, etc., and keeps the information that contributes most to the semantics of the sentence.</li>
</ul>
<p>ç¬¬ä¸€æ­¥ä¸­çš„$p(w) $ æ˜¯åœ¨è¯­æ–™ä¸­çš„è¯é¢‘ï¼Œç¬¬äºŒæ­¥ä¸­å¯¹æ•´ä¸ªå¥å­é›†åˆè¿›è¡Œä¸€æ¬¡PCAï¼Œç„¶åå¯¹æ¯ä¸ªå¥å­ä¸Šé¢å¾—åˆ°çš„å‘é‡å‡å»å®ƒåœ¨ç¬¬ä¸€å¥‡å¼‚å‘é‡æˆ–è€…è¯´ä¸»æˆåˆ†ä¸Šçš„æŠ•å½±ã€‚<br>æœ€ååˆæ­¥çš„å¥å­å‘é‡å‡å»å¯¹åº”å¥å­å‘é‡çš„å…±æ€§æˆåˆ†(èµ·åˆ°å¹³æ»‘ä½œç”¨),å¾—åˆ°æœ€åçš„ç‹¬æœ‰çš„å¥å­å‘é‡(ä½¿å¾—å„ä¸ªå¥å­å‘é‡é—´çš„è€¦åˆåº¦é™ä½,å¢å¼ºå¥å­çš„é²æ£’æ€§).è€¦åˆæ€§è¶Šä½ï¼ˆæ¨¡å—ä¹‹é—´çš„å…³è”æ€§è¶Šå°ï¼‰</p>
<p>ä½œç”¨ï¼š</p>
<p>ç¬¬ä¸€æ­¥éª¤ä¸­çš„è¶…å‚æ•° $a $ æ˜¯ä¸€ç§å¹³æ»‘é¡¹ï¼Œå¯¹äºä½é¢‘è¯çš„æ”¯æŒï¼Œå‡ºç°çš„æ¬¡æ•°å°‘ï¼Œåè€Œæƒé‡æ˜¯æ¯”è¾ƒå¤§çš„ï¼Œé™ä½å¸¸è§è¯çš„æƒé‡ã€‚$ ( \alpha p(w)) $,å…¶ä¸­$(p(w))$æ˜¯å•è¯ $(w) $åœ¨æ•´ä¸ªè¯­æ–™ä¸­å‡ºç°çš„æ¦‚ç‡(è¯é¢‘è§’åº¦), $ (\alpha) $æ˜¯ä¸€ä¸ªè¶…å‚æ•°. è¿™æ ·, å³ä½¿å’Œ $ (c_s) $çš„å†…ç§¯å¾ˆå°, è¿™ä¸ªå•è¯ä¹Ÿæœ‰æ¦‚ç‡å‡ºç°. ç¬¬äºŒæ­¥éª¤ä¸­çš„å‡å» ä¸»æˆåˆ†ï¼Œå¯ä»¥ç†è§£ä¸ºè®©å„ä¸ªè¯å‘é‡æ›´å¥½çš„åˆ†å¼€ï¼Œå‡å»å…¬å…±çš„éƒ¨åˆ†ï¼Œå‡å°‘è€¦åˆæ€§ï¼Œä½¿å¾—ç›¸ä¼¼çš„å¥å­èšç±»åœ¨ä¸€èµ·ã€‚å› ä¸ºè¿™ä¸ªä¸»æˆåˆ†æ˜¯æ•´ä¸ªè¯­æ–™åº“ä¸­çš„ä¸»æˆåˆ†.</p>
<p>å¦å¤–è®ºæ–‡ä¸­è¿˜æåˆ°äº†è¿™ç§æ–¹æ³•çš„é²æ£’æ€§:</p>
<ul>
<li>ä½¿ç”¨ä¸åŒè¯­æ–™(å¤šç§é¢†åŸŸ)è®­ç»ƒå¾—åˆ°çš„ä¸åŒçš„word embedding, å‡å–å¾—äº†å¾ˆå¥½çš„æ•ˆæœ, è¯´æ˜äº†å¯¹å„ç§è¯­æ–™çš„å‹å¥½.</li>
<li>ä½¿ç”¨ä¸åŒè¯­æ–™å¾—åˆ°çš„è¯é¢‘, ä½œä¸ºè®¡ç®—è¯æƒé‡çš„å› ç´ , å¯¹æœ€ç»ˆçš„ç»“æœå½±å“å¾ˆå°.</li>
<li>å¯¹äºæ–¹æ³•ä¸­çš„è¶…å‚æ•°, åœ¨å¾ˆå¤§èŒƒå›´å†…, è·å¾—çš„ç»“æœéƒ½æ˜¯åŒºåŸŸä¸€ç›´çš„, å³è¶…å‚æ•°çš„é€‰æ‹©æ²¡æœ‰å¤ªå¤§çš„å½±å“.</li>
</ul>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3dw277xiyj20pi0c10ww.jpg" alt></p>
<p>å°½ç®¡é•¿æœŸä»¥æ¥å¥å­çš„æ— ç›‘ç£è¡¨ç¤ºå­¦ä¹ æ˜¯ä¸»æµï¼Œæœ€è¿‘å‡ ä¸ªæœˆï¼ˆ2017å¹´æœ«/2018å¹´åˆï¼‰ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†è®¸å¤šéå¸¸æœ‰è¶£çš„å·¥ä½œï¼Œæ˜¾ç¤ºäº†å‘ç›‘ç£å­¦ä¹ å’Œå¤šä»»åŠ¡å­¦ä¹ ï¼ˆä¸åŒçš„ä»»åŠ¡å­¦ä¹ åˆ°ä¸åŒçš„ç»´åº¦ï¼Œç„¶åç»„åˆï¼‰è½¬å‘çš„è¶‹åŠ¿ã€‚</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3dvg2o3wwj20qo0grdgp.jpg" alt></p>
<ul>
<li>å¼ºåŠ›/è¿…é€Ÿçš„åŸºçº¿ï¼šFastTextã€è¯è¢‹ï¼ˆBag-of-Wordsï¼‰</li>
<li>å½“å‰æœ€å…ˆè¿›æ¨¡å‹ï¼šELMoã€Skip-Thoughtsã€Quick-Thoughtsã€ InferSentã€MILA/MSRçš„General Purpose Sentence Representationsã€Googleçš„Universal Sentence Encoder</li>
</ul>
<p>å…³äºnlp ä¸­çš„word embedding æ˜¯å¯ä»¥æœ‰ phrases, sentences, and paragraphs ä¸‰ä¸ªä¸åŒç±»åˆ«çš„ embeddingï¼Œæ‰€ä»¥è¿˜æ˜¯æŒºå¥½çš„ã€‚</p>
<p>ä¼˜ç‚¹ï¼š</p>
<ul>
<li>ç¨‹åºçš„è¿è¡Œåªéœ€è¦åå‡ åˆ†é’Ÿï¼Œæ•ˆæœå’Œç¥ç»ç½‘ç»œæ˜¯ç›¸å½“çš„</li>
<li>å±äºæ— ç›‘ç£çš„å­¦ä¹ ï¼Œå¯ä»¥å¯¹å¤§è§„æ¨¡çš„è¯­æ–™è¿›è¡Œåˆ©ç”¨ï¼Œç›¸å¯¹äºæœ‰ç›‘ç£çš„å­¦ä¹ æ–¹å¼ï¼Œè¿™ä¸ªæ˜¯ä¼˜åŠ¿</li>
</ul>
<p>ç¼ºç‚¹ï¼š</p>
<ul>
<li>ç¼ºç‚¹å°±æ˜¯æ²¡æœ‰è€ƒè™‘å¥å­çš„è¯­åº,å¯¼è‡´ä¸èƒ½è¾¨åˆ«(â€œæˆ‘çˆ±ä½ â€è¿˜æ˜¯â€ä½ çˆ±æˆ‘â€), åªæ˜¯å­—æ„çš„è¡¨è¾¾ï¼Œå¹¶æ²¡æœ‰ä½“ç°äº†å¥æ„</li>
<li>å¯¹äºçŸ­æ–‡æœ¬ä¸Šçš„word2vecï¼Œ SIF æ•ˆæœå¾ˆå¥½ï¼Œä½†æ˜¯æ¶‰åŠåˆ°è¯­æ„ç†è§£çš„æ—¶å€™ï¼Œè¿™ç§æ–¹å¼æ•ˆæœå°±ä¸€èˆ¬äº†ï¼Œè€Œè¿™ä¸ªæ—¶å€™å°±åº”è¯¥ä½¿ç”¨ elmoï¼Œtransformer or bert ç­‰æ¨¡å‹äº†</li>
</ul>
<h2 id="Supervised-Learning-of-Universal-Sentence-Representations-from-Natural-Language-Inference-Data"><a href="#Supervised-Learning-of-Universal-Sentence-Representations-from-Natural-Language-Inference-Data" class="headerlink" title="Supervised Learning of Universal Sentence Representations from Natural Language Inference Data"></a>Supervised Learning of Universal Sentence Representations from Natural Language Inference Data</h2><p>æ–‡ç« æˆåŠŸçš„æ‰¾åˆ°äº†NLPé¢†åŸŸçš„ImageNet â€” SNLI (Stanford Natural Language Inference dataset), å¹¶ä¸”è¯•éªŒäº†ä¸åŒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œæœ€ç»ˆç¡®å®šbi-LSTM max pooled ä¸ºæœ€ä½³æ¨¡å‹ã€‚</p>
<table>
<thead>
<tr>
<th>åŸŸ</th>
<th>æ•°æ®</th>
<th>ä»»åŠ¡</th>
<th>æ¨¡å‹(ç¼–ç å™¨)</th>
</tr>
</thead>
<tbody>
<tr>
<td>CV</td>
<td>ImageNet</td>
<td>image classification</td>
<td>Le-Net, VGG-Net, Google-Net, ResNet, DenseNet</td>
</tr>
<tr>
<td>NLP</td>
<td>SNLI</td>
<td>NLI</td>
<td>?</td>
</tr>
</tbody>
</table>
<p>åŸºäºç›‘ç£å­¦ä¹ æ–¹æ³•å­¦ä¹ sentence embeddingså¯ä»¥å½’çº³ä¸ºä¸¤ä¸ªæ­¥éª¤ï¼š<br>ç¬¬ä¸€æ­¥é€‰æ‹©ç›‘ç£è®­ç»ƒæ•°æ®ï¼Œè®¾è®¡ç›¸åº”çš„åŒ…å«å¥å­ç¼–ç å™¨Encoderçš„æ¨¡å‹æ¡†æ¶ï¼›<br>ç¬¬äºŒæ­¥é€‰æ‹©ï¼ˆè®¾è®¡ï¼‰å…·ä½“çš„å¥å­ç¼–ç å™¨ï¼ŒåŒ…æ‹¬DANã€åŸºäºLSTMã€åŸºäºCNNå’ŒTransformerç­‰ã€‚</p>
<p>æ•°æ®é›†ï¼š</p>
<p>æœ¬æ–‡é‡‡ç”¨çš„æ˜¯Stanford Natural Language Inference Datasetsï¼Œç®€ç§°SNLI ï¼ˆNLPé¢†åŸŸçš„ImageNet ï¼‰ã€‚SNLIåŒ…å«570Kä¸ªäººç±»äº§ç”Ÿçš„å¥å­å¯¹ï¼Œæ¯ä¸ªå¥å­å¯¹éƒ½å·²ç»åšå¥½äº†æ ‡ç­¾ï¼Œæ ‡ç­¾æ€»å…±åˆ†ä¸ºä¸‰ç±»ï¼šè•´å«ã€çŸ›ç›¾å’Œä¸­ç«‹ï¼ˆEntailmentã€contradiction and neutralï¼‰ã€‚ä¸‹é¢æ˜¯è¿™äº›æ•°æ®é›†çš„ä¸€ä¸ªä¾‹å­ï¼š</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eqwkv9tlj20kd097gm4.jpg" alt><br>ä»ä¸Šå›¾å¯ä»¥çœ‹å‡ºï¼Œæ¯ä¸ªå¥å­å¯¹ä¸ºï¼ˆtext, hypothesisï¼‰,ä¸­é—´çš„judgmentsä¸ºå®ƒä»¬çš„æ ‡ç­¾ã€‚å¯ä»¥çœ‹åˆ°æ ‡ç­¾æ˜¯ç»¼åˆäº†5ä¸ªä¸“å®¶çš„æ„è§ï¼Œæ ¹æ®å°‘æ•°æœä»å¤šæ•°çš„åŸåˆ™å¾—åˆ°çš„ã€‚</p>
<p>7ç§ä¸åŒçš„architecturesï¼š </p>
<ol>
<li>standard recurrent encoders with LSTM ï¼Œå–æœ€åä¸€ä¸ªéšçŠ¶æ€</li>
<li>standard recurrent encoders with GRU ï¼Œå–æœ€åä¸€ä¸ªéšçŠ¶æ€<br>ä¸Šè¿°ä¸¤ç§æ˜¯åŸºç¡€çš„recurrent encoderï¼Œåœ¨å¥å­å»ºæ¨¡ä¸­é€šå¸¸å°†ç½‘ç»œä¸­çš„æœ€åä¸€ä¸ªéšè—çŠ¶æ€ä½œä¸ºsentence representationï¼› </li>
<li>conncatenation of last hidden states of forward and backward GRU<br>è¿™ç§æ–¹æ³•æ˜¯å°†å•å‘çš„ç½‘ç»œå˜æˆäº†åŒå‘çš„ç½‘ç»œï¼Œç„¶åç”¨å°†å‰å‘å’Œåå‘çš„æœ€åä¸€ä¸ªçŠ¶æ€è¿›è¡Œè¿æ¥ï¼Œå¾—åˆ°å¥å­å‘é‡ï¼› </li>
<li>Bi-directional LSTMs (BiLSTM) with mean pooling </li>
<li>Bi-directional LSTMs (BiLSTM) with max pooling<br>è¿™ä¸¤ç§æ–¹æ³•ä½¿ç”¨äº†åŒå‘LSTMç»“åˆä¸€ä¸ªpoolingå±‚çš„æ–¹æ³•æ¥è·å–å¥å­è¡¨ç¤ºï¼Œå…·ä½“å…¬å¼å¦‚ä¸‹ï¼š </li>
<li>self-attentive network<br>è¿™ä¸ªç½‘ç»œåœ¨åŒå‘LSTMçš„åŸºç¡€ä¸ŠåŠ å…¥äº†attentionæœºåˆ¶ï¼Œå…·ä½“ç½‘ç»œç»“æ„å¦‚ä¸‹ï¼š </li>
<li>hierarchical convolutional networks </li>
</ol>
<p>Now that we have discussed the various sentence encoding architectures used in the paper, letâ€™s go through the part of the network which takes these sentence embeddings and predicts the output label.</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3eqyoxmknj20ey0d640u.jpg" alt><br>After the sentence vectors are fed as input to this model, 3 matching methods are applied to extract relations between the text, u and hypothesis, v â€“</p>
<ul>
<li>concatenation of the two representations (u, v)</li>
<li>element-wise product u * v</li>
<li>and, absolute element-wise difference |u â€“ v |</li>
</ul>
<p>The resulting vector captures information from both the text, u and the hypothesis, v, and is fed into a 3-class classifier consisting of multiple fully connected layers followed by a softmax layer.</p>
<h2 id="Universal-Sentence-Encoder"><a href="#Universal-Sentence-Encoder" class="headerlink" title="Universal Sentence Encoder"></a>Universal Sentence Encoder</h2><p>è¿™ç¯‡æ–‡ç« åŸºäºInferSentï¼Œ ä¹Ÿæ˜¯æƒ³æ‰¾åˆ°ä¸€ä¸ªuniversal encoderã€‚ä¸åŒä¹‹å¤„åœ¨äºæ–‡ç« æŠŠInferSentçš„bi-lstmæ¢æˆäº†DANï¼ˆæˆ–è€…Transformer)ï¼Œè€Œä½¿ç”¨DANè¿™æ ·â€œç®€å•â€çš„encoderçš„æ•ˆæœç«Ÿç„¶ç›¸å½“å¥½ï¼ˆå°¤å…¶æ˜¯æ—¶é—´å’Œå†…å­˜æ¶ˆè€—å’Œå…¶ä»–ç®—æ³•æ¯”å°å¾ˆå¤šã€‚ï¼‰</p>
<p>The Google Sentence Encoder is Googleâ€™s answer to Facebookâ€™s InferSent. It comes in two forms:</p>
<ul>
<li>an advanced model that takes the element-wise sum of the context-aware word representations produced by the encoding subgraph of a Transformer model.</li>
<li>a simpler Deep Averaging Network (DAN) where input embeddings for words and bigrams are averaged together and passed through a feed-forward deep neural network.<br>The Transformer-based model tends to give better results, but at the time of writing, only the DAN-based encoder was available. In contrast to InferSent, the Google Sentence Encoder was trained on a combination of unsupervised data (in a skip-thought-like task) and supervised data (the SNLI corpus).</li>
</ul>
<p>DAN<br>å…¶å®DAN(Deep Averaging Networks)åº”è¯¥å±äºBag of Wordsç±»çš„ç®—æ³•ã€‚å› ä¸ºæ¯”è¾ƒç‰¹æ®Šï¼Œå•ç‹¬åˆ—å‡ºæ¥ã€‚ å®ƒæ˜¯åœ¨å¯¹æ‰€æœ‰è¯è¯­å–å¹³å‡åï¼Œåœ¨ä¸Šé¢åŠ ä¸Šå‡ å±‚ç¥ç»ç½‘ç»œã€‚ç‰¹æ®Šçš„åœ°æ–¹åœ¨äºå®ƒåœ¨sentiment analysisä¸­è¡¨ç°ä¹Ÿä¸é”™ï¼Œè¿™åœ¨BOWç±»æ–¹æ³•ä¸­æ¯”è¾ƒç½•è§ã€‚</p>
<p><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g3esxw2nilj20dh08ujth.jpg" alt></p>
<table>
<thead>
<tr>
<th>æ–°æ–¹æ³•</th>
<th>ç±»å‹</th>
<th>åŸºäºçš„æ—§ç®—æ³•</th>
<th>è´¡çŒ®</th>
</tr>
</thead>
<tbody>
<tr>
<td>SIF</td>
<td>æ— ç›‘ç£</td>
<td>BOW</td>
<td>ä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„baselineç®—æ³•</td>
</tr>
<tr>
<td>InferSent</td>
<td>ç›‘ç£</td>
<td>NA</td>
<td>æ‰¾åˆ°äº†NLPé¢†åŸŸçš„ImageNet â€“ SNLIï¼Œ å¹¶ç»™å‡ºäº†ä¸€ä¸ªstate-of-art ç®—æ³•</td>
</tr>
<tr>
<td>P-mean</td>
<td>æ— ç›‘ç£</td>
<td>BOW</td>
<td>æ¯”SIFæ›´ç®€å•ä¸”æœ‰æ•ˆçš„ä¸€ä¸ªç®—æ³•ä¸”é€‚ç”¨äºcross-lingual</td>
</tr>
<tr>
<td>Universal-sentence-encoder</td>
<td>ç›‘ç£</td>
<td>InferSent</td>
<td>æ›´åŠ ç®€å•çš„encoder</td>
</tr>
</tbody>
</table>
<p>æ–‡ç« å…±æå‡ºä¸¤ç§åŸºäºä¸åŒç½‘ç»œæ¶æ„çš„Universal Sentence Encoderï¼šTransformer and Deep Averaging Network (DAN).<br>Our two encoders have different design goals. One based on the transformer architecture targets high accuracy at the cost of greater model complexity and resource consumption. The other targets efficient inference with slightly reduced accuracy.</p>
<p>NLP æ˜¯å¦‚ä½•ä½“ç°äº†å¤šä»»åŠ¡è®­ç»ƒçš„ï¼Ÿ</p>
<p>è¯¥ç¯‡è®ºæ–‡åœ¨å‰äººçš„ç ”ç©¶åŸºç¡€ä¸Šï¼Œç»¼åˆåˆ©ç”¨æ— ç›‘ç£è®­ç»ƒæ•°æ®å’Œæœ‰ç›‘ç£è®­ç»ƒæ•°æ®ï¼Œè¿›è¡Œå¤šä»»åŠ¡è®­ç»ƒï¼Œä»è€Œå­¦ä¹ ä¸€ä¸ªé€šç”¨çš„å¥å­ç¼–ç å™¨ã€‚æ— ç›‘ç£è®­ç»ƒæ•°æ®åŒ…æ‹¬é—®ç­”(QA)å‹ç½‘é¡µå’Œè®ºå›ï¼ŒWikipedia, web newsï¼Œæœ‰ç›‘ç£è®­ç»ƒæ•°æ®ä¸ºSNLIã€‚å¤šä»»åŠ¡æ¨¡å‹è®¾è®¡å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå…¶ä¸­ç°è‰²çš„encoderä¸ºå…±äº«å‚æ•°çš„å¥å­ç¼–ç å™¨ã€‚</p>
<p><img src="https://upload.cc/i1/2019/08/04/2VsB5g.png" alt="img"></p>
<p>è®ºæ–‡å¯¹æ¯”äº†DANå’ŒTransfomerè¿™ä¸¤ç§ç¼–ç å™¨ã€‚å¾—å‡ºå¦‚ä¸‹ç»“è®ºï¼š</p>
<ul>
<li>Transformer æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸Šçš„è¡¨ç°éƒ½ä¼˜äºç®€å•çš„ DAN æ¨¡å‹ï¼Œä¸”åœ¨å¤„ç†çŸ­å¥å­æ—¶åªç¨æ…¢ä¸€äº›ã€‚ï¼ˆæ›´é«˜çš„ç²¾åº¦ï¼‰</li>
<li>DANæ¨¡å‹ä¹Ÿèƒ½å…·æœ‰å¾ˆä¸é”™çš„è¡¨ç°ï¼Œå¹¶ä¸”ç›¸è¾ƒäºTransformeræ¨¡å‹ï¼Œè®­ç»ƒæ—¶é—´å’Œå†…å­˜çš„å¼€é”€éƒ½æ›´å°ï¼Œå°¤å…¶æ˜¯å½“å¥å­è¾ƒé•¿æ—¶ã€‚ï¼ˆæ›´å¿«çš„é€Ÿåº¦ï¼‰</li>
</ul>
<p>æ€»ç»“ï¼š</p>
<p>Sentence Embeddingçš„è´¨é‡å¾€å¾€ç”±è®­ç»ƒæ•°æ®å’ŒEncoderå…±åŒå†³å®šã€‚Encoderä¸ä¸€å®šæ˜¯è¶Šå¤æ‚è¶Šå¥½ï¼Œéœ€è¦ä¾æ®ä¸‹æ¸¸ä»»åŠ¡ã€è®¡ç®—èµ„æºã€æ—¶é—´å¼€é”€ç­‰å¤šæ–¹é¢å› ç´ ç»¼åˆè€ƒè™‘ã€‚</p>
<h2 id="BERTçš„ç†è§£"><a href="#BERTçš„ç†è§£" class="headerlink" title="BERTçš„ç†è§£"></a>BERTçš„ç†è§£</h2><p><strong>è¯æ±‡æ‰©å±•ï¼š</strong></p>
<p>å¯¹äºè¯å‘é‡ä¸­ OOV é—®é¢˜çš„å¤„ç†æ–¹æ³•ï¼š</p>
<ol>
<li>å¦‚æœä½¿ç”¨è¯å‘é‡åˆ†è¯çš„è¯ï¼Œä¸€ç§å¸¸è§çš„æ˜¯å­—èŠ‚ç»´åº¦ n-gram æ¨¡å‹ï¼Œä¹Ÿå°±æ˜¯æŠŠä¸€ä¸ªå•è¯åˆ†æˆå¤šä¸ªéƒ¨åˆ†ï¼Œæ¯”å¦‚è¯´playing åˆ†æˆplay he ##ing ä¸¤ä¸ªtokenï¼Œè¿™ç§æ›´åŠ ç»†ç²’åº¦çš„åˆ’åˆ†æ˜¯ä¸€ç§å¸¸è§çš„å¤„ç†oov çš„æ–¹å¼ã€‚</li>
<li>ä½†æ˜¯åœ¨å·¥ä¸šç•Œï¼Œç»å¸¸ä½¿ç”¨å¤šä¸ªä¸åŒçš„è¯­è¨€æ¨¡å‹å¾—åˆ°word2vecï¼Œ å¯ä»¥åˆ†æˆä¸¤ç±»ï¼Œä¸€ç±»æ˜¯é’ˆå¯¹è¯¥ä»»åŠ¡è®­ç»ƒçš„word2vecï¼Œä¸€ç±»æ˜¯åœ¨é€šç”¨çš„æ¨¡å‹ä¸‹è¿›è¡Œè®­ç»ƒçš„word2vecï¼Œ å¹¶ä¸”å½“è¿™ç§è®­ç»ƒæ–¹æ³•ä¸åŒçš„æ—¶å€™ï¼Œæœ€åå¾—åˆ°çš„ç»“æœä¹Ÿæ˜¯ä¸åŒçš„ã€‚é€šè¿‡ä¸åŒçš„ä»»åŠ¡è¿›è¡Œè¡¥å……ã€‚åœ¨ä¸€å®šç¨‹åº¦ä¸Šæ˜¯å¯ä»¥ç¼“è§£ oov é—®é¢˜çš„ã€‚</li>
</ol>
<p>åœ¨å¥å­å‘é‡ä¸­è¿›è¡Œè¯æ±‡æ‰©å±•çš„æ–¹å¼ï¼šå¸¸è§çš„æ˜¯ä½¿ç”¨ word2vecçš„è¯å‘é‡æ¥è¿›è¡Œæ‰©å±•å¥å­å‘é‡ä¸­çš„è¯å‘é‡ã€‚</p>
<p><strong>ELMo</strong></p>
<p>æ€è·¯æ˜¯ä½¿ç”¨åŒå‘RNN åœ¨å¤§é‡æœªæ ‡æ³¨æ•°æ®ä¸Šè®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œå¯¹äºä¹‹åç‰¹å®šçš„ä»»åŠ¡ï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªè¯­è¨€æ¨¡å‹è¿›è¡Œç‰¹å¾æå–å¾—åˆ°è¾“å‡ºçš„å‘é‡ã€‚å’Œ word2vec ä¸åŒçš„æ˜¯ï¼Œè¿™ä¸ªembedding æ˜¯æœ‰ä¸Šä¸‹æ–‡çš„ã€‚æ¯”å¦‚è¯´ bankçš„embedding çš„ä¸Šä¸‹æ–‡å¦‚æœæœ‰river é‚£ä¹ˆå°±æ˜¯æ°´è¾¹çš„æ„æ€ï¼›å¦‚æœä¸Šä¸‹æ–‡æœ‰money é‚£ä¹ˆæ›´å¯èƒ½æ˜¯é“¶è¡Œçš„æ„æ€ã€‚</p>
<p>å®ç°ï¼š åŸºäºlstm è¿›è¡Œå®ç°çš„ï¼Œæ€»çš„loss æ˜¯å‰åä¸¤ä¸ªlossçš„ç›¸åŠ ï¼Œä¼˜åŒ–çš„æ—¶å€™ï¼Œä¸¤ä¸ªlstmçš„äº¤å‰ç†µåŠ èµ·æ¥æ˜¯æœ€å°çš„ã€‚</p>
<p>openai å‡ºçš„ GPT (generative pre-training)ï¼Œ å¾—åˆ°çš„è¯­è¨€æ¨¡å‹ä¸­çš„å‚æ•°ä¸æ˜¯å›ºå®šçš„ï¼Œæ˜¯å¯ä»¥æ ¹æ®ç‰¹å®šçš„ä»»åŠ¡è¿›è¡Œå¾®è°ƒï¼Œä½¿å¾—è¯å‘é‡æ›´åŠ åŒ¹é…ç‰¹å®šçš„ä»»åŠ¡ã€‚æ€æƒ³ä¹Ÿæ˜¯å¾ˆç®€å•ï¼Œä½¿ç”¨transformerå­¦ä¹ ä¸€ä¸ªè¯­è¨€æ¨¡å‹ï¼Œå¯¹å¥å­è¿›è¡Œæ— ç›‘ç£çš„embeddingï¼Œç„¶åæ ¹æ®ç‰¹å®šçš„ä»»åŠ¡å¯¹transformerçš„å‚æ•°è¿›è¡Œå¾®è°ƒã€‚</p>
<p>æ— ç›‘ç£çš„é¢„è®­ç»ƒï¼š<br>æœ€åˆçš„æ—¶å€™ transformeræ˜¯ç”¨æ¥è¿›è¡Œæœºå™¨ç¿»è¯‘çš„ï¼Œencoder å¾—åˆ°çš„è¾“å‡ºè¾“å…¥åˆ°decoderä¸­å»ã€‚ä½†æ˜¯åœ¨GPT ä¸­çš„æ¨¡å‹ï¼Œencoder æ˜¯ç”¨æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªè¯çš„ã€‚ä½†æ˜¯åŸºäºself-attentionçš„åŸºæœ¬ç»“æ„ï¼Œå®ƒæ˜¯èƒ½å¤Ÿçœ‹ä¸­å¿ƒè¯æ±‡å·¦å³ä¸¤è¾¹çš„ä¸Šä¸‹æ–‡ï¼Œè¿™ä¸ªç‰¹ç‚¹å’Œæƒ³è¦è¾¾åˆ°çš„ä»»åŠ¡æ˜¯ä¸ç¬¦åˆè¦æ±‚çš„ã€‚æ‰€ä»¥è¿™é‡Œä½¿ç”¨åˆ°äº† maskçš„åŸç†ï¼Œå°†ä¸­å¿ƒè¯åé¢çš„è¯æ±‡é®ä½ï¼Œç„¶åè¿›è¡Œè®­ç»ƒã€‚</p>
<p>æœ‰ç›‘ç£çš„fine-tuning<br>å½“åªæœ‰ä¸€ä¸ªå¥å­ï¼ˆåˆ†ç±»é—®é¢˜ï¼‰</p>
<p>ä½¿ç”¨ç®€å•çš„åˆ†ç±»é—®é¢˜ä½œä¸ºä¸€ä¸ªä¾‹å­ï¼Œç»™å®šä¸€ä¸ªå¥å­(x1, â€¦xn)ï¼Œç„¶åç»™å®šæ ‡ç­¾ã€‚ç„¶åå†æœ€ä¸Šå±‚åŠ ä¸Šä¸€ä¸ªsoftmaxï¼Œä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°è®¡ç®—lossï¼Œä»è€Œæ ¹æ®æ•°æ®è°ƒæ•´ä¹‹å‰ transformer å’Œsoftmax ä¸­weights çš„å‚æ•°ã€‚</p>
<p>æœ¬æ¥æŒ‰ç…§elmo çš„æ€æƒ³ï¼Œæˆ‘ä»¬å¯ä»¥fixedï¼ˆå›ºå®šï¼‰encoder è¿™ä¸ªè¯­è¨€æ¨¡å‹ä¸­çš„å‚æ•°ï¼Œç„¶ååªæ˜¯è®­ç»ƒæœ€åsoftmax ä¸­weights çš„å‚æ•°ï¼Œä½†æ˜¯è¿™é‡ŒåŒæ—¶å»ä¼˜åŒ– encoder å’Œæœ€åsoftmax çš„å‚æ•°ï¼Œå°±ç±»ä¼¼ä¸€ç§å¤šä»»åŠ¡å­¦ä¹ ï¼ŒåŒæ—¶ä¼˜åŒ–äº†ä¸¤ä¸ªlossï¼Œå¹¶ä¸”è¿™ä¸¤ä¸ªloss ä¸­æ˜¯å¯ä»¥è®¾ç½®æƒé‡çš„ï¼Œæ‰€ä»¥ä»ç†è®ºä¸Šè®²æ¨¡å‹æ˜¯å…·æœ‰æ›´å¥½çš„æ³›åŒ–æ€§èƒ½çš„ã€‚ï¼ˆå¯¹äºå‰ä¸€ä¸ªloss çš„è®­ç»ƒï¼Œå› ä¸ºå‰è€…æ˜¯æ— ç›‘ç£çš„ï¼Œæ‰€ä»¥è¿™é‡Œåªæ˜¯ä½¿ç”¨äº†å…¶ä¸­çš„xï¼Œè€Œæ²¡æœ‰ä½¿ç”¨å…¶ä¸­çš„yï¼‰å¹¶ä¸”è®­ç»ƒé€Ÿåº¦ä¹Ÿä¼šæé«˜ï¼Œä¸ºä»€ä¹ˆè¿™ä¹ˆè¯´å‘¢ï¼Ÿå› ä¸ºæ˜¯åŸºäºå¤§çš„å·²ç»è®­ç»ƒå¥½çš„æ•°æ®é›†ä¸Šè¿›è¡Œfine tuneï¼Œå¾—åˆ°çš„ç»“æœå¯ä»¥ç”¨ä¸ä¼šå¤ªå·®æ¥è¿›è¡Œæè¿°ï¼Œé‚£ä¹ˆä½ çš„loss ä¹Ÿä¼šç›¸åº”çš„ä¸ä¼šå¤ªå¤§ï¼Œæ‰€ä»¥éœ€è¦çš„è¿­ä»£çš„æ¬¡æ•°ä¹Ÿä¸ä¼šå¾ˆå¤šã€‚</p>
<p>å½“æœ‰ä¸¤ä¸ªå¥å­çš„æ—¶å€™ï¼ˆæ¯”å¦‚ç›¸ä¼¼åº¦çš„è®¡ç®—æˆ–è€…é—®ç­”ç³»ç»Ÿï¼‰ã€‚<br>éœ€è¦ä½¿ç”¨ç‰¹æ®Šçš„æŠ€å·§å°†ä¸¤ä¸ªåºåˆ—å˜æˆä¸€ä¸ªè¾“å…¥åºåˆ—ã€‚<br>ï¼ˆä¸Šé¢æœ‰ä¸ªå›¾æ˜¯å¯ä»¥éå¸¸æ¸…æ¥šçš„å±•ç¤ºå¦‚ä½•å¤„ç†å¤šç§ä¸åŒè¾“å…¥ï¼‰</p>
<p>å¯¹äºåªæœ‰ä¸€ä¸ªåºåˆ—çš„ä»»åŠ¡ï¼Œå¯ä»¥åœ¨å‰ååŠ ä¸Šä¸¤ä¸ªç‰¹æ®Štokenï¼Œâ€startâ€ å’Œâ€extractâ€ï¼Œåˆ†åˆ«è¡¨ç¤ºå¼€å§‹å’Œç»“æŸï¼›å¯¹äºä¸¤ä¸ªåºåˆ—ï¼Œå¯ä»¥åœ¨ä¸­é—´åŠ ä¸Šä¸€ä¸ªç‰¹æ®Šçš„token, â€œdelimâ€ï¼Œè¾“å‡ºæ˜¯ä¸‰åˆ†ç±»æ ‡ç­¾ä¸­çš„ä¸€ä¸ªã€‚å¦‚æœæ˜¯ç›¸ä¼¼åº¦è®¡ç®—ï¼Œå› ä¸ºå¯¹ç§°æ€§ï¼Œå¯ä»¥æŠŠä»–ä»¬äº¤æ¢é¡ºåºï¼Œç„¶åè¾“å…¥ä¸¤ä¸ªtransformerã€‚</p>
<p><img src="https://i.loli.net/2019/08/31/mJVuLDAM1sOXrYE.png" alt="1.png"></p>
<p>å¥½ç»ˆäºè¿›å…¥äº†bert çš„å­¦ä¹ ï¼š</p>
<p>é—®é¢˜ï¼š ä¼ ç»Ÿçš„ELMo æˆ–è€…GPT æœ€å¤§çš„é—®é¢˜æ˜¯è¯­è¨€æ¨¡å‹æ˜¯å•å‘ï¼Œä¸åŒåŒæ—¶å¾—åˆ°å‰åä¸¤ä¸ªæ–¹å‘çš„ä¿¡æ¯ã€‚æ³¨æ„transformerä¸­çš„self-attention ä»ç†è®ºä¸Šæ˜¯å¯ä»¥åŒæ—¶handle å‰åä¸Šä¸‹æ–‡çš„ï¼Œä½†æ˜¯è¿™é‡Œä½¿ç”¨äº†mask æœºåˆ¶ï¼Œæ‰€ä»¥è¿™ç§æ–¹å¼ä¹Ÿæ˜¯ä¸è¡Œçš„ã€‚<br>é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ–¹æ³•ï¼š<br>é€šè¿‡å¯¹ç½‘ç»œç»“æ„çš„çº¦æŸï¼Œæ¯”å¦‚CNNçš„å±€éƒ¨ç‰¹æ•ˆï¼ŒRNNçš„æ—¶åºç‰¹æ•ˆï¼Œå¤šå±‚ç½‘ç»œçš„å±‚æ¬¡ç»“æ„ï¼Œå¯¹å®ƒè¿›è¡Œäº†å¾ˆå¤šçº¦æŸï¼Œä»è€Œä½¿å¾—èƒ½å¤Ÿæ”¶æ•›åˆ°æœ€ä½³çš„å‚æ•°ã€‚</p>
<p>è§£å†³æ–¹æ¡ˆï¼š<br>åœ¨BERTä¹‹å‰ï¼ŒLM é€šå¸¸æ˜¯å•å‘çš„ï¼Œå¸¸è§çš„åšæ³•æ˜¯åˆ†åˆ«è®­ç»ƒæ­£å‘å’Œåå‘çš„LMï¼Œç„¶åå†åšä¸€ä¸ªensembleå¾—åˆ°çš„ä¸Šä¸‹æ–‡ç›¸å…³è¡¨ç¤ºã€‚è¿™æ ·çš„åšæ³•æ˜¯ä¼šæœ‰ä¿¡æ¯ç¼ºå¤±çš„é—®é¢˜çš„ã€‚</p>
<p>BERT  æ˜¯ â€œBidirectional Encoder Representations from Transformersâ€ çš„ç¼©å†™ï¼ŒBè¡¨ç¤ºæ¨¡å‹èƒ½å¤ŸåŒæ—¶åˆ©ç”¨å‰åä¸¤ä¸ªæ–¹å‘çš„ä¿¡æ¯ï¼Œè€ŒELMoå’ŒGPT åªèƒ½æ˜¯å•ä¸ªæ–¹å‘çš„ã€‚</p>
<p>è€Œbert ä»ç„¶ä½¿ç”¨çš„æ˜¯ transformeræ¨¡å‹ï¼Œé‚£ä¹ˆæ˜¯å¦‚ä½•è§£å†³è¯­è¨€æ¨¡å‹ä¸­çš„åªåˆ©ç”¨ä¸€ä¸ªæ–¹å‘çš„é—®é¢˜å‘¢ï¼Ÿå› ä¸ºbert ä¸æ˜¯æ™®é€šçš„è¯­è¨€æ¨¡å‹ï¼Œè€Œæ˜¯ä¸€ç§mask è¯­è¨€æ¨¡å‹ã€‚</p>
<p><strong> bert çš„è¾“å…¥è¡¨ç¤ºï¼š</strong><br>è¾“å…¥æ˜¯ä¸¤ä¸ªå¥å­ï¼Œç„¶åæ˜¯å¯¹äºæ¯ä¸ªtoken è¿›è¡Œ3 ä¸ªembeddingï¼šè¯çš„embeddingï¼Œ ä½ç½®çš„embeddingå’Œsegment çš„embeddingã€‚è¯è¯­çš„embedding æ˜¯éå¸¸å¸¸è§çš„ï¼Œä½ç½®embeddingå¼•å…¥äº†è¯è¯­çš„é¡ºåºä¿¡æ¯ï¼Œsegment çš„embeddingå¯ä»¥å­¦ä¹ åˆ°ä¸åŒçš„segmentçš„ä¿¡æ¯ã€‚<br><img src="https://i.bmp.ovh/imgs/2019/07/6c304cd1ba04192c.png" alt><br>ä½ç½®å‘é‡æ˜¯å› ä¸ºtransformer ä¸åƒä¼ ç»Ÿçš„RNN é‚£æ ·èƒ½å¤Ÿå¾ˆå¥½çš„å¤„ç†æ—¶åºï¼Œæ‰€ä»¥äººä¸ºåŠ å…¥äº†è¡¨ç¤ºä½ç½®çš„å‘é‡ã€‚</p>
<p>è¿™ç§æµ·é‡æ•°æ®è¿˜æ˜¯å¾ˆé‡è¦çš„ã€‚</p>
<p>bert æ¨¡å‹æ˜¯éœ€è¦æœ‰ä¸€ä¸ªå›ºå®šçš„sequenceçš„é•¿åº¦ï¼Œæ¯”å¦‚è¯´æ˜¯128ï¼Œå¦‚æœä¸å¤Ÿäº†ä¼špaddingï¼Œå¦‚æœå¤šäº†ä¼šè¿›è¡Œè£å‰ªã€‚</p>
<p>Mask LM å’ŒNSP åˆ†åˆ«å¯¹åº”çš„æ˜¯è¯çº§åˆ«å’Œå¥å­çº§åˆ«çš„ä»»åŠ¡ï¼Œæ•ˆæœå¾ˆå¥½ã€‚bertä¹Ÿæ˜¯ä¸€ç§è¯­è¨€æ¨¡å‹ï¼Œåœ¨è¯­æ–™è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ˜¯æŠŠè¿™ä¸¤ä¸ªä»»åŠ¡çš„æŸå¤±å‡½æ•°ç›¸åŠ ï¼ŒåŒæ—¶å­¦ä¹ è¿™ä¸¤ä¸ªä»»åŠ¡ã€‚æ‰€ä»¥è¿™ä¸ªå°±æ˜¯ä¸€ç§å¤šä»»åŠ¡å­¦ä¹ æ–¹å¼ã€‚BERTæ˜¯é€šè¿‡ä¸¤ä¸ªè¾…åŠ©ä»»åŠ¡è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚</p>
<p><strong>Mask LMï¼ˆbert çš„ç¬¬ä¸€ä¸ªé‡ç‚¹ç»ˆäºæ¥äº†ï¼‰</strong></p>
<p>maskè¯­è¨€æ¨¡å‹ç±»ä¼¼å®Œå½¢å¡«ç©ºï¼Œç»™å®šä¸€ä¸ªå¥å­ï¼Œç„¶åæŠŠå…¶ä¸­çš„æŸä¸ªè¯é®æŒ¡èµ·æ¥ï¼Œè®©äººçŒœæµ‹å¯èƒ½çš„è¯è¯­ã€‚è¿™ä¸ªä¼šéšæœºmask 15%çš„è¯ï¼Œ ç„¶åè®©bert æ¥é¢„æµ‹è¿™äº›mask çš„è¯ï¼ŒåŒå½’è°ƒæ•´æ¨¡å‹çš„å‚æ•°ä½¿å¾—æ¨¡å‹é¢„æµ‹æ­£ç¡®çš„æ¦‚ç‡å°½å¯èƒ½çš„å¤§ï¼Œè¿™ä¸ªç­‰ä»·äºäº¤å‰ç†µçš„æŸå¤±å‡½æ•°ã€‚è¿™æ ·çš„transformeråœ¨ç¼–ç ä¸€ä¸ªè¯çš„æ—¶å€™ï¼ˆå¿…é¡»ï¼‰å‚è€ƒä¸Šä¸‹æ–‡çš„ä¿¡æ¯ã€‚</p>
<p>ä½†æ˜¯è¿˜æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯åœ¨pretraineing mask LM æ—¶å€™ä¼šå‡ºç°ä¸€äº›ç‰¹æ®Šçš„tokenï¼Œä½†æ˜¯åœ¨fine-tuning æ—¶å€™å¹¶ä¸ä¼šå‡ºç°ï¼Œè¿™ä¸ªæ—¶å€™å°±å‡ºç°äº†mismatch çš„é—®é¢˜ã€‚å› æ­¤åœ¨bertä¸­ï¼Œå¦‚æœæŸä¸ªtoken è¢«é€‰ä¸­ä¹‹åï¼Œ ä¼šéšæœºæŒ‰ç…§ä»¥ä¸‹çš„æ–¹å¼éšæœºçš„æ‰§è¡Œï¼š</p>
<ul>
<li>80%éšæœºæ›¿æ¢æˆmask</li>
<li>10%æ›¿æ¢æˆéšæœºçš„ä¸€ä¸ªè¯</li>
<li>10%æ¦‚ç‡æ›¿æ¢æˆå•è¯æœ¬èº«</li>
</ul>
<p>å› æ­¤ï¼Œå½“ä»–çœ‹åˆ°äº† [maskæˆ–è€…apple çš„æ—¶å€™ï¼Œå¼ºè¿«æ¨¡å‹åœ¨ç¼–ç çš„æ—¶å€™ä¸èƒ½å¤ªä¾èµ–å½“æœŸçš„è¯ï¼Œè€Œæ˜¯è¦è€ƒè™‘ä¸Šä¸‹æ–‡ï¼Œç”šè‡³è¿›è¡Œä¸Šä¸‹æ–‡çš„â€œçº é”™â€ã€‚</p>
<p><strong>é¢„æµ‹å¥å­å…³ç³»ï¼ˆbertæ¨¡å‹ä¸­ç¬¬äºŒä¸ªè®­ç»ƒä»»åŠ¡ï¼‰</strong></p>
<p>åœ¨é—®ç­”ä¸­ï¼Œå‰åä¸¤ä¸ªå¥å­æœ‰ä¸€å®šçš„å…³è”å…³ç³»ï¼Œæˆ‘ä»¬å¸Œæœ›bert pretraining çš„æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°è¿™ç§å…³ç³»ã€‚å› æ­¤bert å¢åŠ äº†ä¸€ç§æ–°çš„é¢å­¦ä¹ ä»»åŠ¡â€“é¢„æµ‹ä¸¤ä¸ªå¥å­æ˜¯å¦æœ‰å…³è”å…³ç³»ã€‚è¿™ä¸ªè®­ç»ƒé›†è¦æ±‚æ˜¯æ–‡ç« ï¼ˆæœ‰ä¸Šä¸‹æ–‡å…³ç³»çš„å¥å­ï¼‰ã€‚å¯¹äºè¿™ä¸ªä»»åŠ¡ï¼Œbert ä»¥50%çš„æ¦‚ç‡éšæœºæŠ½å–ä¸¤ä¸ªæ— å…³çš„å¥å­ï¼Œ50%çš„æ¦‚ç‡æŠ½å–æœ‰å…³è”çš„å¥å­ã€‚ï¼ˆè¿™ä¸ªå¥å­æ˜¯ç»è¿‡tokenå¤„ç†çš„å¥å­ï¼‰</p>
<p>å®éªŒè¯æ˜è¯¥é¡¹ä»»åŠ¡æ˜¯å¯ä»¥æ˜æ˜¾ç»™QAå’ŒNLI ç±»ä»»åŠ¡å¸¦æ¥æå‡çš„ã€‚</p>
<p>fine-tuning </p>
<p>å…±æœ‰å››ç§ä»»åŠ¡ï¼Œ</p>
<p><img src="https://i.loli.net/2019/08/31/iKZ1mdzIfgEtraS.png" alt="2.png"></p>
<p>ï¼ˆä½¿ç”¨è¿‡çš„æ˜¯ä¸¤ç§ä»»åŠ¡ï¼Œaå’Œbï¼Œåˆ†åˆ«è¿›è¡Œ sentence pair classification å’Œsingle sentence classificationï¼‰<br>å¯¹äºæ™®é€šçš„åˆ†ç±»ä»»åŠ¡ï¼Œè¾“å…¥æ˜¯ä¸€ä¸ªåºåˆ—ï¼Œå¦‚å›¾å³ä¸Šæ‰€ç¤ºï¼Œæ‰€æœ‰çš„token éƒ½æ˜¯å±äºåŒä¸€ä¸ªsegmentï¼Œç„¶åå†æ¨¡å‹çš„æœ€åä¸€å±‚æ¥ä¸Šä¸€ä¸ªsoftmaxè¿›è¡Œåˆ†ç±»ï¼Œ ç”¨åˆ†ç±»æ•°æ®è¿›è¡Œfine tuning</p>
<p>å¯¹äºç›¸ä¼¼åº¦è®¡ç®—ç­‰è¾“å…¥ä¸ºä¸¤ä¸ªåºåˆ—çš„ä»»åŠ¡ï¼Œè¿‡ç¨‹å¦‚å·¦ä¸Šæ‰€ç¤ºï¼›ä¸¤ä¸ªåºåˆ—çš„token æ˜¯å¯¹åº”ç€ä¸åŒçš„segment(id =0/1)ã€‚åœ¨æœ€åä¸€å±‚åŠ ä¸Šsoftmax è¿›è¡Œåˆ†ç±»ï¼Œç„¶åä½¿ç”¨åˆ†ç±»æ•°æ®è¿›è¡Œfine-tuning </p>
<p>ç¬¬ä¸‰ç±»ä»»åŠ¡æ˜¯åºåˆ—æ ‡æ³¨ï¼Œæ¯”å¦‚å‘½åå®ä½“è¯†åˆ«ï¼Œä½¿ç”¨å³ä¸‹çš„æ–¹å¼è¿›è¡Œè®­ç»ƒã€‚</p>
<p>ç¬¬å››ç±»æ˜¯é—®ç­”ç±»é—®é¢˜ï¼Œè¾“å…¥æ˜¯ä¸€ä¸ªé—®é¢˜å’Œä¸€æ®µå¾ˆé•¿åŒ…å«ç­”æ¡ˆæ–‡å­—ï¼ˆparagraphï¼‰ï¼Œè¾“å‡ºåœ¨è¿™æ®µæ–‡å­—é‡Œæ‰¾åˆ°çš„é—®é¢˜çš„ç­”æ¡ˆã€‚</p>
<p>åœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œä½œè€…å»ºè®®å¤§éƒ¨åˆ†çš„å‚æ•°ä¸ç”¨å˜ï¼Œåªæ˜¯ä¿®æ”¹batch sizeï¼Œ learning rate å’Œ number of epochs å°±å¯ä»¥äº†ï¼š<br>batch size: 16,32<br>learning rate(adam): 5e-5, 3e-5, 2e-5<br>number of epochs: 3, 4<br>å¹¶ä¸”è®­ç»ƒæ•°æ®é›†è¶Šå¤§ï¼Œå¯¹è¶…å‚æ•°å°±è¶Šä¸æ•æ„Ÿï¼Œè€Œä¸”fine tune ä¸€èˆ¬æ¥è¯´æ”¶æ•›çš„æ˜¯æ¯”è¾ƒå¿«çš„ã€‚</p>
<p>å¯¹äºä¸­æ–‡æ¥è¯´ï¼Œbertå¯¹ä¸­æ–‡æä¾›çš„æ¨¡å‹æ˜¯åŸºäºå­—çš„ï¼Œè€Œword2vec æ˜¯åŸºäºè¯çš„ï¼Œæ‰€ä»¥å½“word2vecçš„è¯å‘é‡æ•ˆæœè¶Šå¥½ï¼Œé‚£ä¹ˆè¿™ä¸ªå·®è·æ˜¯è¶Šå¤§çš„ã€‚</p>
<p>æœ‰ç›‘ç£çš„æ¨¡å‹æ•ˆæœå¥½ï¼Œä½†æ˜¯æœ‰æ ‡ç­¾çš„æ•°æ®è·å–éå¸¸éš¾ã€‚ä¸€ç§æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆæ˜¯é‡‡ç”¨å¤šä»»åŠ¡å­¦ä¹ (multi task learning MLT), ä¸€æ–¹é¢å¯ä»¥åœ¨æ•°æ®é›†æ ‡æ³¨è¾ƒå°‘çš„æƒ…å†µä¸‹åˆ©ç”¨å…¶å®ƒç›¸ä¼¼ä»»åŠ¡çš„æ ‡æ³¨æ•°æ®ï¼Œå¦ä¸€æ–¹é¢å¯ä»¥é™ä½é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„è¿‡æ‹Ÿåˆï¼Œèµ·åˆ°æ­£åˆ™åŒ–çš„ä½œç”¨ã€‚</p>
<p>Resnet, BERTéƒ½å‘Šè¯‰æˆ‘ä»¬ï¼š æ›´å¤§çš„æ•°æ®è§„æ¨¡ï¼Œæ›´å¤šæ ·æ€§çš„æ•°æ®å’Œæ›´é«˜çš„æ•°æ®è´¨é‡ã€‚æ•°æ®è¿˜æ˜¯æ¯”è¾ƒå…³é”®çš„ã€‚</p>
<p>bert æ¨¡å‹çš„ç¼ºç‚¹ï¼š</p>
<ol>
<li>å¯¹äºç¯‡ç« çº§åˆ«çš„ä»»åŠ¡ï¼Œtransformerçš„è®¡ç®—é‡å¤æ‚ï¼Œé€Ÿåº¦æ˜¯å˜å¾—å¾ˆæ…¢ã€‚è§£å†³æ–¹æ¡ˆæ˜¯è¿›è¡Œé•¿è¾“å…¥çš„åˆ‡åˆ†</li>
<li>ç½‘ç»œç»“æ„çš„è¿‡äºå¤æ‚</li>
<li>å¯¹äºä¸­æ–‡çš„æ”¹è¿›ï¼ˆä»å­—åˆ°è¯è¯­ çš„maskï¼‰</li>
</ol>
<p>è¿™å‡ ç¯‡æ–‡ç« éƒ½æ˜¯å¯¹BERTæ¨¡å‹çš„Pretrainingé˜¶æ®µçš„Maskè¿›è¡Œäº†ä¸åŒæ–¹å¼çš„æ”¹è¿›ã€‚ä¸ºäº†è§£å†³OOVçš„é—®é¢˜ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šæŠŠä¸€ä¸ªè¯åˆ‡åˆ†æˆæ›´ç»†ç²’åº¦çš„WordPiece(ä¸ç†Ÿæ‚‰çš„è¯»è€…å¯ä»¥å‚è€ƒæœºå™¨ç¿»è¯‘Â·åˆ†è¯å’ŒWordpieceTokenizer)ã€‚BERTåœ¨Pretrainingçš„æ—¶å€™æ˜¯éšæœºMaskè¿™äº›WordPieceçš„ï¼Œè¿™å°±å¯èƒ½å‡ºç°åªMaskä¸€ä¸ªè¯çš„ä¸€éƒ¨åˆ†çš„æƒ…å†µã€‚</p>
<p>ç®€å•è¯´åŸæ¥çš„bert æ¨¡å‹å¯¹äºä¸­æ–‡æ˜¯åŸºäºå­—çš„ï¼Œ æ¯”å¦‚å¦‚ä½•mask æ‰çµç¶ä¸­çš„ä¸€ä¸ªå­—ï¼Œé‚£ä¹ˆæ¨¡å‹æ˜¯å¾ˆå®¹æ˜“é¢„æµ‹ä¸‹ä¸€ä¸ªå­—çš„ã€‚æ‰€ä»¥ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¾ˆè‡ªç„¶çš„æƒ³æ³•å°±æ˜¯æŠŠè¯ä½œä¸ºä¸€ä¸ªæ•´ä½“ï¼Œè¦ä¹ˆéƒ½mask æ‰ï¼Œè¦ä¹ˆä¸maskã€‚å½“ç„¶å‰ä¸ä¹…å“ˆå·¥å¤§å’Œç§‘å¤§è®¯é£æ˜¯åšäº†è¿™æ–¹é¢çš„å·¥ä½œçš„ã€‚</p>
<p>ä½†æ˜¯å¯¹äºBERTæ¨¡å‹æœ¬èº«(åŸºäºMask LMçš„Pretrainingã€Transformeræ¨¡å‹å’ŒFine-tuning)æ²¡æœ‰åšä»»ä½•ä¿®æ”¹ã€‚</p>
<p><a href="https://fancyerii.github.io/2019/08/02/bert-pretrain-imp/" target="_blank" rel="noopener">åŸæ–‡é“¾æ¥</a></p>
<h2 id="transformer-çš„ç†è§£"><a href="#transformer-çš„ç†è§£" class="headerlink" title="transformer çš„ç†è§£"></a>transformer çš„ç†è§£</h2><p><em>Transformer</em> å…¶é‡‡ç”¨ <em>Self Attention</em> æ¥å­¦ä¹ åºåˆ—çš„è¡¨ç¤º, å…·ä½“çš„æ˜¯: <em>Scaled Dot-Product Attention</em>. ä¸ºè§£å†³ä½ç½®ä¿¡æ¯ (Position Information) ä¸¢å¤±é—®é¢˜, æ¨¡å‹å°† <em>Positional Encpding</em> ä¸ Input Embedding ç»“åˆï¼›ä¸ºé˜²æ­¢ decoder ä¸­åç»­ä½ç½® (æ¨¡å‹å¯å¹¶è¡Œè®¡ç®—) å¯¹å‰é¢ä½ç½®çš„å½±å“, æ¨¡å‹åœ¨ decoder ä¸­ä½¿ç”¨äº† Mask ä»¥ä½¿ä½ç½® ii å¤„çš„é¢„æµ‹åªä¾èµ–äºå‰é¢çš„è¾“å‡º.</p>
<p>Transformerç”±ä¸”ä»…ç”±self-Attenionå’ŒFeed Forward Neural Networkç»„æˆã€‚ä¸€ä¸ªåŸºäºTransformerçš„å¯è®­ç»ƒçš„ç¥ç»ç½‘ç»œå¯ä»¥é€šè¿‡å †å Transformerçš„å½¢å¼è¿›è¡Œæ­å»º.ä½œè€…çš„å®éªŒæ˜¯é€šè¿‡æ­å»ºç¼–ç å™¨å’Œè§£ç å™¨å„6å±‚ï¼Œæ€»å…±12å±‚çš„Encoder-Decoder(è¿™ä¸ªåªæ˜¯ä¸€ä¸ªé€šç”¨çš„æ¡†æ¶ï¼Œå®é™…ä¸Šæ˜¯å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚è¿›è¡Œä¸åŒçš„å±‚çš„å¢å‡)</p>
<p>Multi-Head Attentionç›¸å½“äº å¤šä¸ªä¸åŒçš„self-attentionçš„é›†æˆï¼ˆensembleï¼‰ã€‚</p>
<p>å¦‚ä½•è¡¨ç¤ºä½ç½®ä¿¡æ¯ï¼Ÿ</p>
<p>å¸¸è§çš„æ¨¡å¼æœ‰ï¼ša. æ ¹æ®æ•°æ®å­¦ä¹ ï¼›b. è‡ªå·±è®¾è®¡ç¼–ç è§„åˆ™ã€‚åœ¨è¿™é‡Œä½œè€…é‡‡ç”¨äº†ç¬¬äºŒç§æ–¹å¼ã€‚ç¼–ç å…¬å¼å¦‚ä¸‹ï¼š</p>
<p>$$<br>P E(\text { pos, } 2 i)=\sin \left(\frac{\text { pos }}{10000^{\frac{2 i}{\text { model }}}}\right)<br>$$</p>
<p>$$<br>P E(p o s, 2 i+1)=\cos \left(\frac{p o s}{10000^{\frac{2 i}{d_{m o d e l}}}}\right)<br>$$</p>
<p>å…¬å¼ä¸­ï¼š</p>
<ul>
<li>pos è¡¨ç¤ºè¿™ä¸ªword åœ¨å¥å­ä¸­çš„ä½ç½®</li>
<li>$i $è¡¨ç¤º embeddingç»´åº¦ï¼Œæ¯”å¦‚ $d_{model}$ æ˜¯512ï¼Œé‚£ä¹ˆ $i$ å°±ä» 1 åˆ°512.</li>
</ul>
<p>ä¸Šå¼ä¸­ï¼Œ$pos$ è¡¨ç¤ºå½“å‰å•è¯åœ¨å¥å­ä¸­çš„ä½ç½®ï¼Œå¯ä»¥çœ‹å‡ºå¯¹äºå¶æ•°ä½ï¼Œä½¿ç”¨æ­£å¼¦ç¼–ç ï¼Œå¯¹äºå¥‡æ•°ä½ä½¿ç”¨ä½™å¼¦ç¼–ç .ã€‚$d$ è¡¨ç¤ºæ¨¡å‹çš„ç»´åº¦ã€‚é™¤äº†å•è¯çš„ç»å¯¹ä½ç½®ï¼Œå•è¯çš„ç›¸å¯¹ä½ç½®ä¹Ÿéå¸¸é‡è¦ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä½¿ç”¨æ­£å¼¦å’Œä½™å¼¦å‡½æ•°ã€‚æ ¹æ®å…¬å¼$\sin (\alpha+\beta)=\sin \alpha \cos \beta+\cos \alpha \sin \beta$ å’Œ$\cos (\alpha+\beta)=\cos \alpha \cos \beta-\sin \alpha \sin \beta$ï¼Œè¿™è¡¨æ˜ä½ç½®$k+p$  çš„ä½ç½®å‘é‡å¯ä»¥è¡¨ç¤ºä¸ºä½ç½®  $k$çš„ç‰¹å¾å‘é‡çš„çº¿æ€§å˜åŒ–ï¼Œè¿™ä¸ºæ¨¡å‹æ•æ‰å•è¯ä¹‹é—´çš„ç›¸å¯¹ä½ç½®å…³ç³»æä¾›äº†éå¸¸å¤§çš„ä¾¿åˆ©ã€‚</p>
<p>è°·æ­Œè¿˜ç‰¹æ„å°†è¿™ç§æ–¹å¼æ„é€ çš„å‘é‡å’Œå­¦ä¹ å¾—åˆ°çš„å‘é‡ä½œå¯¹æ¯”ï¼Œå‘ç°æ•ˆæœæ¥è¿‘ï¼Œç„¶åè°·æ­Œå°±ç”¨è¿™ä¸ªæ„é€ å¼çš„ï¼Œå› ä¸ºè™½ç„¶æ•ˆæœæ¥è¿‘ï¼Œä½†è¿™ç§æ„é€ å¼çš„æ›´èƒ½åœ¨ä½¿ç”¨ä¸­é€‚åº”ä¸åŒé•¿åº¦åºåˆ—ã€‚</p>
<p>å°†ä½ç½®å‘é‡å’Œè¯å‘é‡è¿›è¡ŒåŠ å’Œå¾—åˆ°æœ€ç»ˆè¾“å…¥å‘é‡ï¼Œæ‰€ä»¥å‰é¢æˆ‘ä»¬çœ‹åˆ°è¯å‘é‡å’Œä½ç½®å‘é‡ç»´åº¦æ˜¯ç›¸åŒçš„ã€‚</p>
<p><strong>ä¸¤ç§mask æŠ€æœ¯</strong></p>
<p>padding maskï¼šmaskå¯¹æŸäº›å€¼è¿›è¡Œæ©ç›–ï¼Œä½¿å…¶ä¸äº§ç”Ÿæ•ˆæœã€‚æˆ‘ä»¬æ¯æ¬¡æ‰¹å¤„ç†åºåˆ—çš„é•¿åº¦æ˜¯ä¸ä¸€æ ·çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦å¯¹é½ï¼Œå…·ä½“æ¥è¯´æ˜¯åœ¨è¾ƒçŸ­åºåˆ—ä¸­å¡«å……0. è€Œattentionæœºåˆ¶ä¸åº”è¯¥æŠŠæ³¨æ„åŠ›æ”¾åœ¨è¿™äº›ä½ç½®ä¸Šã€‚å…·ä½“åšæ³•æ˜¯è¿™äº›ä½ç½®ä¸ŠåŠ ä¸Šä¸€ä¸ªéå¸¸å¤§çš„è´Ÿæ•°ï¼Œè¿™æ ·ç»è¿‡softmaxï¼Œè¿™äº›ä½ç½®çš„æ¦‚ç‡å°±ä¼šæ¥è¿‘0.</p>
<p>åœ¨ encoder å’Œdecoder ä¸­éƒ½ä½¿ç”¨ã€‚</p>
<p>sequence maskï¼šæ˜¯ä¸ºäº†decoder ä¸èƒ½çœ‹è§æœªæ¥çš„ä¿¡æ¯ï¼Œè¿›è¡Œé¢„æµ‹çš„æ—¶å€™åªæ˜¯ä¾èµ–å‰$i$ ä¸ªå•è¯çš„ä¿¡æ¯ã€‚å…·ä½“åšæ³•ï¼Œäº§ç”Ÿä¸€ä¸ªä¸Šä¸‰è§’å½¢ï¼Œä¸Šä¸‰è§’å½¢å€¼å…¨éƒ¨ä¸º1ï¼Œä¸‹ä¸‰è§’å½¢å’Œå¯¹è§’çº¿éƒ½æ˜¯0ï¼Œä½œç”¨åœ¨åºåˆ—ä¸Šå°±å¯ä»¥è¾¾åˆ°ç›®çš„ã€‚åªæ˜¯åœ¨decoder ä¸­ä½¿ç”¨ã€‚</p>
<p>å¯¹äº attention æœºåˆ¶çš„åˆ†ç±»</p>
<p>å¯ä»¥ä»å¤šè§’åº¦å¯¹ Attention è¿›è¡Œåˆ†ç±»ï¼Œå¦‚ä»ä¿¡æ¯é€‰æ‹©çš„æ–¹å¼ä¸Šï¼Œå¯ä»¥åˆ†ä¸º Soft attention å’Œ Hard attentionã€‚ä»ä¿¡æ¯æ¥æ”¶çš„èŒƒå›´ä¸Šå¯åˆ†ä¸º Global attention å’Œ Local attentionã€‚</p>
<p>global attention ä¸­æ‰€æœ‰çš„ä¿¡æ¯éƒ½è¦å‚ä¸è®¡ç®—ï¼Œè¿™æ ·è®¡ç®—çš„å¼€é”€å°±æ¯”è¾ƒå¤§ï¼Œè€Œåˆ«å½“encoder çš„å¥å­æ¯”è¾ƒé•¿æ—¶ï¼Œå¦‚ä¸€æ®µè¯æˆ–ä¸€ç¯‡æ–‡ç« ã€‚æ‰€ä»¥æå‡ºäº† local attentionçš„æ¦‚å¿µ</p>
<p><strong>transformerä¸­æ˜¯æœ‰ä¸‰ç§attention æœºåˆ¶</strong></p>
<p> Encoder ç”± 6 ä¸ªç›¸ä¹˜çš„ Layer å †å è€Œæˆï¼ˆ6å¹¶ä¸æ˜¯å›ºå®šçš„ï¼Œå¯ä»¥åŸºäºå®é™…æƒ…å†µä¿®æ”¹ï¼‰ã€‚</p>
<p><img src="https://upload.cc/i1/2019/10/04/cVA3uE.jpg" alt="img"><br>ä»å›¾ä¸­å¯ä»¥çŸ¥é“ decoder æ˜¯æœ‰ä¸‰ç§ç½‘ç»œç»“æ„çš„ï¼Œ</p>
<p>Diff_1ï¼šDecoder SubLayer-1 ä½¿ç”¨çš„æ˜¯ â€œmaskedâ€ Multi-Headed Attention æœºåˆ¶ï¼Œé˜²æ­¢ä¸ºäº†æ¨¡å‹çœ‹åˆ°è¦é¢„æµ‹çš„æ•°æ®ï¼Œé˜²æ­¢æ³„éœ²ã€‚<br>Diff_2ï¼šSubLayer-2 æ˜¯ä¸€ä¸ª encoder-decoder multi-head attentionã€‚<br>Diff_3ï¼šLinearLayer å’Œ SoftmaxLayer ä½œç”¨äº SubLayer-3 çš„è¾“å‡ºåé¢ï¼Œæ¥é¢„æµ‹å¯¹åº”çš„ word çš„ probabilities ã€‚</p>
<p>encoder-decoder multi-head attention ä¸­</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecoderLayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Decoder is made of self-attn, src-attn, and feed forward (defined below)"</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, self_attn, src_attn, feed_forward, dropout)</span>:</span></span><br><span class="line">        super(DecoderLayer, self).__init__()</span><br><span class="line">        self.size = size</span><br><span class="line">        self.self_attn = self_attn</span><br><span class="line">        self.src_attn = src_attn</span><br><span class="line">        self.feed_forward = feed_forward</span><br><span class="line">        self.sublayer = clones(SublayerConnection(size, dropout), <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, memory, src_mask, tgt_mask)</span>:</span></span><br><span class="line">        m = memory</span><br><span class="line">        x = self.sublayer[<span class="number">0</span>](x, <span class="keyword">lambda</span> x: self.self_attn(x, x, x, tgt_mask))</span><br><span class="line">        x = self.sublayer[<span class="number">1</span>](x, <span class="keyword">lambda</span> x: self.src_attn(x, m, m, src_mask))</span><br><span class="line">        <span class="keyword">return</span> self.sublayer[<span class="number">2</span>](x, self.feed_forward)</span><br></pre></td></tr></table></figure>
<p>é‡ç‚¹åœ¨äº x = self.sublayer1 self.src_attn æ˜¯ MultiHeadedAttention çš„ä¸€ä¸ªå®ä¾‹ã€‚query = xï¼Œkey = m, value = m, mask = src_maskï¼Œè¿™é‡Œxæ¥è‡ªä¸Šä¸€ä¸ª DecoderLayerï¼Œmæ¥è‡ª Encoderçš„è¾“å‡ºã€‚<br>ï¼ˆm æ˜¯encoderçš„è¾“å‡ºï¼Œ x æ ‘decoder ä¸­çš„è¾“å‡ºï¼Œä¸»çº¿è¿˜æ˜¯è·Ÿç€m èµ°ï¼Œattentionæ˜¯æ±‚è§£çš„ m å’Œx çš„ç›¸å…³æ€§ï¼‰</p>
<p>åˆ°ç›®å‰ä½ç½® transformer ä¸­ä¸‰ç§ä¸åŒçš„attention éƒ½å·²ç»ä»‹ç»å®Œæ¯•ã€‚</p>
<p>æœ€åè¿˜æœ‰ä¸€ä¸ªå…¨è¿æ¥åŠ ä¸Šä¸€ä¸ªsoftmax æ±‚probablyï¼Œç”¨æ¥çœ‹å“ªäº›è¯å‡ºç°çš„æ¦‚ç‡æ˜¯æœ€å¤§çš„ã€‚</p>
<p>beam search or  greedy searchï¼š å‰è€…æ˜¯ä¿ç•™k ä¸ªå€™é€‰é›†ï¼Œåè€…åªä¿ç•™ä¸€ä¸ªã€‚</p>
<p>teacher forcing or scheduled samplingï¼š å‰è€…åœ¨ä¸‹ä¸€ä¸ªçš„è¾“å…¥ä½¿ç”¨çœŸå®çš„æ ·æœ¬ï¼›åè€…æ˜¯å¼€å§‹çš„æ—¶å€™ä½¿ç”¨çœŸå®çš„æ ·æœ¬ï¼Œåˆ°åæ¥åŠ ä¸Šäº†ç”Ÿæˆçš„æ ·æœ¬ã€‚</p>
<h2 id="RNNï¼ŒCNN-å’ŒSelf-attention-æ—¶é—´æ•ˆç‡çš„æ¯”è¾ƒ"><a href="#RNNï¼ŒCNN-å’ŒSelf-attention-æ—¶é—´æ•ˆç‡çš„æ¯”è¾ƒ" class="headerlink" title="RNNï¼ŒCNN å’ŒSelf-attention æ—¶é—´æ•ˆç‡çš„æ¯”è¾ƒ"></a>RNNï¼ŒCNN å’ŒSelf-attention æ—¶é—´æ•ˆç‡çš„æ¯”è¾ƒ</h2><table>
<thead>
<tr>
<th>ç½‘ç»œç»“æ„</th>
<th style="text-align:center">æ—¶é—´å¤æ‚åº¦</th>
</tr>
</thead>
<tbody>
<tr>
<td>Self-Attention</td>
<td style="text-align:center">$O(length^2 \cdot dim^2) $</td>
</tr>
<tr>
<td>RNN(LSTM)</td>
<td style="text-align:center">$O(length \cdot dim^2)$</td>
</tr>
<tr>
<td>Convolution</td>
<td style="text-align:center">$O(length \cdot dim^2 \cdot kernel_width)$</td>
</tr>
</tbody>
</table>
<p>å…¶ä¸­ $length$ æ˜¯å¤„ç†çš„å¥å­çš„é•¿åº¦ï¼Œ $dim$ æ˜¯éšè—å±‚çš„é•¿åº¦ï¼Œ$kernel_width$ è¡¨ç¤ºCNN ä¸­kernel çš„å®½åº¦ã€‚å¯ä»¥å‘ç°å½“éšè—å±‚çš„é•¿åº¦è¿œè¿œå¤§äºå¤„ç†çš„å¥å­é•¿åº¦çš„æ—¶å€™ï¼ŒRNN çš„è®¡ç®—æ•ˆç‡éå¸¸ä½ï¼›ç›¸åï¼Œå½“å¤„ç†çš„å¥å­é•¿åº¦ï¼ˆæ–‡ç« ï¼‰è¿œè¿œå¤§äºéšè—å±‚çš„é•¿åº¦æ—¶å€™ï¼Œé€‰æ‹©RNN å¯èƒ½æ˜¯æ›´å¥½çš„é€‰æ‹©ã€‚</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/04/24/pygen/" rel="next" title="pygen">
                <i class="fa fa-chevron-left"></i> pygen
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/05/04/word2vec/" rel="prev" title="Word2vec ä»‹ç»">
                Word2vec ä»‹ç» <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpeg" alt="Jijeng Jia">
            
              <p class="site-author-name" itemprop="name">Jijeng Jia</p>
              <p class="site-description motion-element" itemprop="description">Solving Problems by Coding</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">120</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">85</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/jijeng" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:jia1509309698@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          <script type="text/javascript" src="//rf.revolvermaps.com/0/0/5.js?i=5kk0u0mm50w&amp;m=0&amp;c=54ff00&amp;cr1=ff0000" async="async"></script>


        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#attention-is-all-you-need"><span class="nav-number">1.</span> <span class="nav-text">attention is all you need</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#transformer-çš„ç»“æ„"><span class="nav-number">1.1.</span> <span class="nav-text">transformer çš„ç»“æ„</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deep-Contextualized-Word-Representations"><span class="nav-number">2.</span> <span class="nav-text">Deep Contextualized Word Representations</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OpenAI-GPT"><span class="nav-number">3.</span> <span class="nav-text">OpenAI GPT</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#A-simple-but-tough-to-beat-baseline-for-sentence-embeddings"><span class="nav-number">4.</span> <span class="nav-text">A simple but tough-to-beat baseline for sentence embeddings</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Supervised-Learning-of-Universal-Sentence-Representations-from-Natural-Language-Inference-Data"><span class="nav-number">5.</span> <span class="nav-text">Supervised Learning of Universal Sentence Representations from Natural Language Inference Data</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Universal-Sentence-Encoder"><span class="nav-number">6.</span> <span class="nav-text">Universal Sentence Encoder</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BERTçš„ç†è§£"><span class="nav-number">7.</span> <span class="nav-text">BERTçš„ç†è§£</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#transformer-çš„ç†è§£"><span class="nav-number">8.</span> <span class="nav-text">transformer çš„ç†è§£</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RNNï¼ŒCNN-å’ŒSelf-attention-æ—¶é—´æ•ˆç‡çš„æ¯”è¾ƒ"><span class="nav-number">9.</span> <span class="nav-text">RNNï¼ŒCNN å’ŒSelf-attention æ—¶é—´æ•ˆç‡çš„æ¯”è¾ƒ</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jijeng Jia</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>

<div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
Total  <span id="busuanzi_value_site_pv"></span> views
You got  <span id="busuanzi_value_site_uv"></span> visitors
</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://https-jijeng-github-io.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2019/04/27/paper-reading-bert/';
          this.page.identifier = '2019/04/27/paper-reading-bert/';
          this.page.title = 'NLP Papers Reading- BERT';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://https-jijeng-github-io.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  















  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
