<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="I am trying to write my first english blog based on two reasons: First, the data set used in this blog is english; Second, I’d like to expand my reach and attract more audiences, although I should adm">
<meta property="og:type" content="article">
<meta property="og:title" content="The Evaluation of Sentence Similarity">
<meta property="og:url" content="http://yoursite.com/2019/04/06/The-evaluation-of-sentence-similarity/index.html">
<meta property="og:site_name" content="Jijeng&#39;s blog">
<meta property="og:description" content="I am trying to write my first english blog based on two reasons: First, the data set used in this blog is english; Second, I’d like to expand my reach and attract more audiences, although I should adm">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g1sqxx3vl0j219e07yaam.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g1swpqj9d0j20ps0h5t8z.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g1swpqj9d0j20ps0h5t8z.jpg">
<meta property="og:updated_time" content="2019-08-03T06:28:30.005Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="The Evaluation of Sentence Similarity">
<meta name="twitter:description" content="I am trying to write my first english blog based on two reasons: First, the data set used in this blog is english; Second, I’d like to expand my reach and attract more audiences, although I should adm">
<meta name="twitter:image" content="http://ww1.sinaimg.cn/large/e9a223b5ly1g1sqxx3vl0j219e07yaam.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/04/06/The-evaluation-of-sentence-similarity/"/>







<script>
	(function(){
		if(''){
			if (prompt('请输入文章密码','') !== ''){
				alert('密码错误！');
				history.back();
			}
		}
	})();
</script>

  <title>The Evaluation of Sentence Similarity | Jijeng's blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jijeng's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/06/The-evaluation-of-sentence-similarity/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jijeng Jia">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jijeng's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">The Evaluation of Sentence Similarity</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-06T15:11:01+08:00">
                2019-04-06
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-08-03T14:28:30+08:00">
                2019-08-03
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/04/06/The-evaluation-of-sentence-similarity/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/04/06/The-evaluation-of-sentence-similarity/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>I am trying to write my first english blog based on two reasons: First, the data set used in this blog is english; Second, I’d like to expand my reach and attract more audiences, although I should admit that nobody cares.</p>
<h2 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h2><p>Initially I want to use chinese corpus, but I cannot find a proper one. The data should sound like this one:</p>
<blockquote>
<p>word1    word2    similarity score<br>阿拉伯人    阿拉伯    7.2<br>畜产    农业    5.6<br>垂涎    崇敬    3.4<br>次序    秩序    4.7<br>定心丸    药品    4.3<br>房租    价格    5.2<br>翡翠    宝石    6.7<br>高科技    技术    7.5<br>购入    购买    8.5<br>观音    菩萨    8.2<br>归并    合并    7.7</p>
</blockquote>
<!-- come from https://biendata.com/ccf_tcci2018/datasets/tcci_tag/5 -->
<p>not like this:</p>
<blockquote>
<p>为何我无法申请开通花呗信用卡收款    支付宝开通信用卡花呗收款不符合条件怎么回事    1<br>花呗分期付款会影响使用吗    花呗分期有什么影响吗    0<br>为什么我花呗没有临时额度    花呗没有临时额度怎么可以负    0<br>能不能开花呗老兄    花呗逾期了还能开通    0<br>我的怎么开通花呗收钱    这个花呗是个什么啥？我没开通 我怎么有账单    0<br>蚂蚁借呗可以停掉么    蚂蚁借呗为什么给我关掉了    0<br>我想把花呗功能关了    我去饭店吃饭，能用花呗支付吗    0<br>为什么我借呗开通了又关闭了    为什么借呗存在风险    0<br>支付宝被冻了花呗要怎么还    支付功能冻结了，花呗还不了怎么办    1</p>
</blockquote>
<p>If you can find the dataset where ‘similarity score’ is double, please donot hesitate to <a href="mailto:jiajizhengbuaa@gmail.com" target="_blank" rel="noopener">email me.</a></p>
<p>So, the choice has to be enlgish corpus. The dataset used in this experiment are <a href="http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark" target="_blank" rel="noopener">STSbenchmark</a> and SICK data. The SICK data contains 10,000 sentence paris labeled with semantic relatedness and entailment relation.<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g1sqxx3vl0j219e07yaam.jpg" alt=""></p>
<h2 id="Similarity-Methods"><a href="#Similarity-Methods" class="headerlink" title="Similarity Methods"></a>Similarity Methods</h2><h3 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h3><p>As the baseline, we just take the embedding of the words in sentence, and compute the average, weighted by frequency of each word.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_avg_benchmark</span><span class="params">(sentences1, sentences2, model=None, use_stoplist=False, doc_freqs=None)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> doc_freqs <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">        N = doc_freqs[<span class="string">"NUM_DOCS"</span>]</span><br><span class="line"></span><br><span class="line">    sims = []</span><br><span class="line">    <span class="keyword">for</span> (sent1, sent2) <span class="keyword">in</span> zip(sentences1, sentences2):</span><br><span class="line"></span><br><span class="line">        tokens1 = sent1.tokens_without_stop <span class="keyword">if</span> use_stoplist <span class="keyword">else</span> sent1.tokens</span><br><span class="line">        tokens2 = sent2.tokens_without_stop <span class="keyword">if</span> use_stoplist <span class="keyword">else</span> sent2.tokens</span><br><span class="line"></span><br><span class="line">        tokens1 = [token <span class="keyword">for</span> token <span class="keyword">in</span> tokens1 <span class="keyword">if</span> token <span class="keyword">in</span> model]</span><br><span class="line">        tokens2 = [token <span class="keyword">for</span> token <span class="keyword">in</span> tokens2 <span class="keyword">if</span> token <span class="keyword">in</span> model]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> len(tokens1) == <span class="number">0</span> <span class="keyword">or</span> len(tokens2) == <span class="number">0</span>:</span><br><span class="line">            sims.append(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        tokfreqs1 = Counter(tokens1)</span><br><span class="line">        tokfreqs2 = Counter(tokens2)</span><br><span class="line"></span><br><span class="line">        weights1 = [tokfreqs1[token] * math.log(N / (doc_freqs.get(token, <span class="number">0</span>) + <span class="number">1</span>))</span><br><span class="line">                    <span class="keyword">for</span> token <span class="keyword">in</span> tokfreqs1] <span class="keyword">if</span> doc_freqs <span class="keyword">else</span> <span class="keyword">None</span></span><br><span class="line">        weights2 = [tokfreqs2[token] * math.log(N / (doc_freqs.get(token, <span class="number">0</span>) + <span class="number">1</span>))</span><br><span class="line">                    <span class="keyword">for</span> token <span class="keyword">in</span> tokfreqs2] <span class="keyword">if</span> doc_freqs <span class="keyword">else</span> <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">        embedding1 = np.average([model[token] <span class="keyword">for</span> token <span class="keyword">in</span> tokfreqs1], axis=<span class="number">0</span>, weights=weights1).reshape(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        embedding2 = np.average([model[token] <span class="keyword">for</span> token <span class="keyword">in</span> tokfreqs2], axis=<span class="number">0</span>, weights=weights2).reshape(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">        sim = cosine_similarity(embedding1, embedding2)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        sims.append(sim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sims</span><br></pre></td></tr></table></figure>
<h3 id="Smooth-Inverse-Frequency"><a href="#Smooth-Inverse-Frequency" class="headerlink" title="Smooth Inverse Frequency"></a>Smooth Inverse Frequency</h3><p>The baseline, like we did before, is very simple and crude of computing sentence embedding. Word frequency cannot reliably reflect its importance to sentence, semantically speaking. Smooth Inverse Frequency (SIF) tries to solve this problem.</p>
<ul>
<li>SIF is very similar to the weighted average we used before, with the difference that it’s weighted by this formular.<br>$$<br>\operatorname { SIF } ( w ) = \frac { a } { ( a + p ( w ) )}<br>$$<br>where $a$ is a hyper-parameter (set to 0.001 by default) and $ p(w)$ is the estimated word frequency in the corpus. (这个权重和 TF或者 IDF 都是不相同的)</li>
<li>we need to perform common component removal: subtract from the sentence embedding obtained above the first principal component of the matrix. This corrects for the influence of high-frequency words that have syntactic or dicourse function, such as ‘but’, ‘and’, etc. You can find more information from <a href="https://openreview.net/pdf?id=SyK00v5xx" target="_blank" rel="noopener">this paper</a>. 因为这个的输入直接是句子，没有经过分词的处理，所以不免有 but and 这类的词汇出现。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_first_principal_component</span><span class="params">(X)</span>:</span></span><br><span class="line">    svd = TruncatedSVD(n_components=<span class="number">1</span>, n_iter=<span class="number">7</span>, random_state=<span class="number">0</span>)</span><br><span class="line">    svd.fit(X)</span><br><span class="line">    pc = svd.components_</span><br><span class="line">    XX = X - X.dot(pc.transpose()) * pc</span><br><span class="line">    <span class="keyword">return</span> XX</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_sif_benchmark</span><span class="params">(sentences1, sentences2, model, freqs=&#123;&#125;, use_stoplist=False, a=<span class="number">0.001</span>)</span>:</span></span><br><span class="line">    total_freq = sum(freqs.values())</span><br><span class="line"></span><br><span class="line">    embeddings = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># SIF requires us to first collect all sentence embeddings and then perform</span></span><br><span class="line">    <span class="comment"># common component analysis.</span></span><br><span class="line">    <span class="keyword">for</span> (sent1, sent2) <span class="keyword">in</span> zip(sentences1, sentences2):</span><br><span class="line">        tokens1 = sent1.tokens_without_stop <span class="keyword">if</span> use_stoplist <span class="keyword">else</span> sent1.tokens</span><br><span class="line">        tokens2 = sent2.tokens_without_stop <span class="keyword">if</span> use_stoplist <span class="keyword">else</span> sent2.tokens</span><br><span class="line"></span><br><span class="line">        tokens1 = [token <span class="keyword">for</span> token <span class="keyword">in</span> tokens1 <span class="keyword">if</span> token <span class="keyword">in</span> model]</span><br><span class="line">        tokens2 = [token <span class="keyword">for</span> token <span class="keyword">in</span> tokens2 <span class="keyword">if</span> token <span class="keyword">in</span> model]</span><br><span class="line"></span><br><span class="line">        weights1 = [a / (a + freqs.get(token, <span class="number">0</span>) / total_freq) <span class="keyword">for</span> token <span class="keyword">in</span> tokens1]</span><br><span class="line">        weights2 = [a / (a + freqs.get(token, <span class="number">0</span>) / total_freq) <span class="keyword">for</span> token <span class="keyword">in</span> tokens2]</span><br><span class="line"></span><br><span class="line">        embedding1 = np.average([model[token] <span class="keyword">for</span> token <span class="keyword">in</span> tokens1], axis=<span class="number">0</span>, weights=weights1)</span><br><span class="line">        embedding2 = np.average([model[token] <span class="keyword">for</span> token <span class="keyword">in</span> tokens2], axis=<span class="number">0</span>, weights=weights2)</span><br><span class="line"></span><br><span class="line">        embeddings.append(embedding1)</span><br><span class="line">        embeddings.append(embedding2)</span><br><span class="line"></span><br><span class="line">    embeddings = remove_first_principal_component(np.array(embeddings))</span><br><span class="line">    sims = [cosine_similarity(embeddings[idx * <span class="number">2</span>].reshape(<span class="number">1</span>, <span class="number">-1</span>),</span><br><span class="line">                              embeddings[idx * <span class="number">2</span> + <span class="number">1</span>].reshape(<span class="number">1</span>, <span class="number">-1</span>))[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">for</span> idx <span class="keyword">in</span> range(int(len(embeddings) / <span class="number">2</span>))]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sims</span><br></pre></td></tr></table></figure>
<h3 id="Google-Sentence-Encoder"><a href="#Google-Sentence-Encoder" class="headerlink" title="Google Sentence Encoder"></a>Google Sentence Encoder</h3><p><a href="https://github.com/facebookresearch/InferSent" target="_blank" rel="noopener">InferSent</a> is a pre-trained encoder that produces sentence embedding, which opensourced by Facebook. <a href="https://tfhub.dev/google/universal-sentence-encoder/1" target="_blank" rel="noopener">The Google Sentence Encoder</a> is Google’s answer to Facebook’s InferSent. In contrast to InferSent, the Google Sentence Encoder was trained on a combination of unsupervised data and supervised data (SNLI corpus), which tends to give better results.</p>
<p>The codes can be used in <a href="https://colab.research.google.com/notebooks/welcome.ipynb#recent=true" target="_blank" rel="noopener">Google Jupyter Notebook</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow_hub <span class="keyword">as</span> hub</span><br><span class="line"></span><br><span class="line">tf.logging.set_verbosity(tf.logging.ERROR)</span><br><span class="line">embed = hub.Module(<span class="string">"https://tfhub.dev/google/universal-sentence-encoder/1"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_gse_benchmark</span><span class="params">(sentences1, sentences2)</span>:</span></span><br><span class="line">    sts_input1 = tf.placeholder(tf.string, shape=(<span class="keyword">None</span>))</span><br><span class="line">    sts_input2 = tf.placeholder(tf.string, shape=(<span class="keyword">None</span>))</span><br><span class="line"></span><br><span class="line">    sts_encode1 = tf.nn.l2_normalize(embed(sts_input1))</span><br><span class="line">    sts_encode2 = tf.nn.l2_normalize(embed(sts_input2))</span><br><span class="line"></span><br><span class="line">    sim_scores = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:</span><br><span class="line">        session.run(tf.global_variables_initializer())</span><br><span class="line">        session.run(tf.tables_initializer())</span><br><span class="line"></span><br><span class="line">        [gse_sims] = session.run(</span><br><span class="line">            [sim_scores],</span><br><span class="line">            feed_dict=&#123;</span><br><span class="line">                sts_input1: [sent1.raw <span class="keyword">for</span> sent1 <span class="keyword">in</span> sentences1],</span><br><span class="line">                sts_input2: [sent2.raw <span class="keyword">for</span> sent2 <span class="keyword">in</span> sentences2]</span><br><span class="line">            &#125;)</span><br><span class="line">    <span class="keyword">return</span> gse_sims</span><br></pre></td></tr></table></figure>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_experiment</span><span class="params">(df, benchmarks)</span>:</span></span><br><span class="line">    sentences1 = [Sentence(s) <span class="keyword">for</span> s <span class="keyword">in</span> df[<span class="string">'sent_1'</span>]]</span><br><span class="line">    sentences2 = [Sentence(s) <span class="keyword">for</span> s <span class="keyword">in</span> df[<span class="string">'sent_2'</span>]]</span><br><span class="line"></span><br><span class="line">    pearson_cors, spearman_cors = [], []</span><br><span class="line">    <span class="keyword">for</span> label, method <span class="keyword">in</span> benchmarks:</span><br><span class="line">        sims = method(sentences1, sentences2)</span><br><span class="line">        pearson_correlation = scipy.stats.pearsonr(sims, df[<span class="string">'sim'</span>])[<span class="number">0</span>]</span><br><span class="line">        print(label, pearson_correlation)</span><br><span class="line">        pearson_cors.append(pearson_correlation)</span><br><span class="line">        spearman_correlation = scipy.stats.spearmanr(sims, df[<span class="string">'sim'</span>])[<span class="number">0</span>]</span><br><span class="line">        spearman_cors.append(spearman_correlation)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pearson_cors, spearman_cors</span><br></pre></td></tr></table></figure>
<p>Helper function:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> functools <span class="keyword">as</span> ft</span><br><span class="line"></span><br><span class="line">benchmarks = [</span><br><span class="line">    (<span class="string">"AVG-GLOVE"</span>, ft.partial(run_avg_benchmark, model=glove, use_stoplist=<span class="keyword">False</span>)),</span><br><span class="line">    (<span class="string">"AVG-GLOVE-STOP"</span>, ft.partial(run_avg_benchmark, model=glove, use_stoplist=<span class="keyword">True</span>)),</span><br><span class="line">    (<span class="string">"AVG-GLOVE-TFIDF"</span>, ft.partial(run_avg_benchmark, model=glove, use_stoplist=<span class="keyword">False</span>, doc_freqs=doc_frequencies)),</span><br><span class="line">    (<span class="string">"AVG-GLOVE-TFIDF-STOP"</span>, ft.partial(run_avg_benchmark, model=glove, use_stoplist=<span class="keyword">True</span>, doc_freqs=doc_frequencies)),</span><br><span class="line">    (<span class="string">"SIF-W2V"</span>, ft.partial(run_sif_benchmark, freqs=frequencies, model=word2vec, use_stoplist=<span class="keyword">False</span>)),</span><br><span class="line">    (<span class="string">"SIF-GLOVE"</span>, ft.partial(run_sif_benchmark, freqs=frequencies, model=glove, use_stoplist=<span class="keyword">False</span>)),</span><br><span class="line"></span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">20</span>,<span class="number">13</span>)</span><br><span class="line">spearman[[<span class="string">'AVG-GLOVE'</span>, <span class="string">'AVG-GLOVE-STOP'</span>,<span class="string">'AVG-GLOVE-TFIDF'</span>, <span class="string">'AVG-GLOVE-TFIDF-STOP'</span>,<span class="string">'GSE'</span>]].plot(kind=<span class="string">"bar"</span>).legend(loc=<span class="string">"lower left"</span>)</span><br></pre></td></tr></table></figure>
<p><strong>Take Off</strong></p>
<ul>
<li>Smooth Inverse Frequency methods are better than baseline, no matter with word2vec or Glove embeddings.</li>
<li>Google Sentence Encoder has the similar performance as Smooth Inverse Frequency.</li>
<li>Using tf-idf weights does not help and using a stoplist looks like a reasonable choice.</li>
</ul>
<p>Pearson Correlation<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g1swpqj9d0j20ps0h5t8z.jpg" alt=""><br>Spearman Correlation<br><img src="http://ww1.sinaimg.cn/large/e9a223b5ly1g1swpqj9d0j20ps0h5t8z.jpg" alt=""></p>
<p>Full codes can be found in <a href="https://github.com/jijeng/sentence-similarity" target="_blank" rel="noopener">here</a>.</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/03/26/深度网络中的碎碎念/" rel="next" title="深度网络中的碎碎念">
                <i class="fa fa-chevron-left"></i> 深度网络中的碎碎念
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/04/09/python-for-beginners/" rel="prev" title="Python from Beginner to Master">
                Python from Beginner to Master <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpeg"
                alt="Jijeng Jia" />
            
              <p class="site-author-name" itemprop="name">Jijeng Jia</p>
              <p class="site-description motion-element" itemprop="description">Stay Hungry, Stay Foolish</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">64</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">41</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/jijeng" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:jia1509309698@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          <script type="text/javascript" src="//rf.revolvermaps.com/0/0/5.js?i=5kk0u0mm50w&amp;m=0&amp;c=54ff00&amp;cr1=ff0000" async="async"></script>

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Data"><span class="nav-number">1.</span> <span class="nav-text">Data</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Similarity-Methods"><span class="nav-number">2.</span> <span class="nav-text">Similarity Methods</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Baseline"><span class="nav-number">2.1.</span> <span class="nav-text">Baseline</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Smooth-Inverse-Frequency"><span class="nav-number">2.2.</span> <span class="nav-text">Smooth Inverse Frequency</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Google-Sentence-Encoder"><span class="nav-number">2.3.</span> <span class="nav-text">Google Sentence Encoder</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Experiments"><span class="nav-number">3.</span> <span class="nav-text">Experiments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Results"><span class="nav-number">4.</span> <span class="nav-text">Results</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jijeng Jia</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>

<div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
Total  <span id="busuanzi_value_site_pv"></span> views
You got  <span id="busuanzi_value_site_uv"></span> visitors
</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://https-jijeng-github-io.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2019/04/06/The-evaluation-of-sentence-similarity/';
          this.page.identifier = '2019/04/06/The-evaluation-of-sentence-similarity/';
          this.page.title = 'The Evaluation of Sentence Similarity';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://https-jijeng-github-io.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
