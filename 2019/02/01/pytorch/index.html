<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="pytorch," />










<meta name="description" content="pytorch 学习笔记 不理解的地方，一个是关于 nn包搭建网络的部分。">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch">
<meta property="og:url" content="http://yoursite.com/2019/02/01/pytorch/index.html">
<meta property="og:site_name" content="Jijeng&#39;s blog">
<meta property="og:description" content="pytorch 学习笔记 不理解的地方，一个是关于 nn包搭建网络的部分。">
<meta property="article:published_time" content="2019-02-01T12:36:03.000Z">
<meta property="article:modified_time" content="2020-03-28T01:59:17.315Z">
<meta property="article:author" content="Jijeng Jia">
<meta property="article:tag" content="pytorch">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/02/01/pytorch/"/>







<script>
	(function(){
		if(''){
			if (prompt('请输入文章密码','') !== ''){
				alert('密码错误！');
				history.back();
			}
		}
	})();
</script>

  <title>pytorch | Jijeng's blog</title>
  








<meta name="generator" content="Hexo 4.2.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jijeng's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/01/pytorch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jijeng Jia">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jijeng's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">pytorch</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-01T20:36:03+08:00">
                2019-02-01
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2020-03-28T09:59:17+08:00">
                2020-03-28
              </time>
            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/02/01/pytorch/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/02/01/pytorch/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>pytorch 学习笔记</p>
<p>不理解的地方，一个是关于 nn包搭建网络的部分。</p>
<a id="more"></a>


<ol>
<li>pytorch 和torch 比较</li>
</ol>
<p>编程语言：<br>pytorch 采用python语言，实际上使用c语言和c++ 做接口<br>torch 采用lua，使用c语言和lua 语言做接口<br>（lua 语言相当于一个小型加强版的c语言，支持类和面向对象）<br>依赖库：<br>pytorch 和 torch 框架的区别和联系：<br>pytorch 可调用python强大的第三方库，比如 opencv<br>torch 可调用 lua 库函数，目前 lua库函数没有python多<br>pytorch 依赖库多于 torch<br>效率：<br>python 的debug 功能比lua 强大，所以pytorch 效率高于torch<br>模型和中间变量的关系：<br>pytorch 中中间变量都存在计算图中，所以model 共享中间变量<br>torch 的中间变量在每一个模块中，所以想要调用其他模块的参数就必须复制这个模块然后再调用</p>
<p>总结<br>pytorch可以说是torch 的python版本，并增加了很多新功能</p>
<ol start="2">
<li>常用的框架比较</li>
</ol>
<p>tensorflow 背后是google， mxnet 是Amazon，pytorch背后是Facebook<br>每个框架都有各自的有点，比如tensorflow的工程能力很强，Theano特别适合科研等等<br>keras是一个很高层的结构，它的后端支持theano和tensorflow，它本质上并不是一个框架，只是对框架的操作做了一个封装，你在写keras的时候其实是对其后端进行调用，相当于你还是在tensorflow或者theano上跑程序，只不过你把你的语言交给keras处理了一下变成tensorflow听得懂的语言，然后再交给tensorflow处理，这样的后果当然方便你构建网络，方便定义模型做训练，极快的构建你的想法，工程实现很强，但是这样也有一个后果，那就是细节你没有办法把控，训练过程高度封装，导致你没有办法知道里面的具体细节，以及每个参数的具体细节，使得调试和研究变得很困难。</p>
<ol start="3">
<li>pytorch的思想</li>
</ol>
<p>PyTorch 的构建者表明，PyTorch 的哲学是解决当务之急，也就是说即时构建和运行我们的计算图。这恰好适合 Python 的编程方法，因为我们不需等待整个代码都被写入才能知道是否起作用。我们很容易运行部分代码，并实时检查它。</p>
<p>PyTorch 是一个基于 Python 的库，旨在为深度学习提供一个灵活的开发平台。PyTorch 的工作流程非常接近于 Python 的科学计算库 NumPy。那么为什么我们需要使用 PyTorch 构建深度学习模型？以下作者根据实际经验提供了三个理由：</p>
<ul>
<li>便于使用的 API：它的使用如同 Python 那样简单。</li>
<li>支持 Python：正如上文所述，PyTorch 可以平滑地与 Python 数据科学栈相结合。它与 NumPy 一样简单，甚至我们都感觉不出它们的区别。</li>
<li>动态计算图：PyTorch 不再采用特定的函数预定义计算图，而是提供构建动态计算图的框架，甚至我们可以在运行时修正它们。这种动态框架在我们不知道所构建的神经网络需要多少内存时非常有用。<br>其它一些使用 PyTorch 的优点还有多 GPU 支持、自定义数据加载器和极简的预处理过程等。</li>
</ul>
<p>在讨论 PyTorch 的各个组件前，我们需要了解它的工作流。PyTorch 使用一种称之为 imperative / eager 的范式，即每一行代码都要求构建一个图以定义完整计算图的一个部分。即使完整的计算图还没有完成构建，我们也可以独立地执行这些作为组件的小计算图，这种动态计算图被称为<strong>「define-by-run」</strong>方法。</p>
<p>PyTorch 提供了 CPU 张量和 GPU 张量，并且极大地加速了计算的速度。<br>从张量的构建与运行就能体会到 PyTorch 相比 TensorFLow 需要声明张量、初始化张量要简洁地多。以下语句将随机初始化一个 5×3 的二维张量，因为 PyTorch 是一种动态图，所以它声明和真实赋值是同时进行的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Tensor(5, 3)</span><br></pre></td></tr></table></figure>
<p>若我们希望随机初始化的张量服从某些分布，那么我们可以直接对张量对象使用一些方法。如下初始化的张量将服从均匀分布：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Tensor(5, 3).uniform_(-1, 1)</span><br></pre></td></tr></table></figure>

<p>PyTorch 同样支持广播（Broadcasting）操作，一般它会隐式地把一个数组的异常维度调整到与另一个算子相匹配的维度以实现维度兼容。</p>
<p>如下，我们定义了两个 GPU 张量，并对这两个张量执行矩阵乘法。当然，我们也可以如下所示将 CPU 张量转换为 GPU 张量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以下转化CPU张量为GPU张量</span></span><br><span class="line">x = torch.FloatTensor(<span class="number">5</span>, <span class="number">3</span>).uniform_(<span class="number">-1</span>, <span class="number">1</span>)</span><br><span class="line">print(x)</span><br><span class="line">x = x.cuda(device=<span class="number">0</span>)</span><br><span class="line">print(x)</span><br><span class="line">x = x.cpu()</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>

<p><code>AutoGrad 模块</code></p>
<p>TensorFlow、Caffe 和 CNTK 等大多数框架都是使用的静态计算图，开发者必须建立或定义一个神经网络，并重复使用相同的结构来执行模型训练。改变网络的模式就意味着我们必须从头开始设计并定义相关的模块。</p>
<p>PyTorch 使用的技术为自动微分（automatic differentiation），这个是用来自动求解微分的模块。在这种机制下，系统会有一个 Recorder 来记录我们执行的运算，然后再反向计算对应的梯度。这种技术在构建神经网络的过程中十分强大，因为我们可以通过计算前向传播过程中参数的微分来节省时间。</p>
<p>从概念上讲, <code>Autograd</code> 对数据记录记录了一个有向无环图（DAG）， 叫做计算图，用来表示它的计算过程。沿着计算图应用链式求导法则就可以求出其梯度。<code>Autograd</code> 包中有两个核心包： <code>torch.Tensor</code> 和<code>torch.Function</code>， 默认某个 tensor的属性是 <code>.requires_grad</code> 为true，当计算完成的时候可以调用 <code>.backward()</code> 来自动计算所有的梯度，针对这个tensor 可以在 <code>.grad</code> 属性中去查看。</p>
<p>设置一个张量不跟踪历史记录的方法：</p>
<ol>
<li>调用 <code>.detach()</code> 将其从计算历史中分离出来</li>
<li>使用 <code>torch.no_grad()</code> 包裹代码块，那么在该代码块中的计算都不会计算梯度。使用的情况是， 在评估阶段（predict）阶段。</li>
<li>设置某个tensor 的属性为 <code>Required_grad =False</code></li>
</ol>
<p><code>Function</code> 类，每一个tensor都有一个<code>.grad_fn</code> 属性指向一个 <code>Function</code>，表示如何得到了当期的tensor。如果是用户自己创建的张量tensor，那么 <code>grad_fn is None</code>。</p>
<p><code>.requires_grad</code>具有传递性，比如说 $x_1, x_2, \dots, x_n$ 中某一个满足 <code>required_grad =True</code>，那么这个时候由这些tensor表示tensor 的属性都是<code>true</code>。</p>
<p><strong>最优化模块</strong><br>torch.optim 是实现神经网络中多种优化算法的模块，它目前已经支持大多数一般的方法，所以我们不需要从头构建优化算法。以下展示了使用 Adam 优化器的基本代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer &#x3D; torch.optim.Adam(model.parameters(), lr&#x3D;learning_rate)</span><br></pre></td></tr></table></figure>


<p>我们一般可以使用 torch.nn 包构建神经网络，下面提供了一些 API 的表达及意义：</p>
<ul>
<li>线性层- nn.Linear、nn.Bilinear</li>
<li>卷积层 - nn.Conv1d、nn.Conv2d、nn.Conv3d、nn.ConvTranspose2d</li>
<li>非线性激活函数- nn.Sigmoid、nn.Tanh、nn.ReLU、nn.LeakyReLU</li>
<li>池化层 - nn.MaxPool1d、nn.AveragePool2d</li>
<li>循环网络 - nn.LSTM、nn.GRU</li>
<li>归一化 - nn.BatchNorm2dDropout - nn.Dropout、nn.Dropout2d</li>
<li>嵌入 - nn.Embedding</li>
<li>损失函数 - nn.MSELoss、nn.CrossEntropyLoss、nn.NLLLoss</li>
</ul>
<p><strong>张量</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">a &#x3D; torch.FloatTensor(5, 7)</span><br></pre></td></tr></table></figure>

<p>相同点 / 不同点<br>第一个区别是，所有的操作在张量操作需要有_后缀。例如，add在此处无用，使用add_是可用的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a.fill_(<span class="number">3.5</span>)</span><br><span class="line"><span class="comment"># 将a填充值3.5。</span></span><br><span class="line">b = a.add(<span class="number">4.0</span>)</span><br><span class="line"><span class="comment"># a 依然是填充3.5</span></span><br><span class="line"><span class="comment"># 新张量b的返回值为3.5 + 4＝7.5。</span></span><br><span class="line">print(a, b)</span><br></pre></td></tr></table></figure>

<p><strong>零索引</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">b &#x3D; a[0, 3]  # 选择a中的1行4列</span><br><span class="line">b &#x3D; a[:, 3:5]  # 从a中选择所以行的4到5列</span><br><span class="line">x.index_add_(1, torch.LongTensor([4, 0]), z)</span><br></pre></td></tr></table></figure>
<p>下一个小的区别是所有的功能现在都不是驼峰命名了。例如indexAdd现在调用index_add_</p>
<p>CUDA传感器在pytorch中很好并且很容易，并将CUDA张量从CPU转移到GPU将保留其基础类型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看电脑是否支持CUDA</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    <span class="comment"># 创建一个LongTensor并且把它全部转换为3</span></span><br><span class="line">    <span class="comment"># to GPU as torch.cuda.LongTensor</span></span><br><span class="line">    a = torch.LongTensor(<span class="number">10</span>).fill_(<span class="number">3</span>).cuda()</span><br><span class="line">    print(type(a))</span><br><span class="line">    b = a.cpu()</span><br><span class="line">    <span class="comment"># transfers it to CPU, back to</span></span><br><span class="line">    <span class="comment"># being a torch.LongTensor</span></span><br></pre></td></tr></table></figure>

<p>基本类型<br>Tensor的基本数据类型有五种：</p>
<ul>
<li>32位浮点型：torch.FloatTensor。 (默认)</li>
<li>64位整型：torch.LongTensor。</li>
<li>32位整型：torch.IntTensor。</li>
<li>16位整型：torch.ShortTensor。</li>
<li>64位浮点型：torch.DoubleTensor。</li>
</ul>
<p>numpy 和 tensor 之间的相互转换</p>
<p>使用numpy 方法将tensor 转换成 ndarray</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn((<span class="number">3</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># tensor转化为numpy</span></span><br><span class="line">numpy_a = a.numpy()</span><br><span class="line">print(numpy_a)</span><br></pre></td></tr></table></figure>

<p>numpy转化为Tensor</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch_a = torch.from_numpy(numpy_a)</span><br><span class="line">torch_a</span><br></pre></td></tr></table></figure>



<p>一般情况下可以使用.cuda方法将tensor移动到gpu，这步操作需要cuda设备支持</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cpu_a&#x3D;torch.rand(4, 3)</span><br><span class="line">cpu_a.type()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gpu_a&#x3D;cpu_a.cuda()</span><br><span class="line">gpu_a.type()</span><br></pre></td></tr></table></figure>

<p>使用.cpu 将tensor 转换成cpu</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cpu_b&#x3D;gpu_a.cpu()</span><br><span class="line">cpu_b.type()</span><br></pre></td></tr></table></figure>


<p>如果我们有多GPU的情况，可以使用to方法来确定使用那个设备，这里只做个简单的实例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#使用torch.cuda.is_available()来确定是否有cuda设备</span><br><span class="line">device &#x3D; torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">print(device)</span><br><span class="line">#将tensor传送到设备</span><br><span class="line">gpu_b&#x3D;cpu_b.to(device)</span><br><span class="line">gpu_b.type()</span><br></pre></td></tr></table></figure>

<p>下一章介绍PyTorch的自动求导机制</p>
<ul>
<li>变量</li>
<li>梯度</li>
</ul>
<p>从0.4起, Variable 正式合并入Tensor类, 通过Variable嵌套实现的自动微分功能已经整合进入了Tensor类中。虽然为了代码的兼容性还是可以使用Variable(tensor)这种方式进行嵌套, 但是这个操作其实什么都没做。所以，以后的代码建议直接使用Tensor类进行操作，因为官方文档中已经将Variable设置成过期模块。要想通过Tensor类本身就支持了使用autograd功能，只需要设置.requries_grad=True。 Variable类中的的grad和grad_fn属性已经整合进入了Tensor类中</p>
<p>每个变量都有两个标志：<code>requires_grad</code>和<code>volatile</code>。它们都允许从梯度计算中精细地排除子图，并可以提高效率。</p>
<p><code>requires_grad</code><br>如果有一个单一的输入操作需要梯度，它的输出也需要梯度。相反，只有所有输入都不需要梯度，输出才不需要。如果其中所有的变量都不需要梯度进行，后向计算不会在子图中执行。</p>
<p>这个标志特别有用，当您想要冻结部分模型时，或者您事先知道不会使用某些参数的梯度。例如，如果要对预先训练的CNN进行优化，只要切换冻结模型中的requires_grad标志就足够了，直到计算到最后一层才会保存中间缓冲区，其中的仿射变换将使用需要梯度的权重并且网络的输出也将需要它们。</p>
<p><code>volatile</code></p>
<p>纯粹的inference模式下推荐使用volatile，当你确定你甚至不会调用.backward()时。它比任何其他自动求导的设置更有效——它将使用绝对最小的内存来评估模型。volatile也决定了require_grad is False。</p>
<p>volatile不同于require_grad的传递。如果一个操作甚至只有有一个volatile的输入，它的输出也将是volatile。Volatility比“不需要梯度”更容易传递——只需要一个volatile的输入即可得到一个volatile的输出，相对的，需要所有的输入“不需要梯度”才能得到不需要梯度的输出。使用volatile标志，您不需要更改模型参数的任何设置来用于inference。创建一个volatile的输入就够了，这将保证不会保存中间状态。</p>
<p>参考<a href="https://pytorch-cn.readthedocs.io/zh/latest/notes/autograd/" target="_blank" rel="noopener">官方教程</a></p>
<p>PyTorch 基础 : 神经网络包nn和优化器optm</p>
<p><strong>pytorch 学习笔记</strong></p>
<ol>
<li>pytorch 的核心主要是提供了两个主要的功能：</li>
</ol>
<ul>
<li>n维tensor，类似numpy，但可以运行在GPU 上<br>Numpy是科学计算的通用框架;它对计算图形、深度学习或梯度一无所知。Tensor张量是pytorch 中最基本的概念。PyTorch张量可以利用GPU加速其数字计算。要在GPU上运行PyTorch Tensor，请在构造Tensor时使用<code>device</code>参数将Tensor放置在GPU上。</li>
<li>自动微分，用于构建和训练神经网络<br>使用自动微分来自动计算神经网络中的反向通过。</li>
</ul>
<ol start="2">
<li><p>在搭建网络的过程中，网络中的正向传播定义为一个 computational graph计算图： 图中的节点为张量，边为从输入张量产生输出张量的函数，然后通过改图进行反向传播，可以轻松计算梯度。默认张量中的参数 <code>require_grad=True</code>， 那么在反向传播的时候， <code>x.grad</code>将是另一个张量， 它保持了<code>x</code> 相对于某个标量值的梯度。如果在训练神经网络的时候，比如通常不想要更新步骤中向后传播（形成计算图），那么这个时候可以使用 <code>torch.no_grad()</code> 上下文管理器来防止构建计算图。</p>
</li>
<li><p>pytorch 中的计算图很想 tensorflow 中的计算图，但是两者不同在于前者是动态图，后者是静态图。在tensorflow 中，如果定义了一个计算图，然后一遍遍计算相同的图，可能将不同的输入数据提供给图。在pytorch 中，每一个前向传播都定义了一个新的计算图。静态图的优势，可以预先优化图，比如说融合某些图的操作，分布式之类的。而动态图，入门比较简单，方便debug。</p>
</li>
<li><p>pytorch中常见的包：</p>
</li>
</ol>
<ul>
<li>nn 定义了一组模块，包括神经网络层和有用的损失函数</li>
<li>optim（优化器），优化算法的思想， 比如说 adagrad， rmsprop， adam <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 常见的操作</span><br><span class="line">调用模型前向传播 y_pred &#x3D; model(x)</span><br><span class="line">调用损失函数 loss &#x3D; loss_fn(y_pred, y)</span><br><span class="line">梯度归零 optimizer.zero_grad()</span><br><span class="line">后向传播 loss.backward()</span><br><span class="line">调用优化器更新参数 optimizer.step()</span><br></pre></td></tr></table></figure></li>
</ul>
<ol start="5">
<li><p>使用 custom nn module（这种是经常用到，搭建自己的nn 网络）<br>通过子类nn.Module并定义一个<code>forwad</code>输入来定义自己的模块，该前向接收输入张量并使用其他模块或在张量上的其他自动转换操作产生输出张量。</p>
</li>
<li><p>control flow and weight sharing<br>这个权值共享在RNN 中使用比较多，但是不是很多呀，多看例子把~</p>
</li>
</ol>
<ol start="7">
<li>pytorch  中 <code>model.train()</code> 和 <code>model.eval()</code> 的区别</li>
</ol>
<p>在图像中影响比较大。如果模型中出现了BatchNormalization 和Dropout，必须要区分训练和验证模式。两种模式在计算上是不同的。当 eval 的时候，模型会自动把 BN和DropOut固定住，使用已经训练好的值，否则容易出现异常的结果。 </p>
<ol start="8">
<li>contiguous 关键词</li>
</ol>
<p>contiguous  使用空间换取时间，保证语义上相邻的元素在内存上也是连续的。这样访问的时候，可以减少cpu 对内存的请求的次数。</p>
<h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><p> PyTorch是Torch框架的表亲，Torch是基于lua开发的，在Facebook公司里被广泛使用。然而，PyTorch的出现并不是为了支持流行语言而对Torch进行简单的包装，它被重写和定制出来是为了得到更快的速度和本地化。</p>
<p>tensorboardx </p>
<p>Visdom是Facebook在2017年发布的一款针对PyTorch的可视化工具</p>
<p>方案： pytorch 使用替代品tensorbordx</p>
<p>Pytorch框架也有自己的可视化软件–Visdom，但貌似不是很好用。所以是可以用tensorboardx 来进行运行的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorboardX</span><br><span class="line">pip install tensorboard</span><br><span class="line">pip install tensorflow</span><br><span class="line"></span><br><span class="line">tensorboard --logdir runs</span><br><span class="line">http://localhost:<span class="number">6006</span>/    <span class="comment">#在chrome浏览器中打开</span></span><br></pre></td></tr></table></figure>
<p>注意numpy的版本要对应，否则会报错，如果不匹配，那就进行更新或者新建虚拟环境了！</p>
<ol>
<li><p>Loss可视化<br>最常见的可视化就是loss曲线作图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tb_logger.add_scalar(<span class="string">'loss_train'</span>, loss, curr_step)</span><br></pre></td></tr></table></figure>
</li>
<li><p>输入图片和标签的可视化</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tb_logger.add_image(&#39;image&#39;, input[0], curr_step)</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>单通道特征图的可视化</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def make_grid(tensor, nrow&#x3D;8, padding&#x3D;2,</span><br><span class="line">              normalize&#x3D;False, range&#x3D;None, scale_each&#x3D;False, pad_value&#x3D;0):</span><br></pre></td></tr></table></figure>






<p>pytorch最被人诟病的就是可视化问题和部署问题</p>
<p><a href="https://shenxiaohai.me/2018/10/23/pytorch-tutorial-TensorBoard/" target="_blank" rel="noopener">https://shenxiaohai.me/2018/10/23/pytorch-tutorial-TensorBoard/</a></p>
<p><a href="https://www.jianshu.com/p/429eb27855a0" target="_blank" rel="noopener">https://www.jianshu.com/p/429eb27855a0</a></p>
<p>可视化工具 visdom</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install visdom</span><br></pre></td></tr></table></figure>


<p>使用 以下命令在本地启动服务器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m visdom.server</span><br></pre></td></tr></table></figure>

<p>然后输入 <code>http://localhost:8097</code></p>
<p>‘model.eval()’ vs ‘with torch.no_grad()’</p>
<blockquote>
<p>These two have different goals:<br>model.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.<br>torch.no_grad() impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop (which you don’t want in an eval script).<br>eval()和train 的不同在于 BN 和DropOut 机制的是否使用，前者是不使用，后者是使用。 no_grad() 是不进行反向传播，主要是用来减少内存和加快训练的。</p>
</blockquote>
<blockquote>
<p>Dropout works as a regularization for preventing overfitting during training.<br>It randomly zeros the elements of inputs in Dropout layer on forward call.<br>It should be disabled during testing ( model.eval() ) since you may want to use full model (no element is masked)</p>
</blockquote>
<ol>
<li>argparse模块中的action参数</li>
</ol>
<p>用argparse模块让python脚本接收参数时，对于True/False类型的参数，向add_argument方法中加入参数action=‘store_true’/‘store_false’。<br>顾名思义，store_true就代表着一旦有这个参数，做出动作“将其值标为True”，也就是没有时，默认状态下其值为False。反之亦然，store_false也就是默认为True，一旦命令中有此参数，其值则变为False。</p>
<p>参考文献</p>
<p><a href="https://www.jianshu.com/p/9779683ffa58" target="_blank" rel="noopener">介绍PyTorch的简单示例</a><br><a href="https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#examples" target="_blank" rel="noopener">LEARNING PYTORCH WITH EXAMPLES</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/pytorch/" rel="tag"># pytorch</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/01/22/regular-expression/" rel="next" title="Regular Expression">
                <i class="fa fa-chevron-left"></i> Regular Expression
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/02/06/algorithm-demo1/" rel="prev" title="算法模板-基础算法">
                算法模板-基础算法 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpeg"
                alt="Jijeng Jia" />
            
              <p class="site-author-name" itemprop="name">Jijeng Jia</p>
              <p class="site-description motion-element" itemprop="description">Solving Problems by Coding</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%20%7C%7C%20archive">
              
                  <span class="site-state-item-count">168</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">83</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/jijeng" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:jia1509309698@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          <script type="text/javascript" src="//rf.revolvermaps.com/0/0/5.js?i=5kk0u0mm50w&amp;m=0&amp;c=54ff00&amp;cr1=ff0000" async="async"></script>


        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#可视化"><span class="nav-number">1.</span> <span class="nav-text">可视化</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jijeng Jia</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>

<div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
Total  <span id="busuanzi_value_site_pv"></span> views
You got  <span id="busuanzi_value_site_uv"></span> visitors
</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://https-jijeng-github-io.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2019/02/01/pytorch/';
          this.page.identifier = '2019/02/01/pytorch/';
          this.page.title = 'pytorch';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://https-jijeng-github-io.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  















  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('10');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
